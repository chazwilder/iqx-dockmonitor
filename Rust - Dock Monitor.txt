# Table of Contents
- ./
  - Cargo.toml
  - note.py
  - assets/
  - logs/
  - outputs/
  - src/
    - config.rs
    - errors.rs
    - init.rs
    - lib.rs
    - main.rs
    - alerting/
      - alert_manager.rs
      - mod.rs
    - analysis/
      - context_analyzer.rs
      - mod.rs
    - config/
      - default.yaml
      - log4rs.yaml
      - rules.json
    - controllers/
      - dock_door.rs
      - mod.rs
    - event_handling/
      - event_handler.rs
      - mod.rs
    - logs/
    - models/
      - consolidated_dock_event.rs
      - idb_log.rs
      - idoor.rs
      - ievents.rs
      - isensor.rs
      - istates.rs
      - istatus.rs
      - mod.rs
      - plcvalue.rs
    - monitoring/
      - mod.rs
      - monitoring_queue.rs
      - monitoring_worker.rs
    - repositories/
      - consolidated.rs
      - door_event_repository.rs
      - mod.rs
      - repository_trait.rs
      - wms_status_repository.rs
    - rules/
      - consolidated_data_rule.rs
      - docking_state_rule.rs
      - dock_ready_rule.rs
      - dynamic_rule_manager.rs
      - long_loading_start_rule.rs
      - manual_intervention_rule.rs
      - mod.rs
      - new_shipment_old_trailer_rule.rs
      - rule_factory.rs
      - shipment_started_load_not_ready_rule.rs
      - suspended_door_rule.rs
      - trailer_at_door_db.rs
      - trailer_docking_rule.rs
      - trailer_hostage_rule.rs
      - trailer_pattern_rule.rs
      - trailer_undocking_rule.rs
      - wms_events_rule.rs
      - wms_shipment_status_rule.rs
    - services/
      - db.rs
      - mod.rs
      - dbc/
        - database_client.rs
        - mod.rs
      - plc/
        - mod.rs
        - plcs.rs
        - plc_reader.rs
        - plc_tag_factory.rs
    - state_management/
      - command_processor.rs
      - database_event_manager.rs
      - door_state_repository.rs
      - event_dispatcher.rs
      - mod.rs
      - sensor_data_processor.rs
      - state_manager.rs
      - state_manager_lifecycle.rs
      - wms_data_processor.rs
    - utils/
      - mod.rs
  - __pycache__/

--------------------------------------------------------------------------------

# Cargo.toml
```
[package]
name = "iqx-dockmonitor"
version = "0.1.0"
edition = "2021"


[dependencies]
tokio = { version = "1.39.2", features = ["full"] }
anyhow = "1.0.86"
plctag = "0.4.0"
config = "0.14.0"
serde = { version = "1.0.205", features = ["derive"] }
thiserror = "1.0.63"
sqlx-oldapi = {version = "0.6.23", features = ["mssql", "macros", "sqlx-macros", "runtime-tokio-native-tls", "chrono"]}
lapin = {version = "2.5.0", features = ["native-tls"]}
serde_json = "1.0.122"
chrono = {version = "0.4.38", features = ["serde"]}
futures = "0.3.30"
parking_lot = "0.12.3"
secrecy = "0.8.0"
url = "2.5.2"
derive_more = {version = "1.0.0", features = ["full"]}
time = "0.3.36"
async-trait = "0.1.81"
reqwest = { version = "0.12.7", features = ["json"] }
dashmap = { version =  "6.1.0", features = ["serde", "rayon", "inline"] }
rayon = "1.10.0"
log = "0.4.22"
log4rs = {version = "1.3.0", features = ["rolling_file_appender","serde", "chrono","file_appender", "fixed_window_roller", "console_appender", "gzip", "background_rotation"]}
tracing = "0.1.40"
once_cell = "1.19.0"

[profile.release]
debug = true
```

--------------------------------------------------------------------------------

# note.py
```
import os
import fnmatch

# Hardcoded values
ROOT_DIR = "."  # Current directory
OUTPUT_FILE = "Rust - Dock Monitor.txt"
EXCLUDE_PATTERNS = ["*target", "*git", "*idea", "output"]
FILE_EXTENSIONS = (".rs", ".toml", ".yaml", ".json", ".py")


def should_exclude(path):
    return any(fnmatch.fnmatch(os.path.basename(path), pattern) for pattern in EXCLUDE_PATTERNS)


def generate_toc(root_dir):
    toc = ["# Table of Contents\n"]
    for root, dirs, files in os.walk(root_dir):
        dirs[:] = [d for d in dirs if not should_exclude(d)]
        level = root.replace(root_dir, '').count(os.sep)
        indent = '  ' * level
        toc.append(f"{indent}- {os.path.basename(root)}/\n")
        for file in files:
            if file.endswith(FILE_EXTENSIONS) and not should_exclude(file):
                toc.append(f"{indent}  - {file}\n")
    return ''.join(toc)


def generate_content(root_dir):
    content = []
    for root, dirs, files in os.walk(root_dir):
        dirs[:] = [d for d in dirs if not should_exclude(d)]
        for file in files:
            if file.endswith(FILE_EXTENSIONS) and not should_exclude(file):
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, root_dir)
                content.append(f"\n# {relative_path}\n")
                content.append("```\n")
                with open(file_path, 'r', encoding='utf-8') as f:
                    content.append(f.read())
                content.append("```\n")
                content.append("\n" + "-" * 80 + "\n")
    return ''.join(content)


def main():
    toc = generate_toc(ROOT_DIR)
    content = generate_content(ROOT_DIR)

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(toc)
        f.write("\n" + "-" * 80 + "\n")
        f.write(content)

    print(f"File '{OUTPUT_FILE}' has been generated successfully.")


if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

# src\config.rs
```
//! # Configuration Management

//! This module handles the configuration loading and management for the IQX Dock Manager application. 
//! It leverages the `config` crate to provide a flexible and structured way to define and access configuration settings from various sources, including:

//! * YAML configuration files (default.yaml, development.yaml, production.yaml, queries.yaml, dock_doors.yaml)
//! * Environment variables

//! The core of this module is the `Settings` struct, which encapsulates all the configuration settings required by the application.

use serde::{Deserialize, Serialize};
use config::{Config, Environment, File};
use std::{env, fmt};
use std::path::PathBuf;
use secrecy::{Secret, ExposeSecret};
use log::{debug};
use url::Url;
use crate::errors::DockManagerError;

/// Represents the complete set of configuration settings for the IQX Dock Manager.
/// It's populated by reading from various configuration sources and provides convenient access to the settings throughout the application.
#[derive(Debug, Deserialize, Clone)]
pub struct Settings {
    /// Settings for connecting to the local database
    pub database: DatabaseSettings,
    /// Settings related to PLC (Programmable Logic Controller) communication
    pub plc: PlcSettings,
    /// Settings for application logging
    pub logging: LoggingSettings,
    /// Settings for connecting to the RabbitMQ message broker
    pub rabbitmq: RabbitMQSettings,
    /// SQL queries used to fetch data from the WMS database
    pub queries: Queries,
    /// Configuration settings for each plant
    pub plants: Vec<PlantSettings>,
    pub alerts: AlertSettings,
    pub monitoring: MonitoringSettings,
    pub batch_size: usize
}

/// Represents the configuration settings for a specific plant
#[derive(Debug, Deserialize, Clone)]
pub struct PlantSettings {
    /// The unique identifier for the plant
    pub plant_id: String,
    /// The webhook URL for sending alerts related to this plant
    pub alert_webhook_url: String,
    /// Settings for connecting to the LGV WMS database for this plant
    pub lgv_wms_database: LgvWmsDatabaseSettings,
    /// Configuration for dock doors and their associated PLC tags at this plant
    pub dock_doors: DockDoorSettings,
}

/// # Database Settings

/// This struct holds the configuration settings required to establish a connection to the local database
#[derive(Debug, Deserialize, Clone)]
pub struct DatabaseSettings {
    /// The hostname or IP address of the database server
    pub host: String,
    /// The port number on which the database server is listening
    pub port: u16,
    /// The username for database authentication (optional if using Windows authentication)
    pub username: Option<String>,
    /// The password for database authentication (optional if using Windows authentication)
    #[serde(deserialize_with = "deserialize_optional_secret")]
    pub password: Option<Secret<String>>,
    /// The name of the database to connect to
    pub database_name: String,
    /// The application name to be used in the connection string
    pub app_name: String,
    /// Whether to use Windows authentication (true) or SQL Server authentication (false)
    pub win_auth: bool,
    /// Whether to trust the server certificate (relevant for encrypted connections)
    pub trusted: bool,
}

impl DatabaseSettings {
    /// Constructs a connection string for the local database based on the settings
    ///
    /// This method dynamically builds the connection string, handling both Windows authentication and SQL Server authentication scenarios
    ///
    /// # Returns
    ///
    /// A `Secret<String>` containing the constructed connection string. The connection string is kept secret for security reasons
    pub fn connection_string(&self) -> Secret<String> {
        if self.username.is_none() | self.password.is_none() && self.win_auth {
            let connection_string = format!(
                "mssql://{}:{}/{}",
                self.host,
                self.port,
                self.database_name
            );
            Secret::new(connection_string)
        } else {
            let connection_string = format!(
                "mssql://{}:{}@{}:{}/{}",
                self.username.clone().unwrap(),
                self.password.clone().unwrap().expose_secret(),
                self.host,
                self.port,
                self.database_name
            );
            Secret::new(connection_string)
        }
    }
}

/// # LGV WMS Database Settings

/// This struct holds the configuration settings required to establish a connection to the LGV WMS database
#[derive(Debug, Deserialize, Clone)]
pub struct LgvWmsDatabaseSettings {
    /// The hostname or IP address of the LGV WMS database server
    pub host: String,
    /// The port number on which the LGV WMS database server is listening
    pub port: u16,
    /// The username for LGV WMS database authentication (optional if using Windows authentication)
    pub username: Option<String>,
    /// The password for LGV WMS database authentication (optional if using Windows authentication)
    #[serde(deserialize_with = "deserialize_optional_secret")]
    pub password: Option<Secret<String>>,
    /// The name of the LGV WMS database to connect to
    pub database_name: String,
    /// The application name to be used in the connection string for the LGV WMS database
    pub app_name: String,
    /// Whether to use Windows authentication (true) or SQL Server authentication (false) for the LGV WMS database
    pub win_auth: bool,
    /// Whether to trust the server certificate for the LGV WMS database (relevant for encrypted connections)
    pub trusted: bool,
}


impl LgvWmsDatabaseSettings {
    /// Constructs a connection string for the local database based on the settings
    ///
    /// This method dynamically builds the connection string, handling both Windows authentication and SQL Server authentication scenarios
    ///
    /// # Returns
    ///
    /// A `Secret<String>` containing the constructed connection string. The connection string is kept secret for security reasons
    pub fn connection_string(&self) -> Secret<String> {
        if self.username.is_none() | self.password.is_none() && self.win_auth {
            let connection_string = format!(
                "mssql://{}:{}/{}",
                self.host,
                self.port,
                self.database_name
            );
            Secret::new(connection_string)
        } else {
            let connection_string = format!(
                "mssql://{}:{}@{}:{}/{}",
                self.username.clone().unwrap(),
                self.password.clone().unwrap().expose_secret(),
                self.host,
                self.port,
                self.database_name
            );
            Secret::new(connection_string)
        }
    }
}

/// Holds the SQL queries used to fetch data from the WMS database.
#[derive(Debug, Deserialize, Clone)]
pub struct Queries {
    /// The SQL query to retrieve the current status of dock doors from the WMS
    pub wms_door_status: String,
    /// The SQL query to retrieve events related to shipments from the WMS
    pub wms_events: String,
    pub wms_rack_space: String
}

/// Holds the configuration settings related to PLC (Programmable Logic Controller) communication
#[derive(Debug, Deserialize, Clone)]
pub struct PlcSettings {
    /// The interval (in seconds) at which the PLC will be polled for sensor data
    pub poll_interval_secs: u64,
    /// The timeout (in milliseconds) for PLC communication operations
    pub timeout_ms: u64,
    /// The maximum number of retries allowed for failed PLC communication attempts
    pub max_retries: u64
}

/// Holds the configuration settings for application logging
#[derive(Debug, Deserialize, Clone)]
pub struct LoggingSettings {
    /// The logging level (e.g., "info", "debug", "error")
    pub level: String,
    /// The name of the log file (optional)
    pub file: Option<String>,
    /// The directory path where log files will be stored (optional)
    pub path: Option<PathBuf>,
}

/// Holds the configuration settings required to establish a connection to the RabbitMQ message broker.
#[derive(Debug, Deserialize, Clone)]
pub struct RabbitMQSettings {
    /// The hostname or IP address of the RabbitMQ server
    pub host: String,
    /// The port number on which the RabbitMQ server is listening
    pub port: u16,
    /// The username for RabbitMQ authentication
    pub username: String,
    /// The password for RabbitMQ authentication
    #[serde(deserialize_with = "deserialize_optional_secret")]
    pub password: Option<Secret<String>>,
    /// The name of the RabbitMQ exchange to use
    pub exchange: String,
    /// The virtual host to connect to on the RabbitMQ server
    pub vhost: String,
}

impl RabbitMQSettings {
    /// Constructs a connection string for RabbitMQ based on the settings.
    ///
    /// # Returns
    ///
    /// A `Secret<String>` containing the constructed connection string. The connection string is kept secret for security reasons.
    pub fn connection_string(&self) -> Secret<String> {
        let mut url = Url::parse(&format!("amqp://{}:{}", self.host, self.port))
            .expect("Failed to parse RabbitMQ URL");

        url.set_username(&self.username)
            .expect("Failed to set RabbitMQ username");
        if let Some(password) = &self.password {
            url.set_password(Some(password.expose_secret()))
                .expect("Failed to set RabbitMQ password");
        }
        url.set_path(&self.vhost);

        Secret::new(url.to_string())
    }
}


// Holds the configuration for dock doors and their associated PLC tags.
#[derive(Debug, Deserialize, Clone)]
pub struct DockDoorSettings {
    /// Configuration details for each individual dock door
    pub dock_door_config: Vec<DockDoorConfig>,
    /// Configuration for the PLC tags associated with the dock doors
    pub dock_plc_tags: Vec<DockPlcTag>,
}

/// Represents the configuration for a single dock door
#[derive(Debug, Deserialize, Clone)]
pub struct DockDoorConfig {
    /// The name or identifier of the dock door
    pub dock_name: String,
    /// The IP address of the PLC controlling the dock door
    pub dock_ip: String,
}

/// Represents the configuration of a PLC tag associated with a dock door
#[derive(Debug, Deserialize, Clone)]
pub struct DockPlcTag {
    /// The name of the PLC tag (e.g., "RH_DOOR_OPEN")
    pub tag_name: String,
    /// The address of the PLC tag in the PLC's memory (e.g., "B9:0/9")
    pub address: String,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct AlertSettings {
    pub suspended_door: AlertThresholds,
    pub trailer_pattern: AlertThresholds,
    pub long_loading_start: AlertThresholds,
    pub shipment_started_load_not_ready: AlertThresholds,
    pub trailer_hostage: AlertThresholds,
    pub trailer_docked: AlertThresholds,
    pub dock_ready: AlertThresholds,
    pub trailer_undocked: AlertThresholds,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct AlertThresholds {
    pub initial_threshold: u64,  // in seconds
    pub repeat_interval: u64,    // in seconds
}

#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct MonitoringSettings {
    pub check_interval: u64,  // in seconds
    pub suspended_shipment: MonitoringThresholds,
    pub trailer_docked_not_started: MonitoringThresholds,
    pub shipment_started_load_not_ready: MonitoringThresholds,
    pub trailer_hostage: MonitoringThresholds,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct MonitoringThresholds {
    pub alert_threshold: u64,  // in seconds
    pub repeat_interval: u64,  // in seconds
}


/// # Settings Initialization
///
/// The `Settings` implementation provides a `new` function to load and construct the configuration settings.
impl Settings {
    /// Loads and constructs the application settings from various configuration sources.
    ///
    /// This function reads configuration settings from the following sources, in order of precedence:
    ///
    /// 1. `default.yaml`: Contains default settings for the application
    /// 2. `queries.yaml`: Contains SQL queries used to fetch data from the WMS database (required)
    /// 3. `dock_doors.yaml`: Contains the configuration of dock doors and their associated PLC tags
    /// 4. Environment-specific YAML file (e.g., `development.yaml` or `production.yaml`) based on the `RUN_MODE` environment variable
    /// 5. Environment variables prefixed with `APP` (e.g., `APP__DATABASE__HOST`)
    ///
    /// The `CONFIG_DIR` environment variable can be used to specify the directory where the YAML configuration files are located (defaults to "src/config").
    ///
    /// # Returns
    ///
    /// * `Ok(Settings)`: If the settings were loaded and constructed successfully
    /// * `Err(DockManagerError)`: If there was an error during the loading or construction process
    pub fn new() -> Result<Self, DockManagerError> {
        let run_mode = env::var("RUN_MODE").unwrap_or_else(|_| "development".into());
        let config_dir = env::var("CONFIG_DIR").unwrap_or_else(|_| "src/config".into());
        debug!("Run Mode: {:?}, Config Dir: {:?}", run_mode, config_dir);

        let s = Config::builder()
            .add_source(File::with_name(&format!("{}/default", config_dir)))
            .add_source(File::with_name(&format!("{}/{}", config_dir, run_mode)).required(false))
            .add_source(Environment::with_prefix("APP").separator("__"))
            .build()?;

        debug!("{:#?}", s);
        let mut s: Self = s.try_deserialize::<Settings>()
            .map_err(DockManagerError::from)?;

        if let Some(ref mut path) = s.logging.path {
            *path = env::current_dir()?.join(path.clone());
        }

        s.batch_size = 1;

        Ok(s)
    }

    pub fn get_plant(&self, plant_id: &str) -> Option<&PlantSettings> {
        self.plants.iter().find(|plant| plant.plant_id == plant_id)
    }
}

/// Helper struct for deserializing secret strings from configuration
#[derive(Debug,Clone, Deserialize)]
struct SecretString(Option<String>);

impl From<SecretString> for Secret<Option<String>> {
    fn from(secret: SecretString) -> Self {
        Secret::new(secret.0)
    }
}

/// Deserializes a secret string from configuration into a `Secret<String>`
fn deserialize_optional_secret<'de, D>(deserializer: D) -> Result<Option<Secret<String>>, D::Error>
    where
        D: serde::Deserializer<'de>,
{
    let opt: Option<String> = Option::deserialize(deserializer)?;
    Ok(opt.map(Secret::new))
}

impl fmt::Display for DatabaseSettings {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(
            f,
            "DatabaseSettings {{ host: {}, port: {}, username: {:?}, database_name: {}, app_name: {}, win_auth: {}, trusted: {} }}",
            self.host, self.port, self.username, self.database_name, self.app_name, self.win_auth, self.trusted
        )
    }
}

impl fmt::Display for LgvWmsDatabaseSettings {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(
            f,
            "LgvWmsDatabaseSettings {{ host: {}, port: {}, username: {:?}, database_name: {}, app_name: {}, win_auth: {}, trusted: {} }}",
            self.host, self.port, self.username, self.database_name, self.app_name, self.win_auth, self.trusted
        )
    }
}```

--------------------------------------------------------------------------------

# src\errors.rs
```
/// # Dock Manager Errors
/// This module defines the `DockManagerError` enum, which encapsulates all potential errors that can occur within the IQX Dock Manager application.
/// The enum variants provide specific error types for different components and operations, facilitating clear error handling and reporting throughout the application.


use thiserror::Error;
use sqlx_oldapi::Error as SqlxError;
use std::io;
use plctag::Status as PlcTagStatus;
use tokio::sync::mpsc::error::SendError;
use tokio::sync::oneshot::error::RecvError;

#[derive(Error, Debug)]
pub enum DockManagerError {
    /// Represents errors originating from database interactions.
    #[error("Database error: {0}")]
    DatabaseError(#[from] SqlxError),

    /// Represents errors related to establishing or maintaining connections (e.g., to PLCs or databases).
    #[error("Connection error: {0}")]
    ConnectionError(String),

    /// Represents errors occurring during communication with PLCs.
    #[error("PLC communication error: {0}")]
    PlcError(String),

    /// Represents errors specifically related to PLC tags.
    #[error("PLC Tag error: {0}")]
    PlcTagError(PlcTagStatus),

    /// Represents errors arising from misconfigurations or invalid settings.
    #[error("Configuration error: {0}")]
    ConfigError(String),

    /// Represents errors occurring within the state management component.
    #[error("State management error: {0}")]
    StateError(String),

    /// Represents standard input/output errors.
    #[error("I/O error: {0}")]
    IoError(#[from] io::Error),

    /// Represents errors encountered during sensor polling operations.
    #[error("Sensor polling error: {0}")]
    SensorPollingError(String),

    /// Represents errors that happen while processing events.
    #[error("Event processing error: {0}")]
    EventProcessingError(String),

    /// Represents errors during the initialization of the logging system.
    #[error("Logging initialization error: {0}")]
    LoggingError(String),

    /// Represents errors that occur during serialization or deserialization of data.
    #[error("Serialization error: {0}")]
    SerializationError(#[from] serde_json::Error),

    /// Represents errors when waiting for tasks to complete.
    #[error("Task join error: {0}")]
    TaskJoinError(String),

    /// Represents errors specifically related to reading sensor data.
    #[error("Sensor read error: {0}")]
    SensorReadError(String),

    /// Represents an error when a requested door is not found.
    #[error("Door not found: {0}")]
    DoorNotFound(String),

    /// Represents errors when sending data over a channel.
    #[error("Channel send error: {0}")]
    ChannelSendError(String),

    /// Represents errors when receiving data from a channel.
    #[error("Channel receive error: {0}")]
    ChannelRecvError(String),

    #[error("Plant not found: {0}")]
    PlantNotFound(String),
}

impl<T> From<SendError<T>> for DockManagerError {
    fn from(err: SendError<T>) -> Self {
        DockManagerError::ChannelSendError(err.to_string())
    }
}

impl From<RecvError> for DockManagerError {
    fn from(err: RecvError) -> Self {
        DockManagerError::ChannelRecvError(err.to_string())
    }
}


impl From<config::ConfigError> for DockManagerError {
    fn from(err: config::ConfigError) -> Self {
        DockManagerError::ConfigError(err.to_string())
    }
}

pub type DockManagerResult<T> = Result<T, DockManagerError>;

impl From<String> for DockManagerError {
    fn from(err: String) -> Self {
        DockManagerError::PlcError(err)
    }
}

impl From<PlcTagStatus> for DockManagerError {
    fn from(status: PlcTagStatus) -> Self {
        DockManagerError::PlcTagError(status)
    }
}```

--------------------------------------------------------------------------------

# src\init.rs
```
use std::path::PathBuf;
use std::sync::Arc;
use anyhow::Result;
use crate::alerting::alert_manager::{AlertConfig, AlertManager};
use crate::analysis::create_default_analyzer;
use crate::config::Settings;
use crate::controllers::dock_door::DockDoorController;
use crate::event_handling::EventHandler;
use crate::monitoring::{MonitoringQueue, MonitoringWorker};
use crate::rules::{DynamicRuleManager, WmsShipmentStatus};
use crate::services::db::DatabaseService;
use crate::services::PlcService;
use crate::state_management::DockDoorStateManager;


pub struct AppContext {
    pub settings: Arc<Settings>,
    pub plc_service: PlcService,
    pub alert_manager: Arc<AlertManager>,
    pub db_service: DatabaseService,
    pub state_manager: Arc<DockDoorStateManager>,
    pub event_handler: Arc<EventHandler>,
    pub dock_door_controller: Arc<DockDoorController>,
    pub monitoring_worker: MonitoringWorker,
}

pub async fn initialize() -> Result<AppContext> {
    let settings = Settings::new()?;

    let plc_service = PlcService::new();
    let alert_config = AlertConfig {
        suspended_door: settings.alerts.suspended_door.clone(),
        trailer_pattern: settings.alerts.trailer_pattern.clone(),
        long_loading_start: settings.alerts.long_loading_start.clone(),
        shipment_started_load_not_ready: settings.alerts.shipment_started_load_not_ready.clone(),
        trailer_hostage: settings.alerts.trailer_hostage.clone(),
        trailer_docked: settings.alerts.trailer_docked.clone(),
        dock_ready: settings.alerts.dock_ready.clone(),
        trailer_undocked: settings.alerts.trailer_undocked.clone(),
    };

    let webhook_url = settings.plants.first()
        .map(|plant| plant.alert_webhook_url.clone())
        .ok_or_else(|| anyhow::anyhow!("No plants configured"))?;

    let alert_manager = Arc::new(AlertManager::new(
        Arc::new(alert_config),
        webhook_url
    ));

    let db_service = DatabaseService::new(settings.clone())
        .await
        .map_err(|e| anyhow::anyhow!("Failed to create DatabaseService: {}", e))?;

    let rule_manager = DynamicRuleManager::new(PathBuf::from("src/config/rules.json"));
    let rules = rule_manager.load_rules().expect("Failed to load rules");

    let mut context_analyzer = create_default_analyzer();
    for rule in rules {
        context_analyzer.add_rule(rule);
    }
    context_analyzer.add_rule(Arc::new(WmsShipmentStatus));

    let monitoring_queue = Arc::new(MonitoringQueue::new());

    let (state_manager, event_receiver) = DockDoorStateManager::new(&settings, Arc::new(db_service.clone())).await;
    let event_handler = EventHandler::new(
        event_receiver,
        state_manager.get_door_repository(),
        Arc::new(context_analyzer),
        Arc::clone(&alert_manager),
        Arc::clone(&monitoring_queue),
        Arc::new(db_service.clone()),
    );

    let dock_door_controller = Arc::new(DockDoorController::new(
        settings.clone(),
        plc_service.clone(),
        Arc::new(state_manager.clone()),
        Arc::new(event_handler.clone()),
        db_service.clone(),
    ));

    let monitoring_worker = MonitoringWorker::new(
        Arc::clone(&monitoring_queue),
        state_manager.get_door_repository(),
        Arc::clone(&alert_manager),
        settings.clone(),
    );



    Ok(AppContext {
        settings: Arc::new(settings),
        plc_service,
        alert_manager,
        db_service,
        state_manager: Arc::new(state_manager),
        event_handler: Arc::new(event_handler),
        dock_door_controller,
        monitoring_worker,
    })
}```

--------------------------------------------------------------------------------

# src\lib.rs
```
pub mod errors;
pub mod state_management;
pub mod services;
pub mod utils;
pub mod models;
pub mod config;
pub mod controllers;
pub mod analysis;
pub mod rules;
pub mod repositories;
pub mod event_handling;
pub mod alerting;
pub mod monitoring;
pub mod init;```

--------------------------------------------------------------------------------

# src\main.rs
```
use std::error::Error;
use std::sync::Arc;
use std::time::Duration;
use anyhow::Result;
use log::{error, info};
use tokio::signal::ctrl_c;
use tokio::time::interval;
use iqx_dockmonitor::alerting::alert_manager::{Alert, AlertType};
use iqx_dockmonitor::init;

#[tokio::main]
async fn main() {
    init_logger().expect("Failed to initialize logger");
    if let Err(e) = run().await {
        eprintln!("Application error: {}", e);
        std::process::exit(1);
    }
}

fn init_logger() -> Result<(), Box<dyn Error>> {
    log4rs::init_file("src/config/log4rs.yaml", Default::default())?;
    Ok(())
}

async fn run() -> Result<()> {
    let context = Arc::new(init::initialize().await?);

    // Spawn PLC polling task
    let plc_context = Arc::clone(&context);
    tokio::spawn(async move {
        let mut interval = interval(Duration::from_secs(20));
        loop {
            interval.tick().await;
            info!("Starting new PLC polling cycle...");
            if let Err(e) = plc_context.dock_door_controller.run_polling_cycle().await {
                error!("Error during PLC polling cycle: {}", e);
            }
        }
    });

    // Spawn WMS event polling task
    let wms_event_context = Arc::clone(&context);
    tokio::spawn(async move {
        let mut interval = interval(Duration::from_secs(60));
        loop {
            interval.tick().await;
            info!("Starting WMS event polling cycle...");
            if let Err(e) = wms_event_context.dock_door_controller.update_wms_events().await {
                error!("Error during WMS event update cycle: {}", e);
            }
        }
    });

    // Spawn WMS door status polling task
    let wms_door_context = Arc::clone(&context);
    tokio::spawn(async move {
        let mut interval = interval(Duration::from_secs(25));
        loop {
            interval.tick().await;
            info!("Starting WMS door status polling cycle...");
            if let Err(e) = wms_door_context.dock_door_controller.update_wms_door_status().await {
                error!("Error during WMS door status update cycle: {}", e);
            }
        }
    });

    // Hourly rack space utilization check
    let rack_space_context = Arc::clone(&context);
    tokio::spawn(async move {
        let mut interval = interval(Duration::from_secs(3600));
        loop {
            interval.tick().await;
            info!("Starting rack space utilization check...");
            for plant in &rack_space_context.settings.plants {
                let plant_id = &plant.plant_id;
                match rack_space_context.db_service.fetch_empty_rack_count(plant_id).await {
                    Ok(count) => {
                        if count < 9 {
                            let alert = Alert::new(AlertType::RackSpace, "RackSpace".to_string())
                                .add_info("plant".to_string(), plant_id.clone())
                                .add_info("empty_spaces".to_string(), count.to_string())
                                .build();
                            if let Err(e) = rack_space_context.alert_manager.handle_alert(alert).await {
                                error!("Failed to send rack space alert: {:?}", e);
                            }
                        } else {
                            let alert = Alert::new(AlertType::RackSpace, "RackSpace".to_string())
                                .add_info("info".to_string(), "true".to_string())
                                .add_info("plant".to_string(), plant_id.clone())
                                .add_info("empty_spaces".to_string(), count.to_string())
                                .build();
                            if let Err(e) = rack_space_context.alert_manager.handle_alert(alert).await {
                                error!("Failed to send rack space alert: {:?}", e);
                            }
                        }
                    },
                    Err(e) => {
                        error!("Error fetching rack space count for plant {}: {:?}", plant_id, e);
                    }
                }
            }
        }
    });

    // Spawn EventHandler task
    let event_handler_context = Arc::clone(&context);
    tokio::spawn(async move {
        if let Err(e) = event_handler_context.event_handler.run().await {
            error!("EventHandler error: {:?}", e);
        }
    });

    // Spawn MonitoringWorker task
    let monitoring_context = Arc::clone(&context);
    tokio::spawn(async move {
        monitoring_context.monitoring_worker.run().await;
    });

    // Wait for shutdown signal
    ctrl_c().await?;
    info!("Received shutdown signal. Shutting down gracefully...");

    Ok(())
}```

--------------------------------------------------------------------------------

# src\alerting\alert_manager.rs
```
use std::collections::{HashMap, HashSet};
use std::fmt;
use std::sync::Arc;
use chrono::{Duration, Local, NaiveDateTime};
use reqwest::Client;
use serde_json::json;
use tokio::sync::Mutex;
use log::{info, error};
use crate::config::AlertThresholds;
use crate::utils::format_duration;

/// Configuration for alert thresholds and repeat intervals
pub struct AlertConfig {
    pub suspended_door: AlertThresholds,
    pub trailer_pattern: AlertThresholds,
    pub long_loading_start: AlertThresholds,
    pub shipment_started_load_not_ready: AlertThresholds,
    pub trailer_hostage: AlertThresholds,
    pub trailer_docked: AlertThresholds,
    pub dock_ready: AlertThresholds,
    pub trailer_undocked: AlertThresholds,
}

/// Threshold configuration for a specific alert type
pub struct AlertThreshold {
    pub repeat_interval: u64,
}

/// Represents different types of alerts that can be generated by the system
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum AlertType {
    SuspendedDoor,
    TrailerPatternIssue,
    LongLoadingStart,
    ShipmentStartedLoadNotReady,
    ManualModeAlert,
    ManualInterventionTimeout,
    NewShipmentPreviousTrailerPresent,
    TrailerHostage,
    TrailerDockedNotStarted,
    TrailerDocked,
    DockReady,
    TrailerUndocked,
    RackSpace
}

/// Represents an alert with all its associated information
#[derive(Debug, Clone)]
pub struct Alert {
    alert_type: AlertType,
    door_name: String,
    shipment_id: Option<String>,
    duration: Option<Duration>,
    additional_info: HashMap<String, String>,
}

/// Builder for creating Alert instances
pub struct AlertBuilder {
    alert: Alert,
}

impl Alert {
    /// Creates a new AlertBuilder instance
    ///
    /// # Arguments
    ///
    /// * `alert_type` - The type of the alert
    /// * `door_name` - The name of the door associated with the alert
    ///
    /// # Returns
    ///
    /// An AlertBuilder instance
    pub fn new(alert_type: AlertType, door_name: String) -> AlertBuilder {
        AlertBuilder {
            alert: Alert {
                alert_type,
                door_name,
                shipment_id: None,
                duration: None,
                additional_info: HashMap::new(),
            }
        }
    }
}

impl AlertBuilder {
    /// Sets the shipment ID for the alert
    pub fn shipment_id(mut self, shipment_id: String) -> Self {
        self.alert.shipment_id = Some(shipment_id);
        self
    }

    /// Sets the duration for the alert
    pub fn duration(mut self, duration: Duration) -> Self {
        self.alert.duration = Some(duration);
        self
    }

    /// Adds additional information to the alert
    pub fn add_info(mut self, key: String, value: String) -> Self {
        self.alert.additional_info.insert(key, value);
        self
    }

    /// Builds and returns the Alert instance
    pub fn build(self) -> Alert {
        self.alert
    }
}

impl fmt::Display for Alert {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let base_msg = match self.alert_type {
            AlertType::SuspendedDoor => format!("ðŸš¨ SUSPENDED DOOR ALERT: Door {} has been suspended", self.door_name),
            AlertType::TrailerPatternIssue => format!("âš ï¸ TRAILER PATTERN ISSUE: Door {}", self.door_name),
            AlertType::LongLoadingStart => format!("â³ LONG LOADING START: Door {}", self.door_name),
            AlertType::ShipmentStartedLoadNotReady => format!("ðŸ›‘ SHIPMENT STARTED LOAD NOT READY: Door {}", self.door_name),
            AlertType::ManualModeAlert => format!("ðŸ”§ MANUAL MODE ALERT: Door {}", self.door_name),
            AlertType::ManualInterventionTimeout => format!("â° MANUAL INTERVENTION TIMEOUT: Door {}", self.door_name),
            AlertType::NewShipmentPreviousTrailerPresent => format!("ðŸš› NEW SHIPMENT, PREVIOUS TRAILER PRESENT: Door {}", self.door_name),
            AlertType::TrailerHostage => format!("ðŸš¨ TRAILER HOSTAGE ALERT: Door {}", self.door_name),
            AlertType::TrailerDockedNotStarted => format!("â³ TRAILER DOCKED NOT STARTED: Door {}", self.door_name),
            AlertType::TrailerDocked => {
                let success = self.additional_info.get("success").unwrap().parse::<bool>().unwrap();

                if success {
                    format!(
                        "ðŸš› TRAILER DOCKED: Door {}",
                        self.door_name
                    )
                } else {
                    format!(
                        "âš ï¸ TRAILER DOCKING FAILED: Door {}",
                        self.door_name
                    )
                }
            },
            AlertType::DockReady => format!("âœ… DOCK READY: Door {}", self.door_name),
            AlertType::TrailerUndocked => format!("ðŸšš TRAILER UNDOCKED: Door {}", self.door_name),
            AlertType::RackSpace => {
                let send_info = self.additional_info.get("info");
                if send_info.is_none() {
                    let plant = self.additional_info.get("plant").map_or("Unknown", |s| s);
                    format!("ðŸš¨ LOW RACK SPACE ALERT: Plant {}", plant)
                } else {
                    let plant = self.additional_info.get("plant").map_or("Unknown", |s| s);
                    format!("âœ…âœ… RACK SPACE GOOD!: Plant {}", plant)
                }

            },
        };

        let mut full_msg = base_msg;
        if let Some(shipment_id) = &self.shipment_id {
            full_msg.push_str(&format!(" - Shipment ID: {}", shipment_id));
        }
        if let Some(duration) = self.duration {
            full_msg.push_str(&format!(" - Duration: {}", format_duration(&duration)));
        }
        for (key, value) in &self.additional_info {
            if key != "plant" || self.alert_type != AlertType::RackSpace {
                if key.contains("timestamp") {
                    if let Ok(val) = NaiveDateTime::parse_from_str(value, "%Y-%m-%d %H:%M:%S%.f") {
                        full_msg.push_str(&format!(" - {}: {}", key, val.format("%Y-%m-%d %H:%M:%S")));
                    } else {
                        full_msg.push_str(&format!(" - {}: {}", key, value));
                    }
                } else {
                    full_msg.push_str(&format!(" - {}: {}", key, value));
                }
            }
        }

        write!(f, "{}", full_msg)
    }
}

/// Error types specific to alert operations
#[derive(Debug, thiserror::Error)]
pub enum AlertError {
    #[error("Failed to send alert: {0}")]
    SendFailure(String),
    #[error("Invalid alert configuration: {0}")]
    InvalidConfig(String),
}

type AlertResult<T> = Result<T, AlertError>;

const DEFAULT_REPEAT_INTERVAL: u64 = 300; // 5 minutes

/// Manages the creation and sending of alerts
pub struct AlertManager {
    settings: Arc<AlertConfig>,
    client: Client,
    alert_cooldown: Arc<Mutex<HashMap<String, NaiveDateTime>>>,
    monitored_alert_types: HashSet<AlertType>,
    webhook_url: String,
}

impl AlertManager {
    /// Creates a new AlertManager instance
    ///
    /// # Arguments
    ///
    /// * `settings` - Alert configuration settings
    /// * `webhook_url` - URL for sending alert webhooks
    ///
    /// # Returns
    ///
    /// A new AlertManager instance
    pub fn new(settings: Arc<AlertConfig>, webhook_url: String) -> Self {
        info!("Initializing Alert Manager");
        let client = Client::new();
        let alert_cooldown = Arc::new(Mutex::new(HashMap::new()));
        let mut monitored_alert_types = HashSet::new();
        monitored_alert_types.insert(AlertType::SuspendedDoor);
        monitored_alert_types.insert(AlertType::TrailerDockedNotStarted);
        monitored_alert_types.insert(AlertType::ShipmentStartedLoadNotReady);

        Self {
            settings,
            client,
            alert_cooldown,
            monitored_alert_types,
            webhook_url,
        }
    }

    /// Handles an incoming alert
    ///
    /// # Arguments
    ///
    /// * `alert` - The alert to handle
    ///
    /// # Returns
    ///
    /// A Result indicating success or failure
    pub async fn handle_alert(&self, alert: Alert) -> AlertResult<()> {
        info!("Handling Alert: {:#?}", alert);

        let (cooldown_key, repeat_interval) = match alert.alert_type {
            AlertType::SuspendedDoor => (
                format!("suspended_door_{}", alert.door_name),
                self.settings.suspended_door.repeat_interval,
            ),
            AlertType::TrailerPatternIssue => (
                format!("trailer_pattern_{}", alert.door_name),
                self.settings.trailer_pattern.repeat_interval,
            ),
            AlertType::LongLoadingStart => (
                format!("long_loading_start_{}", alert.door_name),
                self.settings.long_loading_start.repeat_interval,
            ),
            AlertType::ShipmentStartedLoadNotReady => (
                format!("shipment_started_load_not_ready_{}", alert.door_name),
                self.settings.shipment_started_load_not_ready.repeat_interval,
            ),
            AlertType::TrailerHostage => (
                format!("trailer_hostage_{}", alert.door_name),
                self.settings.trailer_hostage.repeat_interval,
            ),
            AlertType::TrailerDocked => (
                format!("trailer_docked_{}", alert.door_name),
                self.settings.trailer_docked.repeat_interval,
            ),
            AlertType::DockReady => (
                format!("dock_ready_{}", alert.door_name),
                self.settings.dock_ready.repeat_interval,
            ),
            AlertType::TrailerUndocked => (
                format!("trailer_undocked_{}", alert.door_name),
                self.settings.trailer_undocked.repeat_interval,
            ),
            _ => (
                format!("default_{}", alert.door_name),
                DEFAULT_REPEAT_INTERVAL,
            ),
        };

        if self.monitored_alert_types.contains(&alert.alert_type) {
            info!("Sending monitored alert: {:?}", alert.alert_type);
            self.send_alert(&alert).await?;
        } else if self.check_cooldown(&cooldown_key, repeat_interval).await {
            info!("Sending alert: {:?}", alert);
            self.send_alert(&alert).await?;
            self.update_cooldown(cooldown_key).await;
        }

        Ok(())
    }

    /// Sends an alert
    ///
    /// # Arguments
    ///
    /// * `alert` - The alert to send
    ///
    /// # Returns
    ///
    /// A Result indicating success or failure
    async fn send_alert(&self, alert: &Alert) -> AlertResult<()> {
        let alert_message = alert.to_string();

        let response = self.client.post(&self.webhook_url)
            .json(&json!({
                "text": alert_message
            }))
            .send()
            .await
            .map_err(|e| AlertError::SendFailure(e.to_string()))?;

        if response.status().is_success() {
            info!("Alert sent successfully: {:?}", alert);
            Ok(())
        } else {
            error!("Failed to send alert: {:?}", alert);
            Err(AlertError::SendFailure("Failed to send alert".to_string()))
        }
    }

    /// Checks if an alert should be sent based on the cooldown period
    ///
    /// # Arguments
    ///
    /// * `key` - The key identifying the alert
    /// * `repeat_interval` - The minimum time between alerts
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the alert should be sent
    async fn check_cooldown(&self, key: &str, repeat_interval: u64) -> bool {
        let cooldown_map = self.alert_cooldown.lock().await;
        if let Some(last_sent) = cooldown_map.get(key) {
            let now = Local::now().naive_local();
            now.signed_duration_since(*last_sent) > Duration::seconds(repeat_interval as i64)
        } else {
            true
        }
    }

    /// Updates the cooldown time for an alert
    ///
    /// # Arguments
    ///
    /// * `alert_key` - The key identifying the alert
    async fn update_cooldown(&self, alert_key: String) {
        let mut cooldown_map = self.alert_cooldown.lock().await;
        cooldown_map.insert(alert_key, Local::now().naive_local());
    }
}
```

--------------------------------------------------------------------------------

# src\alerting\mod.rs
```
pub mod alert_manager;```

--------------------------------------------------------------------------------

# src\analysis\context_analyzer.rs
```
use chrono::{Duration, NaiveDateTime};
use std::sync::Arc;
use serde::{Deserialize, Serialize};

use crate::models::{DoorState, DockDoorEvent, DockDoor, DbInsert};
use crate::models::consolidated_dock_event::ConsolidatedDockEvent;

/// The result of applying an analysis rule to a dock door event
#[derive(Debug, Clone)]
pub enum AnalysisResult {
    /// An alert to be triggered, with the specific alert type
    Alert(AlertType),
    /// A state transition for the dock door
    StateTransition(DoorState),
    /// A log entry to be recorded
    Log(LogEntry),
    /// A database insert operation to be performed
    DbInsert(DbInsert),
    ConsolidatedEvent(ConsolidatedDockEvent),

}

/// The different types of alerts that can be generated by analysis rules
#[derive(Debug, Clone)]
pub enum AlertType {
    /// The docking time has exceeded a defined threshold
    LongDockingTime(Duration),
    /// Manual intervention was required
    ManualIntervention,
    /// A trailer is being held hostage at the dock
    TrailerHostage {
        door_name: String,
        shipment_id: Option<String>,
        duration: Duration,
    },
    /// A trailer is departing under unsafe conditions
    UnsafeDeparture,
    /// Manual mode has been activated while a trailer is at the door
    ManualModeAlert {
        door_name: String,
        shipment_id: Option<String>,
    },
    /// A new shipment is assigned while the previous trailer is still present
    NewShipmentPreviousTrailerPresent {
        dock_name: String,
        new_shipment: String,
        previous_shipment: Option<String>,
        timestamp: NaiveDateTime
    },
    /// Manual intervention has timed out without resolving the issue
    ManualInterventionTimeout {
        dock_name: String,
        shipment_id: String,
        start_time: NaiveDateTime,
        end_time: NaiveDateTime
    },
    /// A door has been suspended for an extended period
    SuspendedDoor {
        door_name: String,
        duration: Duration,
        shipment_id: Option<String>,
        user: String
    },
    /// A loading process has taken too long to start
    LongLoadingStart {
        door_name: String,
        shipment_id: String,
        duration: Duration,
    },
    /// A shipment has started loading but the dock is not ready
    ShipmentStartedLoadNotReady {
        door_name: String,
        shipment_id: String,
        reason: String,
    },
    /// A trailer pattern issue has been detected
    TrailerPatternIssue {
        door_name: String,
        issue: String,
        severity: i32,
        shipment_id: Option<String>,
    },
    /// A trailer has been docked but loading hasn't started
    TrailerDockedNotStarted {
        door_name: String,
        duration: Duration,
    },
    TrailerDocked {
        door_name: String,
        shipment_id: Option<String>,
        timestamp: NaiveDateTime,
        success: bool,
        failure_reason: Option<String>,
    },
    DockReady {
        door_name: String,
        shipment_id: Option<String>,
        timestamp: NaiveDateTime,
    },
    TrailerUndocked {
        door_name: String,
        shipment_id: Option<String>,
        timestamp: NaiveDateTime,
    },
}

/// Represents different types of log entries that can be generated by analysis rules
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum LogEntry {
    /// Logs the docking time for a shipment
    DockingTime {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs the activation of manual mode for a dock door
    ManualModeActivated {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a change in the loading status of a shipment
    LoadingStatusChange {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs when a shipment is unassigned from a door
    ShipmentUnassigned {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs when a shipment is assigned to a door
    ShipmentAssigned {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs when a new shipment is assigned to a door while the previous trailer is still present
    NewShipmentPreviousTrailerPresent {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs the start of a manual intervention on a dock door
    ManualInterventionStarted {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a successful manual intervention on a dock door
    ManualInterventionSuccess {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a failed manual intervention on a dock door
    ManualInterventionFailure {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a change in the trailer's state at a dock door
    TrailerStateChange {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a suspended door event
    SuspendedDoor {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a long loading start event
    LongLoadingStart {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a trailer hostage event
    TrailerHostage {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a shipment started but load not ready event
    ShipmentStartedLoadNotReady {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    /// Logs a trailer pattern issue event
    TrailerPatternIssue {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    TrailerUndocked {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
    },
    WmsEvent {
        log_dttm: NaiveDateTime,
        plant: String,
        door_name: String,
        shipment_id: Option<String>,
        event_type: String,
        success: bool,
        notes: String,
        severity: i32,
        previous_state: Option<String>,
        previous_state_dttm: Option<NaiveDateTime>,
        message_source: String,
        result_code: i32,
    },
}

/// Defines the interface for analysis rules that can be applied to dock door events
pub trait AnalysisRule: Send + Sync {
    /// Applies the analysis rule to a dock door and an event, potentially generating `AnalysisResult`s
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult>;
}

/// Analyzes dock door events in context using a set of rules
#[derive(Default, Clone)]
pub struct ContextAnalyzer {
    /// The collection of analysis rules to apply
    rules: Vec<Arc<dyn AnalysisRule>>,
}

impl ContextAnalyzer {
    /// Creates a new `ContextAnalyzer` with no rules initially
    pub fn new() -> Self {
        ContextAnalyzer { rules: Vec::new() }
    }

    /// Adds an analysis rule to the analyzer
    pub fn add_rule(&mut self, rule: Arc<dyn AnalysisRule>) {
        self.rules.push(rule);
    }

    /// Analyzes a dock door event using the registered rules
    pub async fn analyze(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        let results: Vec<AnalysisResult>  = self.rules
            .iter()
            .flat_map(|rule| {
                let rule_results = rule.apply(dock_door, event);
                rule_results
            })
            .collect();
        results
    }
}

/// Creates a default `ContextAnalyzer` with no rules
pub fn create_default_analyzer() -> ContextAnalyzer {
    ContextAnalyzer::new()
}```

--------------------------------------------------------------------------------

# src\analysis\mod.rs
```
pub mod context_analyzer;

pub use context_analyzer::*;```

--------------------------------------------------------------------------------

# src\config\default.yaml
```
database:
  host: "RCH-WHSE-TEST"
  port: 1433
  username: "TOAD"
  password: "1234"
  database_name: "RCH-E80-REP-DB"
  app_name: "ChazWilder-IQXDockManager2"
  win_auth: false
  trusted: false

batch_size: 1
plc:
  poll_interval_secs: 10
  timeout_ms: 5000
  max_retries: 3

alerts:
  suspended_door:
    initial_threshold: 300
    repeat_interval: 600
  trailer_pattern:
    initial_threshold: 0
    repeat_interval: 300
  long_loading_start:
    initial_threshold: 600
    repeat_interval: 300
  shipment_started_load_not_ready:
    initial_threshold: 60
    repeat_interval: 300
  trailer_hostage:
    initial_threshold: 300
    repeat_interval: 300
  trailer_docked:
    initial_threshold: 0
    repeat_interval: 300
  dock_ready:
    initial_threshold: 0
    repeat_interval: 300
  trailer_undocked:
    initial_threshold: 0
    repeat_interval: 300

monitoring:
  check_interval: 60
  suspended_shipment:
    alert_threshold: 0
    repeat_interval: 240
  trailer_docked_not_started:
    alert_threshold: 240
    repeat_interval: 240
  shipment_started_load_not_ready:
    alert_threshold: 300
    repeat_interval: 120
  trailer_hostage:
    alert_threshold: 60
    repeat_interval: 240


logging:
  level: "info"
  file: "iqx-dm.log"
  path: "src/logs"

rabbitmq:
  host: "10.193.1.235"
  port: 5672
  username: "apps"
  password: "apps@123"
  exchange: "dock_events"
  vhost: "%2f"

queries:
  wms_door_status: |
    SELECT '{|}' as PLANT, 
          SD.Name as dock_name,
          SS.ShipmentNumber as assigned_shipment,
          SS.StagingProgressPercentage as loading_progress_percent,
          CASE
            WHEN SSS.CODE IS NULL THEN 'Idle'
            WHEN SSS.CODE IN ('WaitingInfo', 'NewOrder', 'WaitQtyCheck', 'WaitDockCnfrm', 'Scheduled') THEN 'CSO'
            WHEN SSS.CODE IN ('WaitStartCnfrm') THEN 'WhseInspection'
            WHEN SSS.CODE IN ('Allocating', 'EnqueuedToStart') THEN 'LgvAllocation'
            WHEN SSS.CODE IN ('Started') THEN 'Loading'
            WHEN SSS.CODE IN ('Staged') THEN 'Completed'
            WHEN SSS.CODE IN ('Shipped') THEN 'WaitingForExit'
            WHEN SSS.CODE IN ('Suspending', 'Suspended') THEN 'Suspended'
            WHEN SSS.CODE IN ('Deleting', 'Deleted') THEN 'CancelledShipment'
            WHEN SSS.CODE IN ('StartedWithAnticipationInProgress') THEN 'StartedWithAnticipation'
          END AS loading_status,
          SSS.Code as wms_shipment_status,
    SFC.Name AS shipping_fault_code,
    CAST(MAX_SHP.Value as INT) AS upper_ship_limit,
    SUM(IIF(SSS.Code = 'Started', 1,0)) OVER (PARTITION BY 1) AS shipments_loading,
    COALESCE(IsPreLoadShipment,PreLoadOverride,PreLoadFromSoa) as is_preload
    FROM [Shipping].[Dock] AS SD
    LEFT JOIN [Shipping].[DockAssignment] DA ON SD.Id = DA.Id_Dock
    LEFT JOIN [Shipping].[Shipment] SS ON DA.Id_Shipment = SS.Id
    LEFT JOIN [Shipping].[ShipmentStatus] SSS ON SS.Id_ShipmentStatus = SSS.Id
    LEFT JOIN [WMS_CC1149_PROD].[Shipping].[FaultCode] SFC ON SS.Id_FaultCode = SFC.Id
    LEFT JOIN [Niagara].[Shipment] NS ON SS.Id = NS.Id_Shipment
    OUTER APPLY (SELECT [Value] FROM [WMS_CC1149_PROD].[Common].[ApplicationSetting]  WHERE Id = 45) AS MAX_SHP
    WHERE Id_DockType != 5
    ORDER BY SD.Name

  wms_events: |
    DECLARE @shipment_number VARCHAR(50) = '{}';
    WITH INT_MESSAGE AS (
        SELECT 
            DATEADD(HOUR, -4, InsertDateTime) AS LOG_DTTM,
            'INTERGRATION_MESSAGES' AS MESSAGE_SOURCE,
            MESSAGETYPE AS MESSAGE_TYPE,
            MessageId AS MESSAGE_TYPE_ID,
            ResultText AS MESSAGE_NOTES,
            ResultCode AS RESULT_CODE
        FROM [RCH-E80-DB].[WMS_CC1149_PROD].[History].[Integration_MAProcessedMessage]
        WHERE InsertDateTime > DATEADD(MINUTE, -2, GETDATE())
        AND MessageText.exist('/payload[
            .//ShipmentNumber[text()=sql:variable("@shipment_number")] or
            .//tripId[text()=sql:variable("@shipment_number")] or
            .//tripName[text()=sql:variable("@shipment_number")]
        ]') = 1
    ), 
    EVENTS_LOG AS (
        SELECT
            EventDateTime AS LOG_DTTM,
            'WMS_EVENTS' AS MESSAGE_SOURCE,
            CASE
                WHEN Message LIKE 'Appointment datetime update for shipment (%' THEN 'APPT_UPDATE'
                WHEN Message LIKE 'User started shipment (%' THEN 'STARTED_SHIPMENT'
                WHEN Message LIKE 'User suspended shipment (%' THEN 'SUSPENDED_SHIPMENT'
                WHEN Message LIKE 'User canceled shipment (%' THEN 'CANCELLED_SHIPMENT'
                  WHEN Message LIKE 'User resumed shipment (%' THEN 'RESUMED_SHIPMENT'
                WHEN Message LIKE 'Shipment %, priority has been updated.' THEN 'UPDATED_PRIORITY'
                WHEN Message LIKE 'User changed priority of shipment (%.' THEN 'UPDATED_PRIORITY'
                WHEN Message LIKE 'User saved load plan for shipment (%.' THEN 'SDM_LOAD_PLAN'
                WHEN Message LIKE 'ShipmentNumber % - Manually Closed ' THEN 'SHIPMENT_FORCED_CLOSED'
                WHEN Message LIKE 'ShipmentNumber % - DeliveryItem % pallets number adjusted %' THEN 'LOAD_QTY_ADJUSTED'
                WHEN Message LIKE 'User checked in for the first time.  TripID %, IDShipment %' THEN 'SDM_CHECK_IN'
                WHEN Message LIKE 'User Reject Trailer For Shipment (Id: %, TripId: %).' THEN 'SDM_TRAILER_REJECTION'
                ELSE 'UNKNOWN'
            END AS MESSAGE_TYPE,
            [Number_Shipment] AS MESSAGE_TYPE_ID,
            CONCAT([UserName], ' - ', [Message]) AS MESSAGE_NOTES,
            0 AS RESULT_CODE
        FROM [RCH-E80-DB].[WMS_CC1149_PROD].[Common].[WmsEvent]
        WHERE Id_Shipment IS NOT NULL
        AND EventDateTime > DATEADD(MINUTE, -2, GETDATE()) 
        AND Number_Shipment = @shipment_number
    ),
    CTE AS (
        SELECT 
            ShipmentNumber,
            SD.Name AS dock_name,
            StagingDateTime,
            StartDateTime,
            FirstDropDateTime,    
            StagedDateTime,
            ShipDateTime
        FROM [RCH-E80-DB].[WMS_CC1149_PROD].[Shipping].[DockAssignment] DA
        LEFT JOIN [RCH-E80-DB].[WMS_CC1149_PROD].[Shipping].[Shipment] SS ON DA.Id_Shipment = SS.Id
        LEFT JOIN [RCH-E80-DB].[WMS_CC1149_PROD].[Shipping].[Dock] AS SD ON DA.Id_Dock = SD.ID
        WHERE ShipmentNumber = @shipment_number
    ), 
    SHIPMENT_LOGS AS (
        SELECT 
            v.LOG_DTTM,
            'SHIPMENT_LOG' AS MESSAGE_SOURCE,
            v.MESSAGE_TYPE,
            CONCAT(ShipmentNumber,'_', dock_name) as MESSAGE_TYPE_ID,
            CASE 
                WHEN v.LOG_DTTM IS NULL THEN CONCAT('PENDING - ', v.MESSAGE_TYPE)
                ELSE CONCAT('Trip number: ', ShipmentNumber, ' - logged ', v.MESSAGE_TYPE, ' at ', FORMAT(v.LOG_DTTM, 'yyyy-MM-dd hh:mm')) 
            END AS MESSAGE_NOTES,
            CASE WHEN v.LOG_DTTM IS NULL THEN 99 ELSE 0 END AS RESULT_CODE
        FROM CTE
        CROSS APPLY (VALUES 
            ('DOCK_ASSIGNMENT', StagingDateTime),
            ('LGV_START_LOADING', StartDateTime),
            ('FIRST_DROP', FirstDropDateTime),
            ('COMPLETED_LOAD', StagedDateTime),
            ('CHECKOUT', ShipDateTime)
        ) v(MESSAGE_TYPE, LOG_DTTM)
    ), 
    SHIPMENT_EVENTS AS (
        SELECT * FROM INT_MESSAGE
        UNION ALL
        SELECT * FROM EVENTS_LOG
        UNION ALL
        SELECT * FROM SHIPMENT_LOGS
    )
    SELECT '{#}' as PLANT, '{|}' as DOCK_NAME, @shipment_number AS SHIPMENT_ID, * FROM SHIPMENT_EVENTS
    WHERE LOG_DTTM  > DATEADD(MINUTE, -1, GETDATE()) 
    AND MESSAGE_TYPE NOT IN ('SU_EXT', 'SHIPCFRM', 'SHP_CTRL', 'TRK_STS')
    ORDER BY CASE 
        WHEN LOG_DTTM IS NULL THEN 1 
        ELSE 0 
    END, LOG_DTTM
  wms_rack_space: |
    SELECT COUNT(1) AS NSR_EMPTY
    FROM [WMS_CC1149_PROD].[Client].[vwLocations]
    WHERE LCID = 1033
    AND LocationPhysicalType = 'Selective Rack'
    AND StorageDisabled = 0
    AND UnitsCount = 0
  check_in_analysis: |
    SELECT *
      ,DATEDIFF(MINUTE, COALESCE(DOCK_ASSIGNMENT, SHIPMENT_ASSIGNED), TRAILER_DOCKING) AS DOCKING_TIME_MINUTES
      ,DATEDIFF(MINUTE, TRAILER_DOCKING, STARTED_SHIPMENT) AS INSPECTION_TIME_MINUTES
      ,DATEDIFF(MINUTE, STARTED_SHIPMENT, LGV_START_LOADING) AS ENQUEUED_TIME_MINUTES
      ,DATEDIFF(SECOND, DOCK_ASSIGNMENT, TRAILER_DOCKING) AS DOCKING_TIME_SECONDS
      ,DATEDIFF(SECOND, TRAILER_DOCKING, STARTED_SHIPMENT) AS INSPECTION_TIME_SECONDS
      ,DATEDIFF(SECOND, STARTED_SHIPMENT, LGV_START_LOADING) AS ENQUEUED_TIME_SECONDS
    FROM (
      SELECT PLANT, DOOR_NAME, SHIPMENT_ID, LOG_DTTM, EVENT_TYPE FROM DOCK_DOOR_EVENTS
      WHERE SHIPMENT_ID = {|}
    ) AS RD
    PIVOT (
      MAX(LOG_DTTM)
      FOR EVENT_TYPE IN (
        SHIPMENT_ASSIGNED,
        DOCK_ASSIGNMENT,
        TRAILER_DOCKING,
        STARTED_SHIPMENT,
        LGV_START_LOADING
      )
    ) AS PVT


plants:
  - RCH:
    plant_id: "RCH"
    alert_webhook_url: "https://prod-145.westus.logic.azure.com:443/workflows/49b0eef72aaa40fc87bc9e9629c44a9b/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=fR-wTBEyXceTBP4rs6kKC_D2TabzIFF20xkY2ySpnfM"

    lgv_wms_database:
      host: "RCH-E80-DB"
      port: 1433
      username: "E80"
      password: "E80Works"
      database_name: "WMS_CC1149_PROD"
      app_name: "ChazWilder-IQXDockManager"
      win_auth: false
      trusted: false
    dock_doors:
      dock_door_config:
        - dock_name: "STAGE.002"
          dock_ip: "10.193.122.101"
        - dock_name: "STAGE.004"
          dock_ip: "10.193.122.102"
        - dock_name: "STAGE.006"
          dock_ip: "10.193.122.103"
        - dock_name: "STAGE.009"
          dock_ip: "10.193.122.104"
        - dock_name: "STAGE.011"
          dock_ip: "10.193.122.105"
        - dock_name: "STAGE.013"
          dock_ip: "10.193.122.106"
        - dock_name: "STAGE.016"
          dock_ip: "10.193.122.107"
        - dock_name: "STAGE.018"
          dock_ip: "10.193.122.108"
        - dock_name: "STAGE.020"
          dock_ip: "10.193.122.109"
        - dock_name: "STAGE.023"
          dock_ip: "10.193.122.110"
        - dock_name: "STAGE.025"
          dock_ip: "10.193.122.111"
        - dock_name: "STAGE.027"
          dock_ip: "10.193.122.112"
        - dock_name: "STAGE.030"
          dock_ip: "10.193.122.113"
        - dock_name: "STAGE.032"
          dock_ip: "10.193.122.114"
        - dock_name: "STAGE.034"
          dock_ip: "10.193.122.115"
        - dock_name: "STAGE.037"
          dock_ip: "10.193.122.116"
        - dock_name: "STAGE.039"
          dock_ip: "10.193.122.117"
        - dock_name: "STAGE.041"
          dock_ip: "10.193.122.118"
        - dock_name: "STAGE.044"
          dock_ip: "10.193.122.119"
        - dock_name: "STAGE.046"
          dock_ip: "10.193.122.120"
        - dock_name: "STAGE.048"
          dock_ip: "10.193.122.121"
        - dock_name: "STAGE.051"
          dock_ip: "10.193.122.122"
        - dock_name: "STAGE.053"
          dock_ip: "10.193.122.123"
        - dock_name: "STAGE.055"
          dock_ip: "10.193.122.124"
        - dock_name: "STAGE.058"
          dock_ip: "10.193.122.125"
        - dock_name: "STAGE.060"
          dock_ip: "10.193.122.126"
        - dock_name: "STAGE.062"
          dock_ip: "10.193.122.127"
        - dock_name: "STAGE.065"
          dock_ip: "10.193.122.128"
        - dock_name: "STAGE.067"
          dock_ip: "10.193.122.129"
        - dock_name: "STAGE.069"
          dock_ip: "10.193.122.130"
        - dock_name: "STAGE.072"
          dock_ip: "10.193.122.131"
        - dock_name: "STAGE.074"
          dock_ip: "10.193.122.132"
        - dock_name: "STAGE.076"
          dock_ip: "10.193.122.133"
        - dock_name: "STAGE.079"
          dock_ip: "10.193.122.134"

      dock_plc_tags:
        - tag_name: "AUTO_DISENGAGING"
          address: "B9:0/6"
        - tag_name: "AUTO_ENGAGING"
          address: "B9:0/7"
        - tag_name: "FAULT_PRESENCE"
          address: "B9:1/2"
        - tag_name: "FAULT_TRAILER_DOORS"
          address: "B9:1/3"
        - tag_name: "RH_DOCK_READY"
          address: "B9:0/12"
        - tag_name: "RH_DOKLOCK_FAULT"
          address: "B9:1/1"
        - tag_name: "RH_DOOR_FAULT"
          address: "B9:0/15"
        - tag_name: "RH_DOOR_OPEN"
          address: "B9:0/9"
        - tag_name: "RH_ESTOP"
          address: "B9:1/9"
        - tag_name: "RH_LEVELER_FAULT"
          address: "B9:1/0"
        - tag_name: "RH_LEVELR_READY"
          address: "B9:0/10"
        - tag_name: "RH_MANUAL_MODE"
          address: "B9:1/4"
        - tag_name: "RH_RESTRAINT_ENGAGED"
          address: "B9:0/13"
        - tag_name: "TRAILER_ANGLE"
          address: "B9:1/6"
        - tag_name: "TRAILER_AT_DOOR"
          address: "B9:1/5"
        - tag_name: "TRAILER_CENTERING"
          address: "B9:1/7"
        - tag_name: "TRAILER_DISTANCE"
          address: "B9:1/8"```

--------------------------------------------------------------------------------

# src\config\log4rs.yaml
```
refresh_rate: 10 seconds

appenders:
  console:
    kind: console
    encoder:
      pattern: "{d(%Y-%m-%d %H:%M:%S%.3f)} {h({l})} [{t}] {m}{n}"

  main_log:
    kind: rolling_file
    path: "src/logs/main.log"
    encoder:
      pattern: "{d(%Y-%m-%d %H:%M:%S%.3f)} {l} [{t}] {m}{n}"
    policy:
      trigger:
        kind: size
        limit: 1mb
      roller:
        kind: fixed_window
        base: 1
        count: 5
        pattern: "logs/main.{}.log"

  debug_log:
    kind: rolling_file
    path: "src/logs/debug.log"
    encoder:
      pattern: "{d(%Y-%m-%d %H:%M:%S%.3f)} {l} [{t}] {m}{n}"
    policy:
      trigger:
        kind: size
        limit: 1mb
      roller:
        kind: fixed_window
        base: 1
        count: 5
        pattern: "logs/debug.{}.log"

root:
  level: info
  appenders:
    - console
    - main_log
    - debug_log

loggers:
  sqlx_oldapi:
    level: off
  sqlx:
    level: off
  app:
    level: debug
    appenders:
      - debug_log
    additive: false```

--------------------------------------------------------------------------------

# src\config\rules.json
```
[
  {
    "rule_type": "SuspendedDoorRule",
    "parameters": {
      "alert_threshold": 300,
      "repeat_interval": 240
    }
  },
  {
    "rule_type": "LongLoadingStartRule",
    "parameters": {
      "alert_threshold": 600,
      "repeat_interval": 240
    }
  },
  {
    "rule_type": "TrailerHostageRule",
    "parameters": {
      "alert_threshold": 120,
      "repeat_interval": 240
    }
  },
  {
    "rule_type": "ShipmentStartedLoadNotReadyRule",
    "parameters": {
      "check_restraint": true,
      "check_leveler": true,
      "check_door_open": true
    }
  },
  {
    "rule_type": "TrailerPatternRule",
    "parameters": {
      "severity_threshold": 1
    }
  },
  {
    "rule_type": "DockReadyRule",
    "parameters": {}
  },
  {
    "rule_type": "ConsolidatedDataRule",
    "parameters": {}
  },
  {
    "rule_type": "TrailerDockingRule",
    "parameters": {
      "invalid_loading_status": "Idle",
      "invalid_wms_shipment_status": "Idle",
      "sensors_to_monitor": [
        {
          "name": "TRAILER_ANGLE",
          "success_value": 0
        },
        {
          "name": "TRAILER_CENTERING",
          "success_value": 0
        },
        {
          "name": "TRAILER_DISTANCE",
          "success_value": 0
        },
        {
          "name": "TRAILER_AT_DOOR",
          "success_value": 1
        }
      ]
    }
  },
  {
    "rule_type": "NewShipmentPreviousTrailerPresentRule",
    "parameters": {
      "completion_statuses": ["Completed", "Shipped"]
    }
  },
  {
    "rule_type": "ManualInterventionRule",
    "parameters": {
      "check_interval": 60,
      "max_duration": 7200
    }
  },
  {
    "rule_type": "TrailerUndockingRule",
    "parameters": {}
  },
  {
    "rule_type": "WmsEventsRule",
    "parameters": {}
  }
]```

--------------------------------------------------------------------------------

# src\controllers\dock_door.rs
```
use std::sync::Arc;
use tokio::sync::Mutex;
use log::info;

use crate::config::Settings;
use crate::services::plc::PlcService;
use crate::state_management::DockDoorStateManager;
use crate::errors::{DockManagerError, DockManagerResult};
use crate::event_handling::EventHandler;
use crate::services::db::DatabaseService;
use crate::models::{DbInsert, WmsEvent};

/// The central controller for managing dock doors and their interactions with PLCs, the WMS, and the database
pub struct DockDoorController {
    /// The application settings
    pub settings: Arc<Settings>,
    /// The service for interacting with PLCs
    pub plc_service: Arc<PlcService>,
    /// The state manager for tracking dock door states
    pub state_manager: Arc<DockDoorStateManager>,
    /// The event handler for processing dock door events
    pub event_handler: Arc<EventHandler>,
    /// The service for interacting with the database
    pub db_service: Arc<Mutex<DatabaseService>>,
}

impl DockDoorController {
    /// Creates a new `DockDoorController`
    ///
    /// Initializes the controller with the provided settings, services, and state manager
    /// Logs an informational message upon creation
    ///
    /// # Arguments
    ///
    /// * `settings`: The application settings
    /// * `plc_service`: The `PlcService` for PLC communication
    /// * `state_manager`: The `DockDoorStateManager` for managing door states
    /// * `event_handler`: The `EventHandler` for processing events
    /// * `db_service`: The `DatabaseService` for database interactions
    pub fn new(
        settings: Settings,
        plc_service: PlcService,
        state_manager: Arc<DockDoorStateManager>,
        event_handler: Arc<EventHandler>,
        db_service: DatabaseService
    ) -> Self {
        info!("Initializing Dock Door Controller");
        Self {
            settings: Arc::new(settings),
            plc_service: Arc::new(plc_service),
            state_manager,
            event_handler,
            db_service: Arc::new(Mutex::new(db_service)),
        }
    }

    /// Executes a single polling cycle, updating sensor data and processing events
    ///
    /// 1. Polls sensors using the `plc_service`
    /// 2. Updates the state manager with the new sensor values, which may generate events
    /// 3. Sends the generated events to the `event_handler` for processing, which may result in database insert events
    /// 4. Inserts the database events into the database using the `db_service`
    /// 5. Logs informational messages about the process
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the polling cycle completes successfully
    /// * `Err(DockManagerError)` if any errors occur during polling, state updates, event handling, or database insertion
    pub async fn run_polling_cycle(&self) -> DockManagerResult<()> {
        let start = std::time::Instant::now();
        info!("Starting PLC value polling...");
        let plc_values = self.plc_service.poll_sensors(&self.settings).await?;
        info!("PLC value polling completed in {:?}", start.elapsed());

        let update_start = std::time::Instant::now();
        info!("Starting sensor update...");
        let events = self.state_manager.update_sensors(plc_values).await?;
        info!("Sensor update completed in {:?}", update_start.elapsed());

        let event_start = std::time::Instant::now();
        info!("DOCK DOOR CONTROLLER: Processing {} events...", events.len());
        let mut db_events = Vec::new();
        for event in events {
            let new_db_events = self.event_handler.process_event(event).await?;
            db_events.extend(new_db_events);
        }
        info!("Event processing completed in {:?}", event_start.elapsed());

        if !db_events.is_empty() {
            let db_start = std::time::Instant::now();
            info!("Inserting {} DB events", db_events.len());
            self.db_service.lock().await.insert_dock_door_events(db_events).await?;
            info!("DB insertion completed in {:?}", db_start.elapsed());
        } else {
            info!("No DB events to insert");
        }

        info!("Full polling cycle completed in {:?}", start.elapsed());
        Ok(())
    }

    /// Updates WMS events for doors with assigned shipments
    ///
    /// 1. Gets all doors from the state manager
    /// 2. Filters doors that have an assigned shipment
    /// 3. For each such door, fetches WMS events concurrently using the `db_service`
    /// 4. Collects all fetched WMS events and processes them using the `state_manager`, which may generate database insert events
    /// 5. Inserts the database events into the database
    /// 6. Logs informational messages about the process
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the WMS event update completes successfully
    /// * `Err(DockManagerError)` if any errors occur during fetching WMS events, processing them, or inserting into the database
    pub async fn update_wms_events(&self) -> DockManagerResult<()> {
        let db_service = Arc::clone(&self.db_service);
        let door_repository = self.state_manager.get_door_repository();

        let futures: Vec<_> = door_repository.get_all_doors().await
            .into_iter()
            .filter(|door| door.assigned_shipment.current_shipment.is_some())
            .map(|door| {
                let shipment_id = door.assigned_shipment.current_shipment.clone().unwrap();
                let door_name = door.dock_name.clone();
                let plant_id = door.plant_id.clone();
                let db_service = Arc::clone(&db_service);
                tokio::spawn(async move {
                    let db = db_service.lock().await;
                    db.fetch_wms_events(&plant_id, &shipment_id, &door_name).await
                })
            })
            .collect();

        let results = futures::future::join_all(futures).await;
        let mut all_wms_events = Vec::new();

        for result in results {
            match result {
                Ok(Ok(events)) => all_wms_events.extend(events),
                Ok(Err(e)) => return Err(e),
                Err(e) => return Err(DockManagerError::TaskJoinError(e.to_string())),
            }
        }

        // Process WMS events and get DockDoorEvents
        let dock_door_events = self.state_manager.process_wms_events(all_wms_events.clone()).await?;


        // Process the resulting DockDoorEvents through the event handler
        let mut db_events = Vec::new();

        for event in dock_door_events {
            let new_db_events = self.event_handler.process_event(event).await?;
            info!("WMS Events Converted to DBInsert: {:?}", new_db_events);
            db_events.extend(new_db_events);
        }

        // Insert the resulting database events
        if !db_events.is_empty() {
            info!("Inserting {} WMS event DB events", db_events.len());
            self.db_service.lock().await.insert_dock_door_events(db_events).await?;
        }

        Ok(())
    }

    /// Updates the WMS door status for all plants
    ///
    /// 1. Iterates through all configured plants
    /// 2. Fetches WMS data (door statuses) for the current plant using the `db_service`
    /// 3. Updates the `state_manager` with the fetched WMS data, which may generate events
    /// 4. Sends the generated events to the `event_handler` for processing, which may result in database insert events
    /// 5. Inserts the database events into the database
    /// 6. Logs informational messages about the process
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the WMS door status update completes successfully
    /// * `Err(DockManagerError)` if any errors occur during fetching WMS data, updating the state manager, event handling, or database insertion
    pub async fn update_wms_door_status(&self) -> DockManagerResult<()> {
        let mut all_events = Vec::new();

        for plant in &self.settings.plants {
            let plant_id = &plant.plant_id;
            let wms_data = self.db_service.lock().await.fetch_wms_data(plant_id).await?;
            let events = self.state_manager.update_from_wms(wms_data).await?;
            all_events.extend(events);
        }

        let mut db_events = Vec::new();
        for event in all_events {
            let new_db_events = self.event_handler.process_event(event.clone()).await?;
            db_events.extend(new_db_events);
        }

        if !db_events.is_empty() {
            info!("Inserting {} WMS door status DB events", db_events.len());
            self.db_service.lock().await.insert_dock_door_events(db_events).await?;
        }

        Ok(())
    }

    /// Handles a WMS event and creates a `DbInsert` for it
    ///
    /// This method extracts the user ID (if applicable) from the WMS event's message notes
    /// and constructs a `DbInsert` object representing the event for database insertion
    ///
    /// # Arguments
    ///
    /// * `event`: The `WmsEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(DbInsert)`: The `DbInsert` object representing the WMS event
    pub async fn handle_wms_event(&self, event: WmsEvent) -> DockManagerResult<DbInsert> {
        let user_id = if ["STARTED_SHIPMENT", "SUSPENDED_SHIPMENT", "RESUMED_SHIPMENT",
            "UPDATED_PRIORITY", "CANCELLED_SHIPMENT", "SDM_LOAD_PLAN",
            "LOAD_QTY_ADJUSTED", "SDM_CHECK_IN", "SDM_TRAILER_REJECTION"]
            .contains(&event.message_type.as_str()) {
            event.message_notes
                .as_ref()
                .and_then(|notes| notes.split('-').next())
                .map(|user| user.trim().to_string())
        } else {
            None
        };
        Ok(DbInsert {
            LOG_DTTM: event.log_dttm.unwrap_or_else(|| chrono::Local::now().naive_local()),
            PLANT: event.plant.clone(),
            DOOR_NAME: event.dock_name,
            SHIPMENT_ID: Some(event.shipment_id),
            EVENT_TYPE: event.message_type,
            SUCCESS: if event.result_code == 0 { 1 } else { 0 },
            NOTES: event.message_notes.unwrap_or_default(),
            ID_USER: user_id,
            SEVERITY: event.result_code,
            PREVIOUS_STATE: None,
            PREVIOUS_STATE_DTTM: None
        })
    }
}```

--------------------------------------------------------------------------------

# src\controllers\mod.rs
```
pub mod dock_door;```

--------------------------------------------------------------------------------

# src\event_handling\event_handler.rs
```
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex};
use chrono::{Local, Utc};
use log::{info, error, debug};
use crate::models::{DockDoorEvent, DbInsert, DockDoor};
use crate::analysis::{AnalysisResult, context_analyzer, ContextAnalyzer};
use crate::errors::{DockManagerResult, DockManagerError};
use crate::alerting::alert_manager::{AlertManager, Alert, AlertType};
use crate::monitoring::{MonitoringItem, MonitoringQueue};
use crate::state_management::door_state_repository::DoorStateRepository;
use crate::services::db::DatabaseService;
use crate::models::consolidated_dock_event::ConsolidatedDockEvent;

/// The EventHandler is responsible for processing events in the dock door management system.
#[derive(Clone)]
pub struct EventHandler {
    /// A queue for receiving `DockDoorEvent`s.
    event_queue: Arc<Mutex<mpsc::Receiver<DockDoorEvent>>>,
    /// The state repository responsible for maintaining the state of dock doors.
    door_repository: Arc<DoorStateRepository>,
    /// The context analyzer used to analyze events and generate insights.
    context_analyzer: Arc<ContextAnalyzer>,
    /// The alert manager responsible for handling and sending alerts.
    alert_manager: Arc<AlertManager>,
    /// The queue for monitoring items.
    monitoring_queue: Arc<MonitoringQueue>,
    /// A channel sender for consolidated events.
    consolidated_event_sender: mpsc::Sender<ConsolidatedDockEvent>,
}

impl EventHandler {
    /// Creates a new `EventHandler`.
    ///
    /// # Arguments
    ///
    /// * `event_queue` - The receiver end of a channel to receive `DockDoorEvent`s.
    /// * `door_repository` - The `DoorStateRepository` to interact with for state updates.
    /// * `context_analyzer` - The `ContextAnalyzer` to use for event analysis.
    /// * `alert_manager` - The `AlertManager` to handle alerts.
    /// * `monitoring_queue` - The `MonitoringQueue` to add monitoring items.
    /// * `db_service` - The `DatabaseService` for database operations.
    ///
    /// # Returns
    ///
    /// A new `EventHandler` instance.
    pub fn new(
        event_queue: mpsc::Receiver<DockDoorEvent>,
        door_repository: Arc<DoorStateRepository>,
        context_analyzer: Arc<ContextAnalyzer>,
        alert_manager: Arc<AlertManager>,
        monitoring_queue: Arc<MonitoringQueue>,
        db_service: Arc<DatabaseService>,
    ) -> Self {
        let (consolidated_event_sender, consolidated_event_receiver) = mpsc::channel(1000);

        // Spawn a task to handle consolidated events
        tokio::spawn(Self::process_consolidated_events(consolidated_event_receiver, Arc::clone(&db_service)));

        Self {
            event_queue: Arc::new(Mutex::new(event_queue)),
            door_repository,
            context_analyzer,
            alert_manager,
            monitoring_queue,
            consolidated_event_sender,
        }
    }

    /// Processes consolidated events asynchronously.
    ///
    /// This function runs in a separate task and continuously receives consolidated events
    /// from a channel, inserting them into the database.
    ///
    /// # Arguments
    ///
    /// * `receiver` - The receiver end of the channel for consolidated events.
    /// * `db_service` - The database service for inserting events.
    async fn process_consolidated_events(
        mut receiver: mpsc::Receiver<ConsolidatedDockEvent>,
        db_service: Arc<DatabaseService>,
    ) {
        while let Some(event) = receiver.recv().await {
            if let Err(e) = db_service.insert_consolidated_event(&event).await {
                error!("Failed to insert consolidated event: {:?}", e);
            }
        }
    }

    /// Runs the event handler, continuously processing events from the queue
    /// until the queue is closed or an error occurs.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure of the run.
    pub async fn run(&self) -> DockManagerResult<()> {
        info!("EventHandler started");
        while let Some(event) = self.event_queue.lock().await.recv().await {
            if let Err(e) = self.process_event(event).await {
                error!("Error processing event: {:?}", e);
            }
        }
        info!("EventHandler stopped");
        Ok(())
    }

    /// Processes a single dock door event.
    ///
    /// This method retrieves the associated dock door, analyzes the event using the `ContextAnalyzer`,
    /// handles any resulting state transitions, alerts, or logs, updates the door's state,
    /// and inserts any generated `DbInsert` events into the database.
    ///
    /// # Arguments
    ///
    /// * `event` - The `DockDoorEvent` to be processed.
    ///
    /// # Returns
    ///
    /// * `Ok(Vec<DbInsert>)` - A vector of `DbInsert` events generated during processing.
    /// * `Err(DockManagerError)` - If there's an error processing the event or interacting with the database or state manager.
    pub async fn process_event(&self, event: DockDoorEvent) -> DockManagerResult<Vec<DbInsert>> {
        debug!("Processing event: {:?}", event);

        let door_name = event.get_dock_name();
        let plant_id = event.get_plant_id();

        let mut door = self.door_repository.get_door_state(plant_id, door_name).await
            .ok_or_else(|| DockManagerError::DoorNotFound(door_name.to_string()))?;

        let analysis_results = self.context_analyzer.analyze(&door, &event).await;
        info!("Analysis results: {:?}", analysis_results);

        let mut db_events = Vec::new();
        for result in analysis_results {
            match result {
                AnalysisResult::StateTransition(new_state) => {
                    door.door_state = new_state;
                },
                AnalysisResult::Log(log_entry) => {
                    info!("EVENT HANDLER: Processing event log entry for log: {:?}", log_entry);
                    let db_insert = DbInsert::from_log_entry(&log_entry);
                    db_events.push(db_insert);
                },
                AnalysisResult::Alert(alert_type) => {
                    info!("EVENT HANDLER: Processing event alert for alert: {:?}", alert_type);
                    let alert = self.create_alert(alert_type.clone(), &door);
                    match self.alert_manager.handle_alert(alert.clone()).await {
                        Ok(_) => info!("Alert handled successfully: {:?}", alert),
                        Err(e) => error!("Failed to handle alert: {:?}. Error: {:?}", alert, e),
                    }
                    self.add_to_monitoring_queue(alert_type, &door).await;
                },
                AnalysisResult::DbInsert(db_insert) => {
                    db_events.push(db_insert);
                },
                AnalysisResult::ConsolidatedEvent(consolidated_event) => {
                    if let Err(e) = self.consolidated_event_sender.send(consolidated_event).await {
                        error!("Failed to send consolidated event: {:?}", e);
                    }
                }
            }
        }

        door.handle_event(&event)?;

        if !db_events.is_empty() {
            self.insert_db_events(&db_events).await?;
        }

        Ok(db_events)
    }

    /// Inserts a batch of database events.
    ///
    /// # Arguments
    ///
    /// * `db_events` - A slice of `DbInsert` events to be inserted.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure of the insertion.
    async fn insert_db_events(&self, db_events: &[DbInsert]) -> DockManagerResult<()> {
        for event in db_events {
            let plant_id = event.get_plant_id();
            self.door_repository.insert_db_event(plant_id, event.clone()).await?;
        }
        Ok(())
    }

    /// Creates an `Alert` from an `AlertType` and `DockDoor`.
    ///
    /// This method constructs the appropriate `Alert` based on the given `AlertType`,
    /// populating it with relevant information from the `DockDoor`.
    ///
    /// # Arguments
    ///
    /// * `alert_type` - The `AlertType` to convert into an `Alert`.
    /// * `door` - The `DockDoor` associated with the alert.
    ///
    /// # Returns
    ///
    /// An `Alert` instance constructed from the given `AlertType` and `DockDoor`.
    fn create_alert(&self, alert_type: context_analyzer::AlertType, door: &DockDoor) -> Alert {
        match alert_type {
            context_analyzer::AlertType::SuspendedDoor { door_name, duration, shipment_id, user } => {
                Alert::new(AlertType::SuspendedDoor, door_name)
                    .duration(duration)
                    .shipment_id(shipment_id.unwrap_or_default())
                    .add_info("user".to_string(), user)
                    .build()
            },
            context_analyzer::AlertType::TrailerDocked { door_name, shipment_id, timestamp, success, failure_reason } => {
                Alert::new(AlertType::TrailerDocked, door_name)
                    .shipment_id(shipment_id.unwrap_or_default())
                    .add_info("timestamp".to_string(), timestamp.to_string())
                    .add_info("success".to_string(), success.to_string())
                    .add_info("failure_reason".to_string(), failure_reason.unwrap_or_default())
                    .build()
            },
            context_analyzer::AlertType::ShipmentStartedLoadNotReady { door_name, shipment_id, reason } => {
                Alert::new(AlertType::ShipmentStartedLoadNotReady, door_name)
                    .shipment_id(shipment_id)
                    .add_info("reason".to_string(), reason)
                    .build()
            },
            context_analyzer::AlertType::DockReady { door_name, shipment_id, timestamp } => {
                Alert::new(AlertType::DockReady, door_name)
                    .shipment_id(shipment_id.unwrap_or_default())
                    .add_info("timestamp".to_string(), timestamp.to_string())
                    .build()
            },
            context_analyzer::AlertType::ManualModeAlert { door_name, shipment_id } => {
                Alert::new(AlertType::ManualModeAlert, door_name)
                    .shipment_id(shipment_id.unwrap_or_default())
                    .build()
            },
            context_analyzer::AlertType::TrailerPatternIssue { door_name, shipment_id, .. } => {
                Alert::new(AlertType::TrailerPatternIssue, door_name)
                    .shipment_id(shipment_id.unwrap_or_default())
                    .build()
            },
            context_analyzer::AlertType::TrailerDockedNotStarted { door_name, duration } => {
                Alert::new(AlertType::TrailerDockedNotStarted, door_name)
                    .add_info("has had a trailer docked without inspection or starting in wms for".to_string(), duration.to_string())
                    .build()
            },
            context_analyzer::AlertType::TrailerHostage { door_name, shipment_id, duration } => {
                Alert::new(AlertType::TrailerHostage, door_name)
                    .shipment_id(shipment_id.unwrap_or_default())
                    .add_info("Trailer has been held hostage for ".to_string(), duration.to_string())
                    .build()
            },
            _ => Alert::new(AlertType::ManualModeAlert, door.dock_name.clone()).build(),
        }
    }

    /// Adds a monitoring item to the monitoring queue based on the alert type.
    ///
    /// This method creates and adds appropriate `MonitoringItem`s to the monitoring queue
    /// based on the given `AlertType`.
    ///
    /// # Arguments
    ///
    /// * `alert_type` - The `AlertType` to convert into a monitoring item.
    /// * `door` - The `DockDoor` associated with the alert.
    async fn add_to_monitoring_queue(&self, alert_type: context_analyzer::AlertType, door: &DockDoor) {
        match alert_type {
            context_analyzer::AlertType::SuspendedDoor { door_name, shipment_id, user, .. } => {
                self.monitoring_queue.add(MonitoringItem::SuspendedShipment {
                    plant_id: door.plant_id.clone(),
                    door_name,
                    shipment_id: shipment_id.unwrap_or_default(),
                    suspended_at: Local::now().naive_local(),
                    user,
                    added_to_queue: Utc::now().naive_utc(),
                });
            },
            context_analyzer::AlertType::TrailerDocked { door_name, timestamp, success: true, .. } => {
                self.monitoring_queue.add(MonitoringItem::TrailerDockedNotStarted {
                    plant_id: door.plant_id.clone(),
                    door_name,
                    docked_at: timestamp,
                    added_to_queue: Utc::now().naive_utc(),
                });
            },
            context_analyzer::AlertType::ShipmentStartedLoadNotReady { door_name, shipment_id, .. } => {
                self.monitoring_queue.add(MonitoringItem::ShipmentStartedLoadNotReady {
                    plant_id: door.plant_id.clone(),
                    door_name,
                    shipment_id,
                    started_at: Local::now().naive_local(),
                    added_to_queue: Utc::now().naive_utc(),
                });
            },
            context_analyzer::AlertType::DockReady { door_name, timestamp, .. } => {
                self.monitoring_queue.add(MonitoringItem::TrailerDockedNotStarted {
                    plant_id: door.plant_id.clone(),
                    door_name,
                    docked_at: timestamp,
                    added_to_queue: Utc::now().naive_utc(),
                });
            },
            context_analyzer::AlertType::TrailerHostage { door_name, shipment_id, .. } => {
                self.monitoring_queue.add(MonitoringItem::TrailerHostage {
                    plant_id: door.plant_id.clone(),
                    door_name,
                    shipment_id,
                    detected_at: Local::now().naive_local(),
                    added_to_queue: Utc::now().naive_utc(),
                });
            },
            _ => {}
        }
    }
}```

--------------------------------------------------------------------------------

# src\event_handling\mod.rs
```
pub mod event_handler;
pub use event_handler::*;```

--------------------------------------------------------------------------------

# src\models\consolidated_dock_event.rs
```
use chrono::NaiveDateTime;
use serde::{Deserialize, Serialize};
use sqlx_oldapi::FromRow;

#[derive(Debug, Clone, FromRow, Serialize, Deserialize)]
pub struct ConsolidatedDockEvent {
    pub plant: String,
    pub door_name: String,
    pub shipment_id: i32,
    pub docking_time_minutes: Option<i32>,
    pub inspection_time_minutes: Option<i32>,
    pub enqueued_time_minutes: Option<i32>,
    pub shipment_assigned: Option<NaiveDateTime>,
    pub dock_assignment: Option<NaiveDateTime>,
    pub trailer_docking: Option<NaiveDateTime>,
    pub started_shipment: Option<NaiveDateTime>,
    pub lgv_start_loading: Option<NaiveDateTime>,
    pub dock_ready: Option<NaiveDateTime>,
    pub is_preload: bool,
}```

--------------------------------------------------------------------------------

# src\models\idb_log.rs
```
//! # Database Insertion Structure

//! This module defines the `DbInsert` struct, which represents a record to be inserted into the database. It encapsulates 
//! various fields that capture information about events, their timestamps, associated entities (like plants, doors, and shipments), 
//! success status, notes, and other relevant details. 
//! The `DbInsert` struct facilitates the structured storage of log entries and other events within the database for further analysis and reporting

#![allow(non_snake_case)]

use chrono::NaiveDateTime;
use serde::{Deserialize, Serialize};
use sqlx_oldapi::FromRow;
use crate::analysis::LogEntry;
use crate::models::WmsEvent;

/// Represents a record to be inserted into the database, typically derived from a `LogEntry`
#[derive(Debug, Serialize, Deserialize, FromRow, Clone)]
pub struct DbInsert {
    /// The date and time the event occurred
    pub LOG_DTTM: NaiveDateTime,
    /// The plant associated with the event
    pub PLANT: String,
    /// The name of the dock door related to the event
    pub DOOR_NAME: String,
    /// The ID of the shipment, if applicable to the event
    pub SHIPMENT_ID: Option<String>,
    /// The type of event
    pub EVENT_TYPE: String,
    /// Indicates whether the event was successful (1) or not (0)
    pub SUCCESS: i32,
    /// Additional notes or details about the event
    pub NOTES: String,
    /// The ID of the user who triggered or is associated with the event
    pub ID_USER: Option<String>,
    /// The severity level of the event
    pub SEVERITY: i32,
    /// The previous state or value before the event occurred
    pub PREVIOUS_STATE: Option<String>,
    /// The date and time of the previous state
    pub PREVIOUS_STATE_DTTM: Option<NaiveDateTime>,
}

impl DbInsert {
    /// Creates a `DbInsert` instance from a `LogEntry`
    /// 
    /// This method extracts relevant information from the `LogEntry` and constructs 
    /// a `DbInsert` object suitable for database insertion
    ///
    /// # Arguments
    /// * `log_entry`: The `LogEntry` from which to create the `DbInsert`
    /// 
    /// # Returns
    /// * A new `DbInsert` instance populated with data from the `LogEntry`
    pub fn from_log_entry(log_entry: &LogEntry) -> Self {
        match log_entry {
            LogEntry::DockingTime { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::ManualModeActivated { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::LoadingStatusChange { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::ShipmentUnassigned { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::ShipmentAssigned { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::NewShipmentPreviousTrailerPresent { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::ManualInterventionStarted { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::ManualInterventionSuccess { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::ManualInterventionFailure { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::TrailerStateChange { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::SuspendedDoor { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::LongLoadingStart { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::TrailerHostage { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::ShipmentStartedLoadNotReady { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::TrailerUndocked { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } |
            LogEntry::TrailerPatternIssue { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm } => {
                DbInsert {
                    LOG_DTTM: *log_dttm,
                    PLANT: plant.clone(),
                    DOOR_NAME: door_name.clone(),
                    SHIPMENT_ID: shipment_id.clone(),
                    EVENT_TYPE: event_type.clone(),
                    SUCCESS: if *success { 1 } else { 0 },
                    NOTES: notes.clone(),
                    ID_USER: None,
                    SEVERITY: *severity,
                    PREVIOUS_STATE: previous_state.clone(),
                    PREVIOUS_STATE_DTTM: *previous_state_dttm,
                }
            },
            LogEntry::WmsEvent { log_dttm, plant, door_name, shipment_id, event_type, success, notes, severity, previous_state, previous_state_dttm, .. } => {
                DbInsert {
                    LOG_DTTM: *log_dttm,
                    PLANT: plant.clone(),
                    DOOR_NAME: door_name.clone(),
                    SHIPMENT_ID: shipment_id.clone(),
                    EVENT_TYPE: event_type.clone(),
                    SUCCESS: if *success { 1 } else { 0 },
                    NOTES: notes.clone(),
                    ID_USER: None,
                    SEVERITY: *severity,
                    PREVIOUS_STATE: previous_state.clone(),
                    PREVIOUS_STATE_DTTM: *previous_state_dttm,
                }
            }
        }
    }

    pub fn get_plant_id(&self) -> &str {
        &self.PLANT
    }
}

impl TryFrom<WmsEvent> for DbInsert {
    type Error = String;

    fn try_from(event: WmsEvent) -> Result<Self, Self::Error> {
        Ok(DbInsert {
            LOG_DTTM: event.log_dttm.unwrap_or_else(|| chrono::Local::now().naive_local()),
            PLANT: event.plant,
            DOOR_NAME: event.dock_name,
            SHIPMENT_ID: Some(event.shipment_id),
            EVENT_TYPE: event.message_type,
            SUCCESS: if event.result_code == 0 { 1 } else { 0 },
            NOTES: event.message_notes.unwrap_or_default(),
            ID_USER: None,
            SEVERITY: event.result_code,
            PREVIOUS_STATE: None,
            PREVIOUS_STATE_DTTM: None,
        })
    }
}```

--------------------------------------------------------------------------------

# src\models\idoor.rs
```
//! # Dock Door Representation

//! This module defines the `DockDoor` struct, which represents the state and data associated with a single dock door. 
//! The `DockDoor` struct encapsulates various attributes such as the door's operational state, loading status, 
//! associated sensors, and shipment information. It also provides methods to handle events and update its state based on 
//! sensor readings and interactions with the Warehouse Management System (WMS).

use chrono::NaiveDateTime;
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use std::str::FromStr;
use log::info;
use crate::config::PlantSettings;
use crate::models::isensor::DockSensor;
use crate::models::istates::{DoorState, TrailerState, ManualMode, DockLockState, DoorPosition, LevelerPosition, FaultState};
use crate::models::istatus::LoadingStatus;
use crate::models::ievents::{DockAssignedEvent, DockDoorEvent, DockUnassignedEvent, DoorStateChangedEvent, LoadingCompletedEvent, LoadingStartedEvent, LoadingStatusChangedEvent, SensorStateChangedEvent, TrailerDepartedEvent, TrailerDockedEvent};
use crate::errors::{DockManagerError, DockManagerResult};
use crate::models::{AssignedShipment, RestraintState, ShipmentAssignedEvent, ShipmentUnassignedEvent, TrailerPositionState, TrailerStateChangedEvent, WmsDoorStatus};


/// Represents the result of evaluating a sensor update
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SensorEvaluation {
    /// Indicates whether the sensor value has changed
    pub changed: bool,
    /// The old sensor value before the update
    pub old_value: Option<u8>,
    /// The new sensor value after the update
    pub new_value: Option<u8>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct LoadStatusState {
    /// The current loading status of the door (e.g., Idle, Loading, Completed).
    pub loading_status: LoadingStatus,
    pub current_state_dttm: Option<NaiveDateTime>,
    /// The previous loading status of the door.
    pub previous_loading_status: LoadingStatus,
    pub previous_state_dttm: Option<NaiveDateTime>,
    /// The shipment status as reported by the WMS.
    pub wms_shipment_status: Option<String>,
    pub last_polling_dttm: Option<NaiveDateTime>
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ConsolidatedDataState {
    pub docking_time: Option<NaiveDateTime>,
    pub is_preload: bool,
    pub last_dock_ready_time: Option<NaiveDateTime>,
    pub dock_assignment: Option<NaiveDateTime>,
    pub shipment_started_dttm: Option<NaiveDateTime>,
    pub lgv_loading_started: Option<NaiveDateTime>,
    pub lgv_first_drop: Option<NaiveDateTime>,
}

/// Represents the state and data associated with a single dock door.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DockDoor {
    /// The ID of the plant where the dock door is located.
    pub plant_id: String,
    /// The name or identifier of the dock door.
    pub dock_name: String,
    /// The IP address of the PLC controlling the dock door.
    pub dock_ip: String,
    /// The current operational state of the door (e.g., Unassigned, TrailerDocked, Loading).
    pub door_state: DoorState,
    /// The previous operational state of the door
    pub previous_door_state: DoorState,
    /// The current loading status of the door (e.g., Idle, Loading, Completed).
    pub loading_status: LoadStatusState,
    /// The current state of the trailer at the door (Docked or Undocked).
    pub trailer_state: TrailerState,
    /// The previous state of the trailer at the door
    pub previous_trailer_state: TrailerState,
    /// The timestamp when the trailer state last changed
    pub trailer_state_changed: Option<NaiveDateTime>,
    /// Whether the door is currently in manual mode.
    pub manual_mode: ManualMode,
    /// The state of the dock lock (Engaged or Disengaged).
    pub dock_lock_state: DockLockState,
    /// The current position of the door (Open or Closed).
    pub door_position: DoorPosition,
    /// The current position of the leveler (Stored or Extended).
    pub leveler_position: LevelerPosition,
    /// The current fault state of the door (NoFault or FaultPresent).
    pub fault_state: FaultState,
    /// Information about the shipment currently or previously assigned to the door
    pub assigned_shipment: AssignedShipment,
    /// A map of sensor names to their corresponding `DockSensor` objects, representing the sensors associated with the door
    pub sensors: HashMap<String, DockSensor>,
    /// The timestamp when the door's state was last updated
    pub last_updated: NaiveDateTime,
    /// Indicates if there's a fault with the trailer doors
    pub trailer_door_fault: bool,
    /// Indicates if there's a fault with the dock lock
    pub dock_lock_fault: bool,
    /// Indicates if there's a fault with the door
    pub door_fault: bool,
    /// Indicates if the emergency stop has been activated
    pub emergency_stop: bool,
    /// Indicates if there's a fault with the leveler
    pub leveler_fault: bool,
    /// The current state of the restraint (Locking, Unlocking, Locked, Unlocked)
    pub restraint_state: RestraintState,
    /// The current position state of the trailer (Proper or Improper)
    pub trailer_position_state: TrailerPositionState,
    pub consolidated: ConsolidatedDataState,

}

impl DockDoor {
    /// Creates a new `DockDoor` instance
    ///
    /// Initializes a `DockDoor` with the provided plant ID, dock name, and dock IP.
    /// It also sets up the sensors associated with the door based on the plant settings
    /// and initializes other state variables to their default values
    ///
    /// # Arguments
    ///
    /// * `plant_id`: The ID of the plant where the door is located
    /// * `dock_name`: The name or identifier of the dock door
    /// * `dock_ip`: The IP address of the PLC controlling the door
    /// * `plant_settings`: Configuration settings for the plant, including sensor details
    ///
    /// # Returns:
    /// A new `DockDoor` instance
    pub fn new(plant_id: String, dock_name: String, dock_ip: String, plant_settings: &PlantSettings) -> Self {
        let loading_status = LoadStatusState {
            loading_status: LoadingStatus::Idle,
            current_state_dttm: None,
            previous_loading_status: LoadingStatus::Idle,
            wms_shipment_status: None,
            previous_state_dttm: None,
            last_polling_dttm: None
        };
        let consolidated = ConsolidatedDataState{
            docking_time: None,
            is_preload: false,
            last_dock_ready_time: None,
            dock_assignment: None,
            shipment_started_dttm: None,
            lgv_loading_started: None,
            lgv_first_drop: None,
        };
        let mut door = DockDoor {
            plant_id,
            dock_name: dock_name.clone(),
            dock_ip: dock_ip.clone(),
            loading_status,
            door_state: DoorState::Unassigned,
            previous_door_state: DoorState::Unassigned,
            trailer_state: TrailerState::Undocked,
            previous_trailer_state: TrailerState::Undocked,
            trailer_state_changed: None,
            manual_mode: ManualMode::Disabled,
            dock_lock_state: DockLockState::Disengaged,
            door_position: DoorPosition::Closed,
            leveler_position: LevelerPosition::Stored,
            fault_state: FaultState::NoFault,
            assigned_shipment: AssignedShipment::default(),
            sensors: HashMap::new(),
            last_updated: chrono::Local::now().naive_local(),
            trailer_door_fault: false,
            dock_lock_fault: false,
            door_fault: false,
            emergency_stop: false,
            leveler_fault: false,
            restraint_state: RestraintState::Unlocked,
            trailer_position_state: TrailerPositionState::Improper,
            consolidated,
        };
        for tag in &plant_settings.dock_doors.dock_plc_tags {
            door.sensors.insert(
                tag.tag_name.clone(),
                DockSensor::new(
                    &dock_name,
                    &dock_ip,
                    &tag.tag_name,
                    &tag.address,
                )
            );
        }

        door
    }

/// Updates the value of a sensor and evaluates if a change occurred
    ///
    /// This method attempts to update the value of the specified sensor with the new value
    /// It returns a `SensorEvaluation` indicating whether the value actually changed
    /// and providing the old and new values for reference
    ///
    /// If the sensor is not found or the new value is `None`, an error is returned
    ///
    /// # Arguments
    ///
    /// * `sensor_name`: The name of the sensor to update
    /// * `new_value`: The new value to set for the sensor (or `None` if the read failed)
    ///
    /// # Returns
    ///
    /// * `Ok(SensorEvaluation)` if the sensor was found and updated successfully
    /// * `Err(DockManagerError)` if the sensor was not found or the new value is `None`
    pub fn update_sensor(&mut self, sensor_name: &str, new_value: Option<u8>) -> Result<SensorEvaluation, DockManagerError> {
        if let Some(sensor) = self.sensors.get_mut(sensor_name) {
            let old_value = sensor.get_sensor_data().current_value;

            match new_value {
                Some(value) => {
                    if old_value != Some(value) {
                        sensor.update_value(Some(value));
                        Ok(SensorEvaluation { changed: true, old_value, new_value })
                    } else {
                        Ok(SensorEvaluation { changed: false, old_value, new_value })
                    }
                },
                None => {
                    Err(DockManagerError::PlcError(format!("Failed to read sensor {} for door {}", sensor_name, self.dock_name)))
                }
            }
        } else {
            Err(DockManagerError::SensorReadError(sensor_name.to_string()))
        }
    }

    /// Handles an incoming `DockDoorEvent`, updating the door's state accordingly
    ///
    /// This method dispatches the event to the appropriate handler function based on its type
    /// Each handler function is responsible for updating the relevant state variables of the `DockDoor`
    ///
    /// # Arguments
    /// * `event`: The `DockDoorEvent` to be handled
    ///
    /// # Returns
    /// * `Ok(())` if the event was handled successfully
    /// * `Err(DockManagerError)` if an error occurred during event handling
    pub fn handle_event(&mut self, event: &DockDoorEvent) -> Result<(), DockManagerError> {
        match event {
            DockDoorEvent::DockAssigned(e) => self.handle_dock_assigned(e),
            DockDoorEvent::DockUnassigned(e) => self.handle_dock_unassigned(e),
            DockDoorEvent::TrailerDocked(e) => self.handle_trailer_docked(e),
            DockDoorEvent::TrailerDeparted(e) => self.handle_trailer_departed(e),
            DockDoorEvent::LoadingStarted(e) => self.handle_loading_started(e),
            DockDoorEvent::LoadingCompleted(e) => self.handle_loading_completed(e),
            DockDoorEvent::SensorStateChanged(e) => self.handle_sensor_state_changed(e),
            DockDoorEvent::DoorStateChanged(e) => self.handle_door_state_changed(e),
            DockDoorEvent::LoadingStatusChanged(e) => self.handle_loading_status_changed(e),
            DockDoorEvent::TrailerStateChanged(e) => self.handle_trailer_state_changed(e),
            // Add handlers for other events as needed
            _ => Ok(()),
        }
    }

    /// Handles a `DockAssignedEvent`, updating the door's state and shipment information
    ///
    /// If the assigned shipment in the event is different from the current one, 
    /// the door's state is set to `Assigned`, the shipment information is updated, 
    /// and the last updated timestamp is set
    ///
    /// # Arguments
    ///
    /// * `event`: The `DockAssignedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully
    fn handle_dock_assigned(&mut self, event: &DockAssignedEvent) -> Result<(), DockManagerError> {
        let state_shipment = self.assigned_shipment.current_shipment.clone();
        let event_shipment = Some(event.shipment_id.clone());
        if state_shipment != event_shipment {
            self.door_state = DoorState::Assigned;
            self.assigned_shipment.previous_shipment = self.assigned_shipment.current_shipment.clone();
            self.assigned_shipment.current_shipment = Some(event.shipment_id.clone());
            self.assigned_shipment.assignment_dttm = Some(event.timestamp);
            self.last_updated = event.timestamp;
            return Ok(());
        }
        Ok(())
    }

    /// Handles a `DockUnassignedEvent`, updating the door's state and shipment information
    ///
    /// The door's state is set to `Unassigned`, the current shipment is cleared, 
    /// and the last updated timestamp is set
    ///
    /// # Arguments
    ///
    /// * `event`: The `DockUnassignedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully
    fn handle_dock_unassigned(&mut self, event: &DockUnassignedEvent) -> Result<(), DockManagerError> {
        self.door_state = DoorState::Unassigned;
        self.assigned_shipment.previous_shipment = self.assigned_shipment.current_shipment.clone();
        self.assigned_shipment.current_shipment = None;
        self.assigned_shipment.assignment_dttm = Some(event.timestamp);
        self.last_updated = event.timestamp;
        Ok(())
    }

    /// Handles a `TrailerDockedEvent`, updating the door and trailer states
    ///
    /// The trailer state is set to `Docked`, the door state is set to `TrailerDocked`,
    /// and the last updated timestamp is set
    ///
    /// # Arguments
    ///
    /// * `event`: The `TrailerDockedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully
    fn handle_trailer_docked(&mut self, event: &TrailerDockedEvent) -> Result<(), DockManagerError> {
        info!("TrailerDockedEvent: {:?}", event);
        self.trailer_state = TrailerState::Docked;
        self.door_state = DoorState::TrailerDocked;
        self.last_updated = event.timestamp;
        Ok(())
    }

    /// Handles a `TrailerDepartedEvent`, updating the door and trailer states
    ///
    /// The trailer state is set to `Undocked`, the door state is set to `WaitingForExit`
    /// and the last updated timestamp is set
    ///
    /// # Arguments
    ///
    /// * `event`: The `TrailerDepartedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully
    fn handle_trailer_departed(&mut self, event: &TrailerDepartedEvent) -> Result<(), DockManagerError> {
        info!("TrailerDepartedEvent: {:?}", event);

        self.trailer_state = TrailerState::Undocked;
        self.door_state = DoorState::WaitingForExit;
        self.last_updated = event.timestamp;
        Ok(())
    }

    /// Handles a `LoadingStartedEvent`, updating the loading status and door state
    ///
    /// The loading status is set to `Loading`, the door state is set to `Loading`
    /// and the last updated timestamp is set
    ///
    /// # Arguments
    ///
    /// * `event`: The `LoadingStartedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully
    fn handle_loading_started(&mut self, event: &LoadingStartedEvent) -> Result<(), DockManagerError> {
        self.loading_status.loading_status = LoadingStatus::Loading;
        self.door_state = DoorState::Loading;
        self.last_updated = event.timestamp;
        Ok(())
    }

    /// Handles a `LoadingCompletedEvent`, updating the loading status and door state
    ///
    /// The loading status is set to `Completed`, the door state is set to `LoadingCompleted`
    /// and the last updated timestamp is set
    ///
    /// # Arguments
    ///
    /// * `event`: The `LoadingCompletedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully
    fn handle_loading_completed(&mut self, event: &LoadingCompletedEvent) -> Result<(), DockManagerError> {
        self.loading_status.loading_status = LoadingStatus::Completed;
        self.door_state = DoorState::LoadingCompleted;
        self.last_updated = event.timestamp;
        Ok(())
    }

    /// Handles a `SensorStateChangedEvent`, updating the corresponding sensor's value
    ///
    /// If the sensor is found in the door's sensor map, its value is updated
    /// The last updated timestamp is also set
    ///
    /// # Arguments
    ///
    /// * `event`: The `SensorStateChangedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully (even if the sensor was not found)
    fn handle_sensor_state_changed(&mut self, event: &SensorStateChangedEvent) -> Result<(), DockManagerError> {
        if let Some(sensor) = self.sensors.get_mut(&event.sensor_name) {
            sensor.update_value(event.new_value);
        }
        self.last_updated = event.timestamp;
        Ok(())
    }

    /// Handles a `DoorStateChangedEvent`, updating the door's state
    ///
    /// The door's state is updated to the new state specified in the event
    /// and the last updated timestamp is set
    ///
    /// # Arguments
    ///
    /// * `event`: The `DoorStateChangedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully
    fn handle_door_state_changed(&mut self, event: &DoorStateChangedEvent) -> Result<(), DockManagerError> {
        self.door_state = event.clone().new_state;
        self.last_updated = event.timestamp;
        Ok(())
    }

    /// Handles a `LoadingStatusChangedEvent`, updating the door's loading status
    ///
    /// The door's loading status is updated to the new status specified in the event
    /// and the last updated timestamp is set
    ///
    /// # Arguments
    ///
    /// * `event`: The `LoadingStatusChangedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the event was handled successfully
    fn handle_loading_status_changed(&mut self, event: &LoadingStatusChangedEvent) -> Result<(), DockManagerError> {
        self.loading_status.loading_status = event.clone().new_status;
        self.last_updated = event.timestamp;
        Ok(())
    }

    /// Handles a `TrailerStateChangedEvent`, currently logging a debug message
    ///
    /// # Arguments
    ///
    /// * `event`: The `TrailerStateChangedEvent` to be handled
    ///
    /// # Returns
    ///
    /// * `Ok(())` 
    fn handle_trailer_state_changed(&mut self, event: &TrailerStateChangedEvent) -> Result<(), DockManagerError> {
        log::debug!("trailer state changed: {:?}", event);
        Ok(())
    }

    /// Sets the manual mode of the door
    ///
    /// Updates the `manual_mode` field and the `last_updated` timestamp
    ///
    /// # Arguments
    ///
    /// * `mode`: The new `ManualMode` to set for the door
    pub fn set_manual_mode(&mut self, mode: ManualMode) {
        self.manual_mode = mode;
        self.last_updated = chrono::Local::now().naive_local();
    }

    /// Sets the docking time to the current time
    pub fn set_docking_time(&mut self) {
        self.consolidated.docking_time = Some(chrono::Local::now().naive_local());
    }

    /// Clears the docking time
    pub fn clear_docking_time(&mut self) {
        self.consolidated.docking_time = None;
    }

    /// Calculates the duration since docking, if applicable
    pub fn docking_duration(&self) -> Option<chrono::Duration> {
        self.consolidated.docking_time.map(|docking_time| {
            chrono::Local::now().naive_local().signed_duration_since(docking_time)
        })
    }

    /// Sets the fault state of the door
    ///
    /// Updates the `fault_state` field and the `last_updated` timestamp
    ///
    /// # Arguments
    ///
    /// * `state`: The new `FaultState` to set for the door
    pub fn set_fault_state(&mut self, state: FaultState) {
        self.fault_state = state;
        self.last_updated = chrono::Local::now().naive_local();
    }


    // Updates the door's state based on information from the WMS
    ///
    /// This method processes a `WmsDoorStatus` object and updates the door's
    /// `assigned_shipment`, `loading_status`, and `wms_shipment_status` fields accordingly
    /// It also generates `DockDoorEvent`s for any changes in shipment assignment or loading status
    ///
    /// # Arguments
    ///
    /// * `wms_status`: The `WmsDoorStatus` object containing the updated information from the WMS
    ///
    /// # Returns
    ///
    /// * `Ok(Vec<DockDoorEvent>)` A vector of events generated due to the WMS update
    /// * `Err(DockManagerError)` if there's an error parsing the loading status from the WMS data
    pub fn update_from_wms(&mut self, wms_status: &WmsDoorStatus) -> DockManagerResult<Vec<DockDoorEvent>> {
        let mut events = Vec::new();
        info!("WMS Door Status: {:?}", wms_status);
        if self.assigned_shipment.current_shipment != wms_status.assigned_shipment {
            let old_shipment = self.assigned_shipment.current_shipment.clone();
            self.assigned_shipment.current_shipment = wms_status.assigned_shipment.clone();

            if let Some(shipment_id) = &wms_status.assigned_shipment {
                events.push(DockDoorEvent::ShipmentAssigned(ShipmentAssignedEvent {
                    plant_id: wms_status.plant.clone(),
                    dock_name: self.dock_name.clone(),
                    shipment_id: shipment_id.clone(),
                    timestamp: chrono::Local::now().naive_local(),
                    previous_shipment: old_shipment,
                }));
            } else if let Some(previous_shipment) = old_shipment {
                events.push(DockDoorEvent::ShipmentUnassigned(ShipmentUnassignedEvent {
                    plant_id: wms_status.plant.clone(),
                    dock_name: self.dock_name.clone(),
                    shipment_id: previous_shipment,
                    timestamp: chrono::Local::now().naive_local(),
                }));
            }
        }

        let new_loading_status = LoadingStatus::from_str(&wms_status.loading_status)
            .unwrap_or(LoadingStatus::Idle);
        if self.loading_status.loading_status != new_loading_status {
            events.push(DockDoorEvent::LoadingStatusChanged(LoadingStatusChangedEvent {
                plant_id: wms_status.plant.clone(),
                dock_name: self.dock_name.clone(),
                old_status: self.loading_status.loading_status,
                new_status: new_loading_status,
                timestamp: chrono::Local::now().naive_local(),
            }));
            self.loading_status.loading_status = new_loading_status;
        }

        self.loading_status.wms_shipment_status = wms_status.wms_shipment_status.clone();
        if wms_status.is_preload.is_some() {
            self.consolidated.is_preload = wms_status.is_preload.unwrap();
        }

        Ok(events)
    }

    pub fn check_loading_readiness(&self) -> bool {
        self.door_position == DoorPosition::Open &&
            self.dock_lock_state == DockLockState::Engaged &&
            self.leveler_position == LevelerPosition::Extended &&
            self.fault_state == FaultState::NoFault &&
            self.trailer_state == TrailerState::Docked &&
            self.manual_mode == ManualMode::Disabled &&
            self.restraint_state == RestraintState::Locked &&
            self.trailer_position_state == TrailerPositionState::Proper &&
            !self.trailer_door_fault &&
            !self.dock_lock_fault &&
            !self.door_fault &&
            !self.emergency_stop &&
            !self.leveler_fault
    }
}
```

--------------------------------------------------------------------------------

# src\models\ievents.rs
```
use chrono::NaiveDateTime;
use serde::{Deserialize, Serialize};
use crate::models::istates::DoorState;
use crate::models::istatus::LoadingStatus;
use crate::models::{DbInsert, TrailerState, WmsEvent};

/// Represents the different types of events that can occur at a dock door
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DockDoorEvent {
    DockAssigned(DockAssignedEvent),
    DockUnassigned(DockUnassignedEvent),
    TrailerDocked(TrailerDockedEvent),
    TrailerDeparted(TrailerDepartedEvent),
    LoadingStarted(LoadingStartedEvent),
    LoadingCompleted(LoadingCompletedEvent),
    SensorStateChanged(SensorStateChangedEvent),
    DoorStateChanged(DoorStateChangedEvent),
    LoadingStatusChanged(LoadingStatusChangedEvent),
    TrailerStateChanged(TrailerStateChangedEvent),
    ShipmentAssigned(ShipmentAssignedEvent),
    ShipmentUnassigned(ShipmentUnassignedEvent),
    WmsEvent(WmsEventWrapper),
    ShipmentStarted(ShipmentStartedEvent),
    ShipmentSuspended(ShipmentSuspendedEvent),
    ShipmentCancelled(ShipmentCancelledEvent),
    ShipmentResumed(ShipmentResumedEvent),
    PriorityUpdated(PriorityUpdatedEvent),
    LoadPlanSaved(LoadPlanSavedEvent),
    ShipmentForcedClosed(ShipmentForcedClosedEvent),
    LoadQuantityAdjusted(LoadQuantityAdjustedEvent),
    DriverCheckedIn(DriverCheckedInEvent),
    TrailerRejected(TrailerRejectedEvent),
    LgvStartLoading(LgvStartLoadingEvent),
    FirstDrop(FirstDropEvent),
    ShipmentCheckout(ShipmentCheckoutEvent),
    TrailerPatternProcessed(TrailerPatternProcessedEvent),
    AppointmentUpdated(AppointmentUpdatedEvent),
    TripProcessed(TripProcessedEvent),
    UnknownWmsEvent(UnknownWmsEventEvent),
}

impl DockDoorEvent {
    pub fn get_dock_name(&self) -> &str {
        match self {
            DockDoorEvent::DockAssigned(e) => &e.dock_name,
            DockDoorEvent::DockUnassigned(e) => &e.dock_name,
            DockDoorEvent::TrailerDocked(e) => &e.dock_name,
            DockDoorEvent::LoadingStarted(e) => &e.dock_name,
            DockDoorEvent::LoadingCompleted(e) => &e.dock_name,
            DockDoorEvent::TrailerDeparted(e) => &e.dock_name,
            DockDoorEvent::ShipmentAssigned(e) => &e.dock_name,
            DockDoorEvent::ShipmentUnassigned(e) => &e.dock_name,
            DockDoorEvent::SensorStateChanged(e) => &e.dock_name,
            DockDoorEvent::DoorStateChanged(e) => &e.dock_name,
            DockDoorEvent::LoadingStatusChanged(e) => &e.dock_name,
            DockDoorEvent::TrailerStateChanged(e) => &e.dock_name,
            DockDoorEvent::WmsEvent(e) => &e.dock_name,
            DockDoorEvent::ShipmentStarted(e) => &e.base_event.dock_name,
            DockDoorEvent::ShipmentSuspended(e) => &e.base_event.dock_name,
            DockDoorEvent::ShipmentCancelled(e) => &e.base_event.dock_name,
            DockDoorEvent::ShipmentResumed(e) => &e.base_event.dock_name,
            DockDoorEvent::PriorityUpdated(e) => &e.base_event.dock_name,
            DockDoorEvent::LoadPlanSaved(e) => &e.base_event.dock_name,
            DockDoorEvent::ShipmentForcedClosed(e) => &e.base_event.dock_name,
            DockDoorEvent::LoadQuantityAdjusted(e) => &e.base_event.dock_name,
            DockDoorEvent::DriverCheckedIn(e) => &e.base_event.dock_name,
            DockDoorEvent::TrailerRejected(e) => &e.base_event.dock_name,
            DockDoorEvent::LgvStartLoading(e) => &e.base_event.dock_name,
            DockDoorEvent::FirstDrop(e) => &e.base_event.dock_name,
            DockDoorEvent::ShipmentCheckout(e) => &e.base_event.dock_name,
            DockDoorEvent::TrailerPatternProcessed(e) => &e.base_event.dock_name,
            DockDoorEvent::AppointmentUpdated(e) => &e.base_event.dock_name,
            DockDoorEvent::TripProcessed(e) => &e.base_event.dock_name,
            DockDoorEvent::UnknownWmsEvent(e) => &e.base_event.dock_name,
        }
    }

    pub fn get_plant_id(&self) -> &str {
        match self {
            DockDoorEvent::DockAssigned(e) => &e.plant_id,
            DockDoorEvent::DockUnassigned(e) => &e.plant_id,
            DockDoorEvent::TrailerDocked(e) => &e.plant_id,
            DockDoorEvent::TrailerDeparted(e) => &e.plant_id,
            DockDoorEvent::LoadingStarted(e) => &e.plant_id,
            DockDoorEvent::LoadingCompleted(e) => &e.plant_id,
            DockDoorEvent::SensorStateChanged(e) => &e.plant_id,
            DockDoorEvent::DoorStateChanged(e) => &e.plant_id,
            DockDoorEvent::LoadingStatusChanged(e) => &e.plant_id,
            DockDoorEvent::TrailerStateChanged(e) => &e.plant_id,
            DockDoorEvent::ShipmentAssigned(e) => &e.plant_id,
            DockDoorEvent::ShipmentUnassigned(e) => &e.plant_id,
            DockDoorEvent::WmsEvent(e) => &e.plant_id,
            DockDoorEvent::ShipmentStarted(e) => &e.base_event.plant_id,
            DockDoorEvent::ShipmentSuspended(e) => &e.base_event.plant_id,
            DockDoorEvent::ShipmentCancelled(e) => &e.base_event.plant_id,
            DockDoorEvent::ShipmentResumed(e) => &e.base_event.plant_id,
            DockDoorEvent::PriorityUpdated(e) => &e.base_event.plant_id,
            DockDoorEvent::LoadPlanSaved(e) => &e.base_event.plant_id,
            DockDoorEvent::ShipmentForcedClosed(e) => &e.base_event.plant_id,
            DockDoorEvent::LoadQuantityAdjusted(e) => &e.base_event.plant_id,
            DockDoorEvent::DriverCheckedIn(e) => &e.base_event.plant_id,
            DockDoorEvent::TrailerRejected(e) => &e.base_event.plant_id,
            DockDoorEvent::LgvStartLoading(e) => &e.base_event.plant_id,
            DockDoorEvent::FirstDrop(e) => &e.base_event.plant_id,
            DockDoorEvent::ShipmentCheckout(e) => &e.base_event.plant_id,
            DockDoorEvent::TrailerPatternProcessed(e) => &e.base_event.plant_id,
            DockDoorEvent::AppointmentUpdated(e) => &e.base_event.plant_id,
            DockDoorEvent::TripProcessed(e) => &e.base_event.plant_id,
            DockDoorEvent::UnknownWmsEvent(e) => &e.base_event.plant_id,
        }
    }

    pub fn from_wms_event(wms_event: WmsEvent) -> Self {
        let base_event = WmsEventWrapper {
            plant_id: wms_event.plant.clone(),
            dock_name: wms_event.dock_name.clone(),
            shipment_id: wms_event.shipment_id.clone(),
            event_type: wms_event.message_type.clone(),
            timestamp: wms_event.log_dttm.unwrap_or_else(|| chrono::Local::now().naive_local()),
            message_source: wms_event.message_source.clone(),
            message_notes: wms_event.message_notes.clone(),
            result_code: wms_event.result_code,
        };

        match wms_event.message_type.as_str() {
            "STARTED_SHIPMENT" => DockDoorEvent::ShipmentStarted(ShipmentStartedEvent { base_event }),
            "SUSPENDED_SHIPMENT" => DockDoorEvent::ShipmentSuspended(ShipmentSuspendedEvent { base_event }),
            "CANCELLED_SHIPMENT" => DockDoorEvent::ShipmentCancelled(ShipmentCancelledEvent { base_event }),
            "RESUMED_SHIPMENT" => DockDoorEvent::ShipmentResumed(ShipmentResumedEvent { base_event }),
            "UPDATED_PRIORITY" => DockDoorEvent::PriorityUpdated(PriorityUpdatedEvent { base_event }),
            "SDM_LOAD_PLAN" => DockDoorEvent::LoadPlanSaved(LoadPlanSavedEvent { base_event }),
            "SHIPMENT_FORCED_CLOSED" => DockDoorEvent::ShipmentForcedClosed(ShipmentForcedClosedEvent { base_event }),
            "LOAD_QTY_ADJUSTED" => DockDoorEvent::LoadQuantityAdjusted(LoadQuantityAdjustedEvent { base_event }),
            "SDM_CHECK_IN" => DockDoorEvent::DriverCheckedIn(DriverCheckedInEvent { base_event }),
            "SDM_TRAILER_REJECTION" => DockDoorEvent::TrailerRejected(TrailerRejectedEvent { base_event }),
            "DOCK_ASSIGNMENT" => DockDoorEvent::DockAssigned(DockAssignedEvent::from(base_event)),
            "LGV_START_LOADING" => DockDoorEvent::LgvStartLoading(LgvStartLoadingEvent { base_event }),
            "FIRST_DROP" => DockDoorEvent::FirstDrop(FirstDropEvent { base_event }),
            "COMPLETED_LOAD" => DockDoorEvent::LoadingCompleted(LoadingCompletedEvent::from(base_event)),
            "CHECKOUT" => DockDoorEvent::ShipmentCheckout(ShipmentCheckoutEvent { base_event }),
            "TRK_PTRN" => DockDoorEvent::TrailerPatternProcessed(TrailerPatternProcessedEvent { base_event }),
            "APPT_UPDATE" => DockDoorEvent::AppointmentUpdated(AppointmentUpdatedEvent { base_event }),
            "PROCTRIP" => DockDoorEvent::TripProcessed(TripProcessedEvent { base_event }),
            _ => DockDoorEvent::UnknownWmsEvent(UnknownWmsEventEvent { base_event }),
        }
    }

    pub fn from_db_insert(db_insert: &DbInsert) -> Self {
        DockDoorEvent::WmsEvent(WmsEventWrapper {
            plant_id: db_insert.PLANT.clone(),
            dock_name: db_insert.DOOR_NAME.clone(),
            shipment_id: db_insert.SHIPMENT_ID.clone().unwrap_or_default(),
            event_type: db_insert.EVENT_TYPE.clone(),
            timestamp: db_insert.LOG_DTTM,
            message_source: "DB_INSERT".to_string(),
            message_notes: Some(db_insert.NOTES.clone()),
            result_code: db_insert.SUCCESS,
        })
    }

    pub fn get_shipment_id(&self) -> Option<String> {
        match self {
            DockDoorEvent::ShipmentAssigned(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::ShipmentUnassigned(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::DockAssigned(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::DockUnassigned(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::TrailerDocked(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::TrailerDeparted(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::LoadingStarted(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::LoadingCompleted(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::LoadingStatusChanged(_) => None,
            DockDoorEvent::WmsEvent(e) => Some(e.shipment_id.clone()),
            DockDoorEvent::SensorStateChanged(_) => None,
            DockDoorEvent::DoorStateChanged(_) => None,
            DockDoorEvent::TrailerStateChanged(_) => None,
            DockDoorEvent::ShipmentStarted(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::ShipmentSuspended(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::ShipmentCancelled(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::ShipmentResumed(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::PriorityUpdated(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::LoadPlanSaved(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::ShipmentForcedClosed(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::LoadQuantityAdjusted(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::DriverCheckedIn(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::TrailerRejected(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::LgvStartLoading(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::FirstDrop(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::ShipmentCheckout(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::TrailerPatternProcessed(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::AppointmentUpdated(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::TripProcessed(e) => Some(e.base_event.shipment_id.clone()),
            DockDoorEvent::UnknownWmsEvent(e) => Some(e.base_event.shipment_id.clone()),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WmsEventWrapper {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub event_type: String,
    pub timestamp: NaiveDateTime,
    pub message_source: String,
    pub message_notes: Option<String>,
    pub result_code: i32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DockAssignedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub timestamp: NaiveDateTime,
}

impl From<WmsEventWrapper> for DockAssignedEvent {
    fn from(wrapper: WmsEventWrapper) -> Self {
        Self {
            plant_id: wrapper.plant_id,
            dock_name: wrapper.dock_name,
            shipment_id: wrapper.shipment_id,
            timestamp: wrapper.timestamp,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DockUnassignedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrailerDockedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrailerDepartedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoadingStartedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoadingCompletedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub timestamp: NaiveDateTime,
}

impl From<WmsEventWrapper> for LoadingCompletedEvent {
    fn from(wrapper: WmsEventWrapper) -> Self {
        Self {
            plant_id: wrapper.plant_id,
            dock_name: wrapper.dock_name,
            shipment_id: wrapper.shipment_id,
            timestamp: wrapper.timestamp,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SensorStateChangedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub sensor_name: String,
    pub old_value: Option<u8>,
    pub new_value: Option<u8>,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DoorStateChangedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub old_state: DoorState,
    pub new_state: DoorState,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoadingStatusChangedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub old_status: LoadingStatus,
    pub new_status: LoadingStatus,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrailerStateChangedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub old_state: TrailerState,
    pub new_state: TrailerState,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentAssignedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub timestamp: NaiveDateTime,
    pub previous_shipment: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentUnassignedEvent {
    pub plant_id: String,
    pub dock_name: String,
    pub shipment_id: String,
    pub timestamp: NaiveDateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentStartedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentSuspendedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentCancelledEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentResumedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PriorityUpdatedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoadPlanSavedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentForcedClosedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoadQuantityAdjustedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DriverCheckedInEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrailerRejectedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LgvStartLoadingEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FirstDropEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentCheckoutEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrailerPatternProcessedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AppointmentUpdatedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TripProcessedEvent {
    pub base_event: WmsEventWrapper,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UnknownWmsEventEvent {
    pub base_event: WmsEventWrapper,
}```

--------------------------------------------------------------------------------

# src\models\isensor.rs
```
//! # Dock Sensor Representation

//! This module defines the `DockSensor` enum and the `SensorData` struct, which together represent the various sensors 
//! associated with a dock door and the data collected from those sensors. The `SensorType` enum provides a type-safe 
//! way to identify different sensor types.

use chrono::{Local, NaiveDateTime};
use serde::{Deserialize, Serialize};

/// Represents the different types of sensors that can be associated with a dock door.
/// Each sensor type holds its specific `SensorData`.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DockSensor {
    AutoDisengaging(SensorData),
    AutoEngaging(SensorData),
    FaultPresence(SensorData),
    FaultTrailerDoors(SensorData),
    RhDockReady(SensorData),
    RhDokLockFault(SensorData),
    RhDoorFault(SensorData),
    RhDoorOpen(SensorData),
    RhEstop(SensorData),
    RhLevelerFault(SensorData),
    RhLevelrReady(SensorData),
    RhManualMode(SensorData),
    RhRestraintEngaged(SensorData),
    TrailerAngle(SensorData),
    TrailerAtDoor(SensorData),
    TrailerCentering(SensorData),
    TrailerDistance(SensorData),
}

/// Holds the data associated with a specific sensor reading
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SensorData {
    /// The name of the dock door the sensor belongs to
    pub door_name: String,
    /// The IP address of the PLC controlling the door
    pub door_ip: String,
    /// The name or type of the sensor
    pub sensor: String,
    /// The PLC address where the sensor's value is stored
    pub address: String,
    /// The current value read from the sensor
    pub current_value: Option<u8>,
    /// The previous value read from the sensor
    pub previous_value: Option<u8>,
    /// The timestamp of the last sensor update
    pub last_updated: NaiveDateTime,
    /// Information about the last reported change in the sensor's value
    pub last_reported_change: Option<(Option<u8>, Option<u8>)>,
}

/// Provides a type-safe representation of the different sensor types
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum SensorType {
    AutoDisengaging,
    AutoEngaging,
    FaultPresence,
    FaultTrailerDoors,
    RhDockReady,
    RhDokLockFault,
    RhDoorFault,
    RhDoorOpen,
    RhEstop,
    RhLevelerFault,
    RhLevelrReady,
    RhManualMode,
    RhRestraintEngaged,
    TrailerAngle,
    TrailerAtDoor,
    TrailerCentering,
    TrailerDistance,
}

impl std::str::FromStr for SensorType {
    type Err = String;

    /// Converts a string representation into a `SensorType`.
    ///
    /// This method attempts to parse the input string (case-insensitively) and match it to a corresponding `SensorType` variant.
    /// If a match is found, it returns the `SensorType`; otherwise, it returns an error indicating an unknown sensor type.
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_uppercase().as_str()  {
            "AUTO_DISENGAGING" => Ok(SensorType::AutoDisengaging),
            "AUTO_ENGAGING" => Ok(SensorType::AutoEngaging),
            "FAULT_PRESENCE" => Ok(SensorType::FaultPresence),
            "FAULT_TRAILER_DOORS" => Ok(SensorType::FaultTrailerDoors),
            "RH_DOCK_READY" => Ok(SensorType::RhDockReady),
            "RH_DOKLOCK_FAULT" => Ok(SensorType::RhDokLockFault),
            "RH_DOOR_FAULT" => Ok(SensorType::RhDoorFault),
            "RH_DOOR_OPEN" => Ok(SensorType::RhDoorOpen),
            "RH_ESTOP" => Ok(SensorType::RhEstop),
            "RH_LEVELER_FAULT" => Ok(SensorType::RhLevelerFault),
            "RH_LEVELR_READY" => Ok(SensorType::RhLevelrReady),
            "RH_MANUAL_MODE" => Ok(SensorType::RhManualMode),
            "RH_RESTRAINT_ENGAGED" => Ok(SensorType::RhRestraintEngaged),
            "TRAILER_ANGLE" => Ok(SensorType::TrailerAngle),
            "TRAILER_AT_DOOR" => Ok(SensorType::TrailerAtDoor),
            "TRAILER_CENTERING" => Ok(SensorType::TrailerCentering),
            "TRAILER_DISTANCE" => Ok(SensorType::TrailerDistance),
            _ => Err(format!("Unknown sensor type: {}", s)),
        }
    }
}

impl DockSensor {
    /// Creates a new `DockSensor` instance based on the provided sensor type and data
    ///
    /// # Arguments
    ///
    /// * `door_name`: The name of the dock door the sensor belongs to
    /// * `door_ip`: The IP address of the PLC controlling the door
    /// * `sensor_type`: A string representing the type of sensor
    /// * `address`: The PLC address where the sensor's value is stored
    ///
    /// # Returns
    ///
    /// A new `DockSensor` instance of the appropriate variant, containing the provided `SensorData`
    ///
    /// # Panics
    ///
    /// This function will panic if an unknown `sensor_type` is provided
    pub fn new(door_name: &str, door_ip: &str, sensor_type: &str, address: &str) -> Self {
        let sensor_data = SensorData {
            door_name: door_name.to_string(),
            door_ip: door_ip.to_string(),
            sensor: sensor_type.to_string(),
            address: address.to_string(),
            current_value: None,
            previous_value: None,
            last_updated: Local::now().naive_local(),
            last_reported_change: None,
        };
        match sensor_type {
            "AUTO_DISENGAGING" => DockSensor::AutoDisengaging(sensor_data),
            "AUTO_ENGAGING" => DockSensor::AutoEngaging(sensor_data),
            "FAULT_PRESENCE" => DockSensor::FaultPresence(sensor_data),
            "FAULT_TRAILER_DOORS" => DockSensor::FaultTrailerDoors(sensor_data),
            "RH_DOCK_READY" => DockSensor::RhDockReady(sensor_data),
            "RH_DOKLOCK_FAULT" => DockSensor::RhDokLockFault(sensor_data),
            "RH_DOOR_FAULT" => DockSensor::RhDoorFault(sensor_data),
            "RH_DOOR_OPEN" => DockSensor::RhDoorOpen(sensor_data),
            "RH_ESTOP" => DockSensor::RhEstop(sensor_data),
            "RH_LEVELER_FAULT" => DockSensor::RhLevelerFault(sensor_data),
            "RH_LEVELR_READY" => DockSensor::RhLevelrReady(sensor_data),
            "RH_MANUAL_MODE" => DockSensor::RhManualMode(sensor_data),
            "RH_RESTRAINT_ENGAGED" => DockSensor::RhRestraintEngaged(sensor_data),
            "TRAILER_ANGLE" => DockSensor::TrailerAngle(sensor_data),
            "TRAILER_AT_DOOR" => DockSensor::TrailerAtDoor(sensor_data),
            "TRAILER_CENTERING" => DockSensor::TrailerCentering(sensor_data),
            "TRAILER_DISTANCE" => DockSensor::TrailerDistance(sensor_data),
            _ => panic!("Unknown sensor type: {}", sensor_type)
        }
    }

    /// Updates the sensor's value and metadata
    ///
    /// # Arguments
    ///
    /// * `new_value`: The new value read from the sensor
    pub fn update_value(&mut self, new_value: Option<u8>) {
        let sensor_data = self.get_sensor_data_mut();
        sensor_data.previous_value = sensor_data.current_value;
        sensor_data.current_value = new_value;
        sensor_data.last_updated = Local::now().naive_local();
    }

    /// Provides immutable access to the sensor's data
    ///
    /// # Returns
    ///
    /// A reference to the `SensorData` associated with this `DockSensor`
    pub fn get_sensor_data(&self) -> &SensorData {
        match self {
            DockSensor::AutoDisengaging(data) => data,
            DockSensor::AutoEngaging(data) => data,
            DockSensor::FaultPresence(data) => data,
            DockSensor::FaultTrailerDoors(data) => data,
            DockSensor::RhDockReady(data) => data,
            DockSensor::RhDokLockFault(data) => data,
            DockSensor::RhDoorFault(data) => data,
            DockSensor::RhDoorOpen(data) => data,
            DockSensor::RhEstop(data) => data,
            DockSensor::RhLevelerFault(data) => data,
            DockSensor::RhLevelrReady(data) => data,
            DockSensor::RhManualMode(data) => data,
            DockSensor::RhRestraintEngaged(data) => data,
            DockSensor::TrailerAngle(data) => data,
            DockSensor::TrailerAtDoor(data) => data,
            DockSensor::TrailerCentering(data) => data,
            DockSensor::TrailerDistance(data) => data,
        }
    }

    /// Provides mutable access to the sensor's data (for internal use)
    pub(crate) fn get_sensor_data_mut(&mut self) -> &mut SensorData {
        match self {
            DockSensor::AutoDisengaging(data) => data,
            DockSensor::AutoEngaging(data) => data,
            DockSensor::FaultPresence(data) => data,
            DockSensor::FaultTrailerDoors(data) => data,
            DockSensor::RhDockReady(data) => data,
            DockSensor::RhDokLockFault(data) => data,
            DockSensor::RhDoorFault(data) => data,
            DockSensor::RhDoorOpen(data) => data,
            DockSensor::RhEstop(data) => data,
            DockSensor::RhLevelerFault(data) => data,
            DockSensor::RhLevelrReady(data) => data,
            DockSensor::RhManualMode(data) => data,
            DockSensor::RhRestraintEngaged(data) => data,
            DockSensor::TrailerAngle(data) => data,
            DockSensor::TrailerAtDoor(data) => data,
            DockSensor::TrailerCentering(data) => data,
            DockSensor::TrailerDistance(data) => data,
        }
    }
}

```

--------------------------------------------------------------------------------

# src\models\istates.rs
```
use serde::{Deserialize, Serialize};
use derive_more::FromStr;

/// Represents the different states a dock door can be in.
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum DoorState {
    /// The door is not assigned to any shipment.
    Unassigned,
    /// The door has been assigned to a shipment but the driver has not yet checked in.
    Assigned,
    /// The driver has checked in at the door.
    DriverCheckedIn,
    /// The trailer is approaching the door.
    TrailerApproaching,
    /// The trailer is in the process of docking.
    TrailerDocking,
    /// The trailer is fully docked at the door.
    TrailerDocked,
    /// The door is ready for loading/unloading.
    DoorReady,
    /// The loading/unloading process is in progress.
    Loading,
    /// The loading/unloading process is complete.
    LoadingCompleted,
    /// The shipment is complete and the trailer is waiting to exit.
    WaitingForExit,
}

/// Represents the two possible states of a trailer: docked or undocked.
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum TrailerState {
    /// The trailer is docked at a door.
    Docked,
    /// The trailer is not docked at any door.
    Undocked,
}

/// Represents whether manual mode is enabled or disabled for a dock door.
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum ManualMode {
    /// Manual mode is enabled, allowing manual control of the door.
    Enabled,
    /// Manual mode is disabled, the door operates automatically.
    Disabled,
}

/// Represents the state of the dock lock: engaged or disengaged.
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum DockLockState {
    /// The dock lock is engaged, securing the trailer to the dock.
    Engaged,
    /// The dock lock is disengaged, allowing the trailer to move.
    Disengaged,
}

/// Represents the position of the door: open or closed.
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum DoorPosition {
    /// The door is open.
    Open,
    /// The door is closed.
    Closed,
}

/// Represents the position of the leveler: stored or extended.
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum LevelerPosition {
    /// The leveler is stored, not in use.
    Stored,
    /// The leveler is extended, bridging the gap between the dock and the trailer.
    Extended,
}

/// Represents the fault state of a component: no fault or fault present
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum FaultState {
    /// No fault is detected.
    NoFault,
    /// A fault is present.
    FaultPresent,
}

/// Represents the state of the restraint: locking, unlocking, locked, or unlocked
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum RestraintState {
    /// The restraint is in the process of locking
    Locking,
    /// The restraint is in the process of unlocking
    Unlocking,
    /// The restraint is locked
    Locked,
    /// The restraint is unlocked
    Unlocked,
}

/// Represents the position state of the trailer: proper or improper
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum TrailerPositionState {
    /// The trailer is in the proper position
    Proper,
    /// The trailer is not in the proper position
    Improper,
}

#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr)]
pub enum LoadTypeState {
    /// The Load is a Live Load Shipment
    LiveLoad,
    /// The Load is a Prelaod Load Shipment
    Preload,
}```

--------------------------------------------------------------------------------

# src\models\istatus.rs
```
//! # Warehouse Management System (WMS) Data Structures

//! This module defines data structures that interact with and represent information from the Warehouse Management System (WMS). 
//! These structures facilitate the seamless integration and processing of WMS data within the IQX Dock Manager application.

use std::collections::HashSet;
use chrono::NaiveDateTime;
use derive_more::{Constructor, Display, FromStr};
use serde::{Deserialize, Serialize};
use sqlx_oldapi::FromRow;

/// Represents the various loading statuses a shipment can have in the WMS.
#[derive(Debug, Clone, PartialEq, Copy, Serialize, Deserialize, FromStr, Display)]
pub enum LoadingStatus {
    /// The dock is idle, not assigned to any shipment.
    Idle,
    /// The shipment is in the Customer Service Order (CSO) stage.
    CSO,
    /// The shipment is undergoing warehouse inspection.
    WhseInspection,
    /// The system is allocating an LGV (Laser Guided Vehicle) for the shipment.
    LgvAllocation,
    /// The shipment is currently being loaded.
    Loading,
    /// The loading process is temporarily suspended.
    Suspended,
    /// The loading is completed.
    Completed,
    /// The loaded shipment is awaiting departure.
    WaitingForExit,
    /// The shipment has been canceled.
    CancelledShipment,
    /// The shipment has been started with anticipation.
    StartedWithAnticipation,
}

/// Represents the status of a dock door as retrieved from the WMS.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, FromRow)]
pub struct WmsDoorStatus {
    /// The plant associated with the event
    #[sqlx(rename = "PLANT")]
    pub plant: String,
    /// The name of the dock door.
    pub dock_name: String,
    /// The shipment currently assigned to the dock door (if any).
    pub assigned_shipment: Option<String>,
    /// The percentage progress of the loading process.
    pub loading_progress_percent: Option<i32>,
    /// The current loading status of the dock door.
    pub loading_status: String,
    /// The status of the shipment in the WMS.
    pub wms_shipment_status: Option<String>,
    /// Any shipping fault code associated with the shipment.
    pub shipping_fault_code: Option<String>,
    /// The upper limit for the number of shipments allowed to be loading simultaneously.
    pub upper_ship_limit: i32,
    /// The current number of shipments in the loading state.
    pub shipments_loading: i32,
    pub is_preload: Option<bool>,
}

/// Represents an event related to a shipment in the WMS
#[derive(Debug, Clone, Serialize, Deserialize, FromRow, Eq, PartialEq, Hash)]
pub struct WmsEvent {
    /// The plant associated with the event
    #[sqlx(rename = "PLANT")]
    pub plant: String,
    /// The dock name associated with the event
    #[sqlx(rename = "DOCK_NAME")]
    pub dock_name: String,
    /// The ID of the shipment the event pertains to
    #[sqlx(rename = "SHIPMENT_ID")]
    pub shipment_id: String,
    /// The date and time the event occurred
    #[sqlx(rename = "LOG_DTTM")]
    pub log_dttm: Option<NaiveDateTime>,
    /// The source system that generated the event
    #[sqlx(rename = "MESSAGE_SOURCE")]
    pub message_source: String,
    /// The type of event
    #[sqlx(rename = "MESSAGE_TYPE")]
    pub message_type: String,
    /// An identifier for the event type
    #[sqlx(rename = "MESSAGE_TYPE_ID")]
    pub message_type_id: Option<String>,
    /// Additional notes or details about the event
    #[sqlx(rename = "MESSAGE_NOTES")]
    pub message_notes: Option<String>,
    /// A code indicating the result or outcome of the event
    #[sqlx(rename = "RESULT_CODE")]
    pub result_code: i32,
}

/// Represents a shipment that is or has been assigned to a dock door
#[derive(Debug, Clone, Serialize, Deserialize, Constructor, Default, Eq, PartialEq)]
pub struct AssignedShipment {
    /// The ID of the currently assigned shipment
    pub current_shipment: Option<String>,
    /// The date and time when the current shipment was assigned
    pub assignment_dttm: Option<NaiveDateTime>,
    /// The date and time when the current shipment was unassigned
    pub unassignment_dttm: Option<NaiveDateTime>,
    /// The ID of the previously assigned shipment
    pub previous_shipment: Option<String>,
    /// The date and time when the previous shipment was completed
    pub previous_completed_dttm: Option<NaiveDateTime>,
    /// A collection of WMS events related to the shipment
    pub events: HashSet<WmsEvent>,
}

impl AssignedShipment {
    /// Adds a WMS event to the shipment's event history
    pub fn add_event(&mut self, event: WmsEvent) {
        self.events.insert(event);
    }

    /// Clears the shipment's event history
    pub fn clear_events(&mut self) {
        self.events.clear();
    }
}

```

--------------------------------------------------------------------------------

# src\models\mod.rs
```
pub mod plcvalue;
pub mod idoor;
pub mod istatus;
pub mod isensor;
pub mod ievents;
pub mod istates;
pub mod idb_log;
pub mod consolidated_dock_event;

pub use idoor::*;
pub use istatus::*;
pub use isensor::*;
pub use ievents::*;
pub use istates::*;
pub use idb_log::*;

use chrono::{Local, NaiveDateTime};
pub use plcvalue::*;

pub fn local_now() -> NaiveDateTime {
    Local::now().naive_local()
}```

--------------------------------------------------------------------------------

# src\models\plcvalue.rs
```
//! # PLC Value Representation

//! This module defines the `PlcVal` struct, which represents a value read from a PLC (Programmable Logic Controller) sensor. 
//! It encapsulates the essential information associated with a sensor reading, including the plant ID, door name, door IP address, 
//! sensor name, the actual sensor value, and the timestamp of the reading.


use chrono::{NaiveDateTime, Local};
use serde::{Serialize, Deserialize};

/// Represents a value read from a PLC sensor.
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PlcVal {
    /// The ID of the plant where the sensor is located.
    pub plant_id: String,
    /// The name of the dock door associated with the sensor.
    pub door_name: String,
    /// The IP address of the dock door's PLC.
    pub door_ip: String,
    /// The name of the sensor.
    pub sensor_name: String,
    /// The value read from the sensor.
    pub value: u8,
    /// The timestamp when the sensor value was read.
    pub timestamp: NaiveDateTime,
}

impl PlcVal {
    /// Creates a new `PlcVal` instance.
    /// 
    /// # Arguments
    /// 
    /// * `plant_id`: The ID of the plant.
    /// * `door_name`: The name of the dock door.
    /// * `door_ip`: The IP address of the dock door's PLC.
    /// * `sensor_name`: The name of the sensor.
    /// * `value`: The sensor value.
    /// 
    /// # Returns
    /// 
    /// A new `PlcVal` instance with the provided information and the current local time as the timestamp.
    pub fn new(plant_id: &str, door_name: &str, door_ip: &str, sensor_name: &str, value: u8) -> Self {
        PlcVal {
            plant_id: plant_id.to_string(),
            door_name: door_name.to_string(),
            door_ip: door_ip.to_string(),
            sensor_name: sensor_name.to_string(),
            value,
            timestamp: Local::now().naive_local(),
        }
    }
}```

--------------------------------------------------------------------------------

# src\monitoring\mod.rs
```
mod monitoring_queue;
mod monitoring_worker;

pub use monitoring_queue::*;
pub use monitoring_worker::*;
```

--------------------------------------------------------------------------------

# src\monitoring\monitoring_queue.rs
```
use dashmap::DashSet;
use std::sync::Arc;
use chrono::{NaiveDateTime, Duration, Utc};
use serde::{Serialize, Deserialize};

/// Represents different types of items that can be monitored in the dock monitoring system.
#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq, Hash)]
pub enum MonitoringItem {
    /// Represents a suspended shipment.
    SuspendedShipment {
        /// The ID of the plant where the suspension occurred.
        plant_id: String,
        /// The name of the dock door where the shipment is suspended.
        door_name: String,
        /// The ID of the suspended shipment.
        shipment_id: String,
        /// The timestamp when the shipment was suspended.
        suspended_at: NaiveDateTime,
        /// The user who suspended the shipment.
        user: String,
        /// The timestamp when this item was added to the monitoring queue.
        added_to_queue: NaiveDateTime,
    },
    /// Represents a trailer that has docked but loading hasn't started.
    TrailerDockedNotStarted {
        /// The ID of the plant where the trailer is docked.
        plant_id: String,
        /// The name of the dock door where the trailer is docked.
        door_name: String,
        /// The timestamp when the trailer docked.
        docked_at: NaiveDateTime,
        /// The timestamp when this item was added to the monitoring queue.
        added_to_queue: NaiveDateTime,
    },
    /// Represents a shipment that has started loading but the dock is not ready.
    ShipmentStartedLoadNotReady {
        /// The ID of the plant where the shipment is located.
        plant_id: String,
        /// The name of the dock door where the shipment is located.
        door_name: String,
        /// The ID of the shipment.
        shipment_id: String,
        /// The timestamp when the shipment started loading.
        started_at: NaiveDateTime,
        /// The timestamp when this item was added to the monitoring queue.
        added_to_queue: NaiveDateTime,
    },
    /// Represents a potential trailer hostage situation.
    TrailerHostage {
        /// The ID of the plant where the potential hostage situation is occurring.
        plant_id: String,
        /// The name of the dock door involved in the potential hostage situation.
        door_name: String,
        /// The ID of the shipment associated with the potential hostage situation.
        shipment_id: Option<String>,
        /// The timestamp when the potential hostage situation was first detected.
        detected_at: NaiveDateTime,
        /// The timestamp when this item was added to the monitoring queue.
        added_to_queue: NaiveDateTime,
    },
}

/// A thread-safe queue for monitoring items in the dock monitoring system.
pub struct MonitoringQueue {
    /// The internal DashSet storing the monitoring items.
    queue: Arc<DashSet<MonitoringItem>>,
}

impl MonitoringQueue {
    /// Creates a new, empty `MonitoringQueue`.
    ///
    /// # Returns
    ///
    /// A new `MonitoringQueue` instance.
    pub fn new() -> Self {
        Self {
            queue: Arc::new(DashSet::new()),
        }
    }

    /// Adds a new item to the monitoring queue.
    ///
    /// If the item already exists in the queue (based on its hash and equality),
    /// it will not be added again. The `added_to_queue` timestamp is set to the current time.
    ///
    /// # Arguments
    ///
    /// * `item` - The `MonitoringItem` to be added to the queue.
    pub fn add(&self, mut item: MonitoringItem) {
        let now = Utc::now().naive_utc();
        match item {
            MonitoringItem::SuspendedShipment { ref mut added_to_queue, .. } |
            MonitoringItem::TrailerDockedNotStarted { ref mut added_to_queue, .. } |
            MonitoringItem::ShipmentStartedLoadNotReady { ref mut added_to_queue, .. } |
            MonitoringItem::TrailerHostage { ref mut added_to_queue, .. } => {
                *added_to_queue = now;
            }
        }
        self.queue.insert(item);
    }

    /// Removes an item from the monitoring queue.
    ///
    /// # Arguments
    ///
    /// * `item` - The `MonitoringItem` to be removed from the queue.
    ///
    /// # Returns
    ///
    /// `true` if the item was present in the queue and removed, `false` otherwise.
    pub fn remove(&self, item: &MonitoringItem) -> bool {
        self.queue.remove(item).is_some()
    }

    /// Checks if an item is present in the monitoring queue.
    ///
    /// # Arguments
    ///
    /// * `item` - The `MonitoringItem` to check for in the queue.
    ///
    /// # Returns
    ///
    /// `true` if the item is present in the queue, `false` otherwise.
    pub fn contains(&self, item: &MonitoringItem) -> bool {
        self.queue.contains(item)
    }

    /// Returns the number of items in the monitoring queue.
    ///
    /// # Returns
    ///
    /// The number of items currently in the queue.
    pub fn len(&self) -> usize {
        self.queue.len()
    }

    /// Checks if the monitoring queue is empty.
    ///
    /// # Returns
    ///
    /// `true` if the queue is empty, `false` otherwise.
    pub fn is_empty(&self) -> bool {
        self.queue.is_empty()
    }

    /// Removes all items from the monitoring queue.
    pub fn clear(&self) {
        self.queue.clear();
    }

    /// Returns an iterator over the items in the monitoring queue.
    ///
    /// # Returns
    ///
    /// An iterator that yields references to `MonitoringItem`s.
    pub fn iter(&self) -> impl Iterator<Item = dashmap::setref::multiple::RefMulti<'_, MonitoringItem>> {
        self.queue.iter()
    }

    /// Removes items from the queue that have been present for longer than the specified duration.
    ///
    /// This method is used to prevent items from staying in the queue indefinitely,
    /// which helps avoid infinite alerts.
    ///
    /// # Arguments
    ///
    /// * `max_age` - The maximum duration an item can remain in the queue before being removed.
    pub fn remove_old_items(&self, max_age: Duration) {
        let now = Utc::now().naive_utc();
        self.queue.retain(|item| {
            let age = match item {
                MonitoringItem::SuspendedShipment { added_to_queue, .. } |
                MonitoringItem::TrailerDockedNotStarted { added_to_queue, .. } |
                MonitoringItem::ShipmentStartedLoadNotReady { added_to_queue, .. } |
                MonitoringItem::TrailerHostage { added_to_queue, .. } => {
                    now.signed_duration_since(*added_to_queue)
                }
            };
            age <= max_age
        });
    }
}

impl Default for MonitoringQueue {
    fn default() -> Self {
        Self::new()
    }
}```

--------------------------------------------------------------------------------

# src\monitoring\monitoring_worker.rs
```
use std::sync::Arc;
use chrono::{Local, Duration, NaiveDateTime};
use tokio::time::interval;
use log::{info, warn, error};
use crate::alerting::alert_manager::{AlertManager, Alert, AlertType};
use crate::config::Settings;
use crate::models::{LoadingStatus, TrailerState, ManualMode};
use crate::state_management::door_state_repository::DoorStateRepository;
use crate::utils::format_duration;
use super::monitoring_queue::{MonitoringQueue, MonitoringItem};

/// Represents a worker that monitors and processes items from a monitoring queue
#[derive(Clone)]
pub struct MonitoringWorker {
    queue: Arc<MonitoringQueue>,
    door_repository: Arc<DoorStateRepository>,
    alert_manager: Arc<AlertManager>,
    settings: Settings,
}

impl MonitoringWorker {
    /// Creates a new MonitoringWorker instance
    ///
    /// # Arguments
    ///
    /// * `queue` - The monitoring queue to process items from
    /// * `door_repository` - The repository to retrieve door information
    /// * `alert_manager` - The alert manager to send alerts
    /// * `settings` - The application settings
    ///
    /// # Returns
    ///
    /// A new MonitoringWorker instance
    pub fn new(
        queue: Arc<MonitoringQueue>,
        door_repository: Arc<DoorStateRepository>,
        alert_manager: Arc<AlertManager>,
        settings: Settings,
    ) -> Self {
        Self {
            queue,
            door_repository,
            alert_manager,
            settings
        }
    }

    /// Runs the monitoring worker, continuously processing items from the queue
    pub async fn run(&self) {
        let monitoring_check_interval = self.settings.monitoring.check_interval;
        let mut interval = interval(tokio::time::Duration::from_secs(monitoring_check_interval));

        loop {
            interval.tick().await;
            info!("Starting Monitoring Worker Loop...");

            // Remove items older than 4 hours
            self.queue.remove_old_items(Duration::hours(4));

            let queue_size = self.queue.len();
            info!("Current Monitoring Queue size: {}", queue_size);

            let items: Vec<MonitoringItem> = self.queue.iter().map(|ref_multi| ref_multi.key().clone()).collect();
            for item in items {
                info!("Processing Monitoring Item: {:#?}", item);
                if !self.process_item(item.clone()).await {
                    self.queue.remove(&item);
                }
            }

            info!("Monitoring Worker Loop Completed");
        }
    }

    /// Processes a single monitoring item
    ///
    /// # Arguments
    ///
    /// * `item` - The monitoring item to process
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the item should be kept in the queue
    async fn process_item(&self, item: MonitoringItem) -> bool {
        match item {
            MonitoringItem::SuspendedShipment { plant_id, door_name, shipment_id, suspended_at, user, .. } => {
                self.process_suspended_shipment(plant_id, door_name, shipment_id, suspended_at, user).await
            },
            MonitoringItem::TrailerDockedNotStarted { plant_id, door_name, docked_at, .. } => {
                self.process_trailer_docked_not_started(plant_id, door_name, docked_at).await
            },
            MonitoringItem::ShipmentStartedLoadNotReady { plant_id, door_name, shipment_id, started_at, .. } => {
                self.process_shipment_started_load_not_ready(plant_id, door_name, shipment_id, started_at).await
            },
            MonitoringItem::TrailerHostage { plant_id, door_name, shipment_id, detected_at, .. } => {
                self.process_trailer_hostage(plant_id, door_name, shipment_id, detected_at).await
            },
        }
    }

    // ... [Other existing methods remain unchanged] ...

    /// Processes a trailer hostage monitoring item
    ///
    /// # Arguments
    ///
    /// * `plant_id` - The ID of the plant
    /// * `door_name` - The name of the door
    /// * `shipment_id` - The ID of the shipment (if available)
    /// * `detected_at` - The timestamp when the hostage situation was first detected
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the item should be kept in the queue
    async fn process_suspended_shipment(&self, plant_id: String, door_name: String, shipment_id: String, suspended_at: NaiveDateTime, user: String) -> bool {
        info!("Processing SuspendedShipment for door: {}, shipment: {}", door_name, shipment_id);
        if let Some(door_state) = self.door_repository.get_door_state(&plant_id, &door_name).await {
            if door_state.loading_status.loading_status == LoadingStatus::Suspended {
                let duration = Local::now().naive_local().signed_duration_since(suspended_at);
                let alert_threshold = Duration::seconds(self.settings.monitoring.suspended_shipment.alert_threshold as i64);
                let repeat_interval = Duration::seconds(self.settings.monitoring.suspended_shipment.repeat_interval as i64);

                info!("Door {} is suspended for {:?}. Alert threshold: {:?}, Repeat interval: {:?}",
                    door_name, duration, alert_threshold, repeat_interval);

                if duration >= alert_threshold && self.should_alert(duration, repeat_interval) {
                    info!("Sending alert for suspended door {}", door_name);
                    let alert = Alert::new(AlertType::SuspendedDoor, door_name.clone())
                        .shipment_id(shipment_id.clone())
                        .duration(duration)
                        .add_info("user".to_string(), user.clone())
                        .build();
                    if let Err(e) = self.alert_manager.handle_alert(alert).await {
                        error!("Failed to handle SuspendedDoor alert: {:?}", e);
                    }
                }
                true // Keep in queue for future checks
            } else {
                info!("Door {} is no longer suspended", door_name);
                false // Remove from queue
            }
        } else {
            warn!("Door {} not found in state manager", door_name);
            false // Remove from queue
        }
    }

    /// Processes a trailer docked not started monitoring item
    ///
    /// # Arguments
    ///
    /// * `plant_id` - The ID of the plant
    /// * `door_name` - The name of the door
    /// * `docked_at` - The timestamp when the trailer was docked
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the item should be kept in the queue
    async fn process_trailer_docked_not_started(&self, plant_id: String, door_name: String, docked_at: NaiveDateTime) -> bool {
        info!("Processing TrailerDockedNotStarted for door: {}", door_name);
        if let Some(door_state) = self.door_repository.get_door_state(&plant_id, &door_name).await {
            info!("Door state: {:?}, Loading status: {:?}", door_state.trailer_state, door_state.loading_status);
            let loading_started = matches!(door_state.loading_status.loading_status,
                LoadingStatus::Loading |
                LoadingStatus::Suspended |
                LoadingStatus::Completed |
                LoadingStatus::WaitingForExit |
                LoadingStatus::CancelledShipment |
                LoadingStatus::Idle |
                LoadingStatus::StartedWithAnticipation
            );

            let door_check = door_state.sensors.get("TRAILER_AT_DOOR")
                .and_then(|sensor| sensor.get_sensor_data().current_value)
                .unwrap_or(0);

            if door_check == 0 {
                info!("Trailer is not at door {} sensor value = {}", door_name, door_check);
                return false // Remove from queue
            }

            if loading_started {
                info!("Loading is started or progressed for door {}", door_name);
                false // Remove from queue
            } else {
                let duration = Local::now().naive_local().signed_duration_since(docked_at);
                let alert_threshold = Duration::seconds(self.settings.monitoring.trailer_docked_not_started.alert_threshold as i64);
                let repeat_interval = Duration::seconds(self.settings.monitoring.trailer_docked_not_started.repeat_interval as i64);

                if duration >= alert_threshold && self.should_alert(duration, repeat_interval) {
                    info!("Sending alert for trailer docked not started {}", door_name);
                    let alert = Alert::new(AlertType::TrailerDockedNotStarted, door_name.clone())
                        .duration(duration)
                        .build();
                    if let Err(e) = self.alert_manager.handle_alert(alert).await {
                        error!("Failed to handle TrailerDockedNotStarted alert: {:?}", e);
                    }
                }
                true // Keep in queue for future checks
            }
        } else {
            warn!("Door {} not found in state manager", door_name);
            false // Remove from queue
        }
    }

    /// Processes a shipment started load not ready monitoring item
    ///
    /// # Arguments
    ///
    /// * `plant_id` - The ID of the plant
    /// * `door_name` - The name of the door
    /// * `shipment_id` - The ID of the shipment
    /// * `started_at` - The timestamp when the shipment started loading
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the item should be kept in the queue
    async fn process_shipment_started_load_not_ready(&self, plant_id: String, door_name: String, shipment_id: String, started_at: NaiveDateTime) -> bool {
        info!("Processing ShipmentStartedLoadNotReady for door: {}, shipment: {}", door_name, shipment_id);
        if let Some(door_state) = self.door_repository.get_door_state(&plant_id, &door_name).await {
            if !door_state.check_loading_readiness() && door_state.assigned_shipment.current_shipment.is_some() {
                let duration = Local::now().naive_local().signed_duration_since(started_at);
                let alert_threshold = Duration::seconds(self.settings.monitoring.shipment_started_load_not_ready.alert_threshold as i64);
                let repeat_interval = Duration::seconds(self.settings.monitoring.shipment_started_load_not_ready.repeat_interval as i64);

                info!("Door {} has shipment started load not ready for {:?}. Alert threshold: {:?}, Repeat interval: {:?}",
                    door_name, duration, alert_threshold, repeat_interval);

                if duration >= alert_threshold && self.should_alert(duration, repeat_interval) {
                    info!("Sending alert for shipment started load not ready {}", door_name);
                    let alert = Alert::new(AlertType::ShipmentStartedLoadNotReady, door_name.clone())
                        .shipment_id(shipment_id.clone())
                        .add_info("reason".to_string(), format!("Dock still not ready after {}", format_duration(&duration)))
                        .build();
                    if let Err(e) = self.alert_manager.handle_alert(alert).await {
                        error!("Failed to handle ShipmentStartedLoadNotReady alert: {:?}", e);
                    }
                }
                true // Keep in queue for future checks
            } else {
                info!("Door {} is now ready for loading", door_name);
                false // Remove from queue
            }
        } else {
            warn!("Door {} not found in state manager", door_name);
            false // Remove from queue
        }
    }

    /// Processes a trailer hostage monitoring item
    ///
    /// # Arguments
    ///
    /// * `plant_id` - The ID of the plant
    /// * `door_name` - The name of the door
    /// * `shipment_id` - The ID of the shipment (if available)
    /// * `detected_at` - The timestamp when the hostage situation was first detected
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the item should be kept in the queue
    async fn process_trailer_hostage(&self, plant_id: String, door_name: String, shipment_id: Option<String>, detected_at: NaiveDateTime) -> bool {
        info!("Processing TrailerHostage for door: {}, shipment: {:?}", door_name, shipment_id);
        if let Some(door_state) = self.door_repository.get_door_state(&plant_id, &door_name).await {
            let is_hostage_situation = (door_state.loading_status.previous_loading_status == LoadingStatus::Completed ||
                door_state.loading_status.loading_status == LoadingStatus::WaitingForExit) &&
                door_state.trailer_state == TrailerState::Docked &&
                door_state.manual_mode == ManualMode::Enabled;

            if is_hostage_situation {
                let duration = Local::now().naive_local().signed_duration_since(detected_at);
                let alert_threshold = Duration::seconds(self.settings.monitoring.trailer_hostage.alert_threshold as i64);
                let repeat_interval = Duration::seconds(self.settings.monitoring.trailer_hostage.repeat_interval as i64);

                info!("Door {} is in a hostage situation for {:?}. Alert threshold: {:?}, Repeat interval: {:?}",
                    door_name, duration, alert_threshold, repeat_interval);

                if duration >= alert_threshold && self.should_alert(duration, repeat_interval) {
                    info!("Sending alert for trailer hostage situation at door {}", door_name);
                    let alert = Alert::new(AlertType::TrailerHostage, door_name.clone())
                        .shipment_id(shipment_id.clone().unwrap_or_default())
                        .duration(duration)
                        .add_info("detected_at".to_string(), detected_at.to_string())
                        .build();
                    if let Err(e) = self.alert_manager.handle_alert(alert).await {
                        error!("Failed to handle TrailerHostage alert: {:?}", e);
                    }
                }
                true // Keep in queue for future checks
            } else {
                info!("Door {} is no longer in a hostage situation", door_name);
                false // Remove from queue
            }
        } else {
            warn!("Door {} not found in state manager", door_name);
            false // Remove from queue
        }
    }

    /// Determines if an alert should be sent based on the duration and repeat interval
    ///
    /// # Arguments
    ///
    /// * `duration` - The duration since the event occurred
    /// * `repeat_interval` - The interval at which alerts should be repeated
    ///
    /// # Returns
    ///
    /// A boolean indicating whether an alert should be sent
    fn should_alert(&self, duration: Duration, repeat_interval: Duration) -> bool {
        let intervals_passed = duration.num_seconds() / repeat_interval.num_seconds();
        let last_alert_time = intervals_passed * repeat_interval.num_seconds();
        duration.num_seconds() - last_alert_time < 60 // Alert within the first minute after an interval
    }
}

impl MonitoringWorker {
    // ... [Previous methods remain unchanged]

    /// Adds a new item to the monitoring queue
    ///
    /// # Arguments
    ///
    /// * `item` - The `MonitoringItem` to be added to the queue
    pub fn add_to_queue(&self, item: MonitoringItem) {
        self.queue.add(item);
    }

    /// Removes an item from the monitoring queue
    ///
    /// # Arguments
    ///
    /// * `item` - The `MonitoringItem` to be removed from the queue
    ///
    /// # Returns
    ///
    /// `true` if the item was present in the queue and removed, `false` otherwise
    pub fn remove_from_queue(&self, item: &MonitoringItem) -> bool {
        self.queue.remove(item)
    }

    /// Checks if an item is present in the monitoring queue
    ///
    /// # Arguments
    ///
    /// * `item` - The `MonitoringItem` to check for in the queue
    ///
    /// # Returns
    ///
    /// `true` if the item is present in the queue, `false` otherwise
    pub fn is_in_queue(&self, item: &MonitoringItem) -> bool {
        self.queue.contains(item)
    }

    /// Returns the current size of the monitoring queue
    ///
    /// # Returns
    ///
    /// The number of items currently in the queue
    pub fn queue_size(&self) -> usize {
        self.queue.len()
    }

    /// Clears all items from the monitoring queue
    pub fn clear_queue(&self) {
        self.queue.clear();
    }

    /// Manually triggers the removal of old items from the queue
    ///
    /// This method can be called to remove items that have been in the queue
    /// for longer than the specified duration, outside of the regular monitoring cycle.
    ///
    /// # Arguments
    ///
    /// * `max_age` - The maximum duration an item can remain in the queue before being removed
    pub fn remove_old_items(&self, max_age: Duration) {
        self.queue.remove_old_items(max_age);
    }
}```

--------------------------------------------------------------------------------

# src\repositories\consolidated.rs
```
use crate::errors::DockManagerError;
use crate::services::DatabaseClient;
use crate::repositories::repository_trait::Repository;
use async_trait::async_trait;
use sqlx_oldapi::Mssql;
use crate::models::consolidated_dock_event::ConsolidatedDockEvent;

/// A repository responsible for managing consolidated dock events in the database.
pub struct ConsolidatedDockEventRepository {
    /// The database client used to interact with the database.
    client: DatabaseClient,
}

impl ConsolidatedDockEventRepository {
    /// Creates a new `ConsolidatedDockEventRepository`.
    ///
    /// # Arguments
    /// * `client`: The `DatabaseClient` to use for database operations.
    pub fn new(client: DatabaseClient) -> Self {
        Self { client }
    }
}

#[async_trait]
impl Repository<ConsolidatedDockEvent> for ConsolidatedDockEventRepository {
    /// Inserts a consolidated dock event into the database.
    ///
    /// # Arguments
    /// * `event`: The `ConsolidatedDockEvent` to be inserted
    ///
    /// # Returns
    /// * `Ok(())` if the insertion was successful
    /// * `Err(DockManagerError)` if there was an error during the database operation
    async fn insert(&self, event: &ConsolidatedDockEvent) -> Result<(), DockManagerError> {
        let query = r#"
            EXEC sp_GetDockDoorEventDetails @PLANT = @p1, @DOCK_DOOR = @p2, @SHIPMENT_ID = @p3, @PRELOAD = @p4;
        "#;

        sqlx_oldapi::query::<Mssql>(query)
            .bind(&event.plant)
            .bind(&event.door_name)
            .bind(&event.shipment_id)
            .bind(&event.is_preload)
            .execute(&*self.client.pool)
            .await
            .map_err(DockManagerError::DatabaseError)?;

        Ok(())
    }

    /// Fetches consolidated dock events from the database based on the provided query
    ///
    /// # Arguments
    /// * `query`: The SQL query to execute for fetching the events.
    ///
    /// # Returns
    /// * `Ok(Vec<ConsolidatedDockEvent>)`: A vector of `ConsolidatedDockEvent` representing the fetched consolidated dock events
    /// * `Err(DockManagerError)` if there was an error during the database operation
    async fn fetch(&self, query: &str) -> Result<Vec<ConsolidatedDockEvent>, DockManagerError> {
        sqlx_oldapi::query_as::<_, ConsolidatedDockEvent>(query)
            .fetch_all(&*self.client.pool)
            .await
            .map_err(DockManagerError::DatabaseError)
    }
}```

--------------------------------------------------------------------------------

# src\repositories\door_event_repository.rs
```

use crate::models::DbInsert;
use crate::errors::DockManagerError;
use crate::services::DatabaseClient;
use crate::repositories::repository_trait::Repository;
use async_trait::async_trait;
use sqlx_oldapi::{Mssql};

/// A repository responsible for managing dock door events in the database.
pub struct DoorEventRepository {
    /// The database client used to interact with the database.
    client: DatabaseClient,
}

impl DoorEventRepository {
    /// Creates a new `DoorEventRepository`.
    ///
    /// # Arguments
    /// * `client`: The `DatabaseClient` to use for database operations.
    pub fn new(client: DatabaseClient) -> Self {
        Self { client }
    }
}

#[async_trait]
impl Repository<DbInsert> for DoorEventRepository {
    /// Inserts a dock door event into the database.
    ///
    /// # Arguments
    /// * `event`: The `DbInsert` representing the dock door event to be inserted
    /// 
    /// # Returns
    /// * `Ok(())` if the insertion was successful
    /// * `Err(DockManagerError)` if there was an error during the database operation
    async fn insert(&self, event: &DbInsert) -> Result<(), DockManagerError> {
        let query = r#"
            INSERT INTO DOCK_DOOR_EVENTS
            (LOG_DTTM, PLANT, DOOR_NAME, SHIPMENT_ID, EVENT_TYPE, SUCCESS, NOTES, ID_USER, SEVERITY, PREVIOUS_STATE, PREVIOUS_STATE_DTTM)
            VALUES
            (@p1, @p2, @p3, @p4, @p5, @p6, @p7, @p8, @p9, @p10, @p11)
        "#;

        sqlx_oldapi::query::<Mssql>(query)
            .bind(&event.LOG_DTTM)
            .bind(&event.PLANT)
            .bind(&event.DOOR_NAME)
            .bind(&event.SHIPMENT_ID)
            .bind(&event.EVENT_TYPE)
            .bind(&event.SUCCESS)
            .bind(&event.NOTES)
            .bind(&event.ID_USER)
            .bind(&event.SEVERITY)
            .bind(&event.PREVIOUS_STATE)
            .bind(&event.PREVIOUS_STATE_DTTM)
            .execute(&*self.client.pool)
            .await
            .map_err(DockManagerError::DatabaseError)?;

        Ok(())
    }

    /// Fetches dock door events from the database based on the provided query
    ///
    /// # Arguments
    /// * `query`: The SQL query to execute for fetching the events.
    /// 
    /// # Returns
    /// * `Ok(Vec<DbInsert>)`: A vector of `DbInsert` representing the fetched dock door events
    /// * `Err(DockManagerError)` if there was an error during the database operation
    async fn fetch(&self, query: &str) -> Result<Vec<DbInsert>, DockManagerError> {
        sqlx_oldapi::query_as::<_, DbInsert>(query)
            .fetch_all(&*self.client.pool)
            .await
            .map_err(DockManagerError::DatabaseError)
    }
}```

--------------------------------------------------------------------------------

# src\repositories\mod.rs
```
pub mod door_event_repository;
pub mod wms_status_repository;
pub mod repository_trait;
pub mod consolidated;

pub use door_event_repository::*;
pub use wms_status_repository::*;
pub use repository_trait::*;```

--------------------------------------------------------------------------------

# src\repositories\repository_trait.rs
```
use async_trait::async_trait;
use sqlx_oldapi::FromRow;
use crate::errors::DockManagerError;

/// Defines a generic asynchronous repository interface for interacting with the database
#[async_trait]
pub trait Repository<T>
    where
        T: for<'r> FromRow<'r, sqlx_oldapi::mssql::MssqlRow> + Send + Unpin,
{
    /// Inserts a single item into the database
    ///
    /// # Arguments
    ///
    /// * `item`: A reference to the item of type `T` to be inserted
    ///
    /// # Returns
    ///
    /// * `Ok(())` if the insertion is successful
    /// * `Err(DockManagerError)` if an error occurs during the insertion
    async fn insert(&self, item: &T) -> Result<(), DockManagerError>;

    /// Fetches data from the database based on the provided query
    ///
    /// The query should be a valid SQL query that returns rows of data that can be deserialized into the type `T`
    ///
    /// # Arguments
    ///
    /// * `query`: The SQL query string
    ///
    /// # Returns
    ///
    /// * `Ok(Vec<T>)`: A vector containing the fetched rows, deserialized into the type `T`
    /// * `Err(DockManagerError)` if an error occurs during the fetch operation or deserialization
    async fn fetch(&self, query: &str) -> Result<Vec<T>, DockManagerError>;
}```

--------------------------------------------------------------------------------

# src\repositories\wms_status_repository.rs
```
use async_trait::async_trait;
use crate::models::{WmsDoorStatus, WmsEvent};
use crate::errors::DockManagerError;
use crate::services::DatabaseClient;
use crate::repositories::repository_trait::Repository;
use sqlx_oldapi::{Mssql};

/// A repository responsible for fetching WMS (Warehouse Management System) status and event data from the database
pub struct WmsStatusRepository {
    /// The database client used to interact with the database
    client: DatabaseClient,
}

impl WmsStatusRepository {
    /// Creates a new `WmsStatusRepository`
    ///
    /// # Arguments
    ///
    /// * `client`: The `DatabaseClient` to use for database operations
    pub fn new(client: DatabaseClient) -> Self {
        Self { client }
    }

    /// Fetches WMS events from the database based on the provided query
    ///
    /// The `_shipment_id` and `_dock_name` parameters are currently unused but might be intended for future filtering or logging
    ///
    /// # Arguments
    ///
    /// * `query`: The SQL query to execute for fetching the WMS events
    /// * `_shipment_id`: (Unused) The ID of the shipment (potentially for future filtering)
    /// * `_dock_name`: (Unused) The name of the dock (potentially for future filtering)
    ///
    /// # Returns
    ///
    /// * `Ok(Vec<WmsEvent>)`: A vector of `WmsEvent` representing the fetched WMS events
    /// * `Err(DockManagerError)`: If there's an error during the database operation
    pub async fn fetch_wms_events(&self, query: &str, _shipment_id: &str, _dock_name: &str) -> Result<Vec<WmsEvent>, DockManagerError> {
        sqlx_oldapi::query_as::<Mssql, WmsEvent>(query)
            .fetch_all(&*self.client.pool)
            .await
            .map_err(DockManagerError::DatabaseError)
    }
}

#[async_trait]
impl Repository<WmsDoorStatus> for WmsStatusRepository {
    /// Inserts a `WmsDoorStatus` into the database (currently not implemented)
    ///
    /// This method currently returns an error indicating that it's not implemented
    /// It might be intended for future use when inserting WMS door status data is required
    ///
    /// # Arguments
    ///
    /// * `_status`: The `WmsDoorStatus` to be inserted (currently unused)
    ///
    /// # Returns:
    /// * `Err(DockManagerError)` indicating that the operation is not implemented
    async fn insert(&self, _status: &WmsDoorStatus) -> Result<(), DockManagerError> {
        Err(DockManagerError::DatabaseError(sqlx_oldapi::Error::RowNotFound))
    }

    /// Fetches WMS door statuses from the database based on the provided query
    ///
    /// # Arguments
    ///
    /// * `query`: The SQL query to execute for fetching the WMS door statuses
    ///
    /// # Returns
    ///
    /// * `Ok(Vec<WmsDoorStatus>)`: A vector of `WmsDoorStatus` representing the fetched door statuses
    /// * `Err(DockManagerError)`: If there's an error during the database operation
    async fn fetch(&self, query: &str) -> Result<Vec<WmsDoorStatus>, DockManagerError> {
        sqlx_oldapi::query_as::<Mssql, WmsDoorStatus>(query)
            .fetch_all(&*self.client.pool)
            .await
            .map_err(DockManagerError::DatabaseError)
    }
}```

--------------------------------------------------------------------------------

# src\rules\consolidated_data_rule.rs
```
use chrono::NaiveDateTime;
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult};
use crate::models::{DockDoor, DockDoorEvent, FirstDropEvent};
use crate::models::consolidated_dock_event::ConsolidatedDockEvent;

/// `ConsolidatedDataRule` is responsible for generating consolidated events
/// when a shipment is started in the Warehouse Management System (WMS).
/// It aggregates various pieces of information about a dock door and shipment
/// into a single `ConsolidatedDockEvent`.
pub struct ConsolidatedDataRule;

impl ConsolidatedDataRule {
    /// Creates a new instance of `ConsolidatedDataRule`.
    pub fn new() -> Self {
        Self {}
    }

    fn build_consolidated(&self, door: &DockDoor, event: &FirstDropEvent) -> Vec<AnalysisResult> {
        let (docking_time_minutes,inspection_time_minutes,enqueued_time_minutes) = self.calculate_times(door, event);
        vec![AnalysisResult::ConsolidatedEvent(ConsolidatedDockEvent{
            plant: door.plant_id.to_string(),
            door_name: door.dock_name.to_string(),
            shipment_id: door.assigned_shipment.current_shipment.as_ref()
                .and_then(|s| s.parse::<i32>().ok())
                .unwrap_or(0),
            docking_time_minutes,
            inspection_time_minutes,
            enqueued_time_minutes,
            shipment_assigned: door.assigned_shipment.assignment_dttm,
            dock_assignment: door.consolidated.dock_assignment,
            trailer_docking: door.consolidated.docking_time,
            started_shipment: door.consolidated.shipment_started_dttm,
            lgv_start_loading: Some(event.base_event.timestamp),
            dock_ready: door.consolidated.last_dock_ready_time,
            is_preload: door.consolidated.is_preload,
        })]
    }

    fn calculate_times(&self, door: &DockDoor, event: &FirstDropEvent) -> (Option<i32>, Option<i32>, Option<i32>) {
        let mut docking_time_minutes: Option<i32> = None;
        let mut inspection_time_minutes: Option<i32> = None;
        let mut enqueued_time_minutes: Option<i32> = None;

        if let (Some(dock_assignment), Some(trailer_docking)) = (door.consolidated.dock_assignment.or(door.assigned_shipment.assignment_dttm), door.consolidated.docking_time) {
            docking_time_minutes = Some(ConsolidatedDataRule::calculate_duration_minutes(dock_assignment, trailer_docking));
        }

        if let (Some(trailer_docking), Some(started_shipment)) = (door.consolidated.docking_time.or(door.consolidated.last_dock_ready_time), door.consolidated.shipment_started_dttm) {
            inspection_time_minutes = Some(ConsolidatedDataRule::calculate_duration_minutes(trailer_docking, started_shipment));
        }

        if let (Some(started_shipment), lgv_start_loading) = (door.consolidated.shipment_started_dttm, event.base_event.timestamp) {
            enqueued_time_minutes = Some(ConsolidatedDataRule::calculate_duration_minutes(started_shipment, lgv_start_loading));
        }
        (docking_time_minutes, inspection_time_minutes, enqueued_time_minutes)
    }

    fn calculate_duration_minutes(start: NaiveDateTime, end: NaiveDateTime) -> i32 {
        (end - start).num_minutes() as i32
    }
}

impl AnalysisRule for ConsolidatedDataRule {
    fn apply(&self, door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        match event {
            DockDoorEvent::FirstDrop(e) => {
                self.build_consolidated(door, e)
            },
            _ => Vec::new()
        }
    }
}```

--------------------------------------------------------------------------------

# src\rules\docking_state_rule.rs
```
use crate::models::{DockDoor, DockDoorEvent, TrailerState};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, LogEntry};

/// An analysis rule that logs trailer state changes (docked/undocked).
pub struct TrailerStateChangeRule;

impl AnalysisRule for TrailerStateChangeRule {
    /// Applies the rule to a dock door event, generating a log entry if the event is a trailer state change
    ///
    /// The method checks if the provided event is a `TrailerStateChangedEvent`. If so, it creates a `LogEntry::TrailerStateChange`
    /// with relevant details like the timestamp, plant ID, door name, shipment ID, event type (TRAILER_DOCKED or TRAILER_UNDOCKED),
    /// success status, notes about the state change, severity, previous state, and previous state timestamp
    /// The log entry is wrapped in an `AnalysisResult::Log` and returned in a vector
    /// If the event is not a trailer state change, an empty vector is returned
    ///
    /// # Arguments
    ///
    /// * `door`: A reference to the `DockDoor` object the event is associated with
    /// * `event`: A reference to the `DockDoorEvent` to be analyzed
    ///
    /// # Returns
    ///
    /// A vector containing an `AnalysisResult::Log` if the event is a trailer state change, otherwise an empty vector
    fn apply(&self, door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        if let DockDoorEvent::TrailerStateChanged(e) = event {
            let event_type = match e.new_state {
                TrailerState::Docked => "TRAILER_DOCKED",
                TrailerState::Undocked => "TRAILER_UNDOCKED",
            }.to_string();

            let notes = format!("Trailer state changed from {:?} to {:?}", e.old_state, e.new_state);

            let log_entry = LogEntry::TrailerStateChange {
                log_dttm: e.timestamp,
                plant: door.plant_id.clone(),
                door_name: e.dock_name.clone(),
                shipment_id: door.assigned_shipment.current_shipment.clone(),
                event_type: event_type.clone(),
                success: true,
                notes: notes.clone(),
                severity: 0,
                previous_state: Some(format!("{:?}", e.old_state)),
                previous_state_dttm: Some(e.timestamp),
            };


            vec![AnalysisResult::Log(log_entry)]
        } else {
            vec![]
        }
    }
}```

--------------------------------------------------------------------------------

# src\rules\dock_ready_rule.rs
```
use crate::models::{DockDoor, DockDoorEvent, DoorState};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, AlertType, LogEntry};
use chrono::Local;
use log::info;

pub struct DockReadyRule;

impl AnalysisRule for DockReadyRule {
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        info!("DockReadyRule applying to event: {:?}", event);

        let mut results = Vec::new();

        match event {
            DockDoorEvent::SensorStateChanged(e) if e.sensor_name == "RH_DOCK_READY" => {
                if e.new_value == Some(1) && e.old_value == Some(0)  {
                    info!("Door ready detected, checking conditions...");

                    results.push(AnalysisResult::Alert(AlertType::DockReady {
                        door_name: dock_door.dock_name.clone(),
                        shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                        timestamp: e.timestamp,
                    }));

                    let log_entry = LogEntry::DockingTime {
                        log_dttm: Local::now().naive_local(),
                        plant: dock_door.plant_id.clone(),
                        door_name: dock_door.dock_name.clone(),
                        shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                        event_type: "DOCK_READY".to_string(),
                        success: true,
                        notes: "Dock ready, docking process completed successfully".to_string(),
                        severity: 0,
                        previous_state: Some(format!("{:?}", DoorState::TrailerDocked)),
                        previous_state_dttm: Some(e.timestamp),
                    };

                    results.push(AnalysisResult::Log(log_entry));
                }
            },
            _ => {}
        }
        info!("DockReadyRule results: {:?}", results);
        results
    }
}```

--------------------------------------------------------------------------------

# src\rules\dynamic_rule_manager.rs
```
use std::fs::File;
use std::io::BufReader;
use std::path::PathBuf;
use std::sync::Arc;
use serde::{Deserialize, Serialize};
use anyhow::{Result, Context};
use log::info;
use crate::analysis::context_analyzer::AnalysisRule;
use crate::rules::rule_factory::RuleFactory;

/// Represents the configuration for a dynamically loaded analysis rule
#[derive(Debug, Serialize, Deserialize)]
pub struct RuleConfig {
    /// The type of rule to be created (e.g., "DockingTimeRule")
    pub rule_type: String,
    /// The parameters specific to the rule type, serialized as a JSON value
    pub parameters: serde_json::Value,
}

/// Manages the dynamic loading and configuration of analysis rules from a JSON file
pub struct DynamicRuleManager {
    /// The factory responsible for creating rule instances based on their configurations
    rule_factory: RuleFactory,
    /// The path to the JSON file containing the rule configurations
    config_path: PathBuf,
}

impl DynamicRuleManager {
    /// Creates a new `DynamicRuleManager`
    ///
    /// # Arguments
    ///
    /// * `config_path`: The path to the JSON file containing rule configurations
    pub fn new(config_path: PathBuf) -> Self {
        DynamicRuleManager {
            rule_factory: RuleFactory::new(),
            config_path,
        }
    }

    /// Loads analysis rules from the configuration file
    ///
    /// This method reads the JSON configuration file, parses the rule configurations, and uses the `RuleFactory` 
    /// to create instances of the specified rule types with their corresponding parameters
    /// It logs informational messages about the loading process and returns the loaded rules or an error if any occur
    ///
    /// # Returns
    ///
    /// * `Ok(Vec<Arc<dyn AnalysisRule>>)`: A vector of dynamically loaded analysis rules
    /// * `Err(anyhow::Error)`: If there's an error opening, reading, parsing the configuration file, or creating the rules
    pub fn load_rules(&self) -> Result<Vec<Arc<dyn AnalysisRule>>> {
        info!("Loading rules from config file: {:?}", self.config_path);
        let file = File::open(&self.config_path)
            .with_context(|| format!("Failed to open config file: {:?}", self.config_path))?;
        let reader = BufReader::new(file);
        let configs: Vec<RuleConfig> = serde_json::from_reader(reader)
            .with_context(|| "Failed to parse rule configurations")?;
        info!("Loaded {} rule configurations", configs.len());
        configs.into_iter()
            .map(|config| {
                info!("Creating rule: {}", config.rule_type);
                self.rule_factory.create_rule(&config.rule_type, &config.parameters)
            })
            .collect()
    }

    /// Adds a new rule configuration to the existing ones and saves them
    ///
    /// # Arguments
    /// * `rule_config`: The new `RuleConfig` to add
    ///
    /// # Returns
    /// * `Ok(())` if the rule was added and saved successfully
    /// * `Err(anyhow::Error)` if there is an error loading or saving the configurations
    pub fn add_rule(&self, rule_config: RuleConfig) -> Result<()> {
        let mut configs = self.load_rule_configs()?;
        configs.push(rule_config);
        self.save_rule_configs(&configs)
    }

    /// Loads rule configurations from the JSON file
    ///
    /// # Returns
    /// * `Ok(Vec<RuleConfig>)`: The loaded rule configurations
    /// * `Err(anyhow::Error)` if there is an error opening, reading, or parsing the file
    fn load_rule_configs(&self) -> Result<Vec<RuleConfig>> {
        let file = File::open(&self.config_path)
            .with_context(|| format!("Failed to open config file: {:?}", self.config_path))?;
        let reader = BufReader::new(file);
        serde_json::from_reader(reader)
            .with_context(|| "Failed to parse rule configurations")
    }

    /// Saves the provided rule configurations to the JSON file
    ///
    /// # Arguments
    /// * `configs`: A slice of `RuleConfig` to be saved
    ///
    /// # Returns:
    /// * `Ok(())` if the configurations were saved successfully
    /// * `Err(anyhow::Error)` if there is an error creating or writing to the file
    fn save_rule_configs(&self, configs: &[RuleConfig]) -> Result<()> {
        let file = File::create(&self.config_path)
            .with_context(|| format!("Failed to create config file: {:?}", self.config_path))?;
        serde_json::to_writer_pretty(file, configs)
            .with_context(|| "Failed to write rule configurations")
    }
}```

--------------------------------------------------------------------------------

# src\rules\long_loading_start_rule.rs
```
use std::collections::HashMap;
use chrono::{NaiveDateTime, Local, Duration};
use serde::{Deserialize, Serialize};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, AlertType};
use crate::models::{DockDoor, DockDoorEvent, LoadingStatus};

/// Configuration for the LongLoadingStartRule
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LongLoadingStartRuleConfig {
    /// The time threshold (in seconds) after which an alert should be triggered
    pub alert_threshold: u64,
    /// The interval (in seconds) at which repeat alerts should be sent
    pub repeat_interval: u64,
}

/// Rule for detecting and alerting on long loading start times
pub struct LongLoadingStartRule {
    /// The parsed configuration for this rule
    config: LongLoadingStartRuleConfig,
    /// A map to track the last alert time for each door
    last_alert_time: HashMap<String, NaiveDateTime>,
}

impl LongLoadingStartRule {
    /// Creates a new LongLoadingStartRule with the given configuration
    ///
    /// # Arguments
    ///
    /// * `config` - The JSON configuration containing the rule parameters
    ///
    /// # Returns
    ///
    /// A new instance of LongLoadingStartRule
    pub fn new(config: serde_json::Value) -> Self {
        let parsed_config: LongLoadingStartRuleConfig = serde_json::from_value(config)
            .expect("Failed to parse LongLoadingStartRule configuration");
        Self {
            config: parsed_config,
            last_alert_time: HashMap::new(),
        }
    }

    /// Checks if an alert should be sent based on the last alert time and repeat interval
    ///
    /// # Arguments
    ///
    /// * `door_name` - The name of the dock door
    ///
    /// # Returns
    ///
    /// A boolean indicating whether an alert should be sent
    fn should_send_alert(&self, door_name: &str) -> bool {
        let now = Local::now().naive_local();
        let last_alert = self.last_alert_time.get(door_name);

        match last_alert {
            Some(time) if now.signed_duration_since(*time) < Duration::seconds(self.config.repeat_interval as i64) => false,
            _ => {
                self.last_alert_time.clone().insert(door_name.to_string(), now);
                true
            }
        }
    }
}

impl AnalysisRule for LongLoadingStartRule {
    /// Applies the LongLoadingStartRule to the given dock door and event
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to which the rule is being applied
    /// * `event` - The DockDoorEvent being processed
    ///
    /// # Returns
    ///
    /// A vector of AnalysisResult, which may contain alerts if the rule conditions are met
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        let mut results = Vec::new();

        match event {
            DockDoorEvent::LoadingStatusChanged(e) if e.new_status == LoadingStatus::Loading => {
                let loading_duration = Local::now().naive_local().signed_duration_since(e.timestamp);
                if loading_duration > Duration::seconds(self.config.alert_threshold as i64) {
                    // Check if the loading progress is still 0%
                    if dock_door.loading_status.wms_shipment_status == Some("Started".to_string()) &&
                        dock_door.loading_status.loading_status == LoadingStatus::Loading {
                        if self.should_send_alert(&dock_door.dock_name) {
                            results.push(AnalysisResult::Alert(AlertType::LongLoadingStart {
                                door_name: dock_door.dock_name.clone(),
                                shipment_id: dock_door.assigned_shipment.current_shipment.clone().unwrap_or_default(),
                                duration: loading_duration,
                            }));
                        }
                    }
                }
            },
            DockDoorEvent::WmsEvent(e) if e.event_type == "STARTED_SHIPMENT" => {
                let loading_duration = Local::now().naive_local().signed_duration_since(e.timestamp);
                if loading_duration > Duration::seconds(self.config.alert_threshold as i64) {
                    if dock_door.loading_status.loading_status == LoadingStatus::Loading {
                        if self.should_send_alert(&dock_door.dock_name) {
                            results.push(AnalysisResult::Alert(AlertType::LongLoadingStart {
                                door_name: dock_door.dock_name.clone(),
                                shipment_id: e.shipment_id.clone(),
                                duration: loading_duration,
                            }));
                        }
                    }
                }
            },
            _ => {}
        }

        results
    }
}```

--------------------------------------------------------------------------------

# src\rules\manual_intervention_rule.rs
```
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use chrono::{Duration, Local, NaiveDateTime};
use derive_more::Constructor;
use crate::models::{DockDoor, DockDoorEvent, ManualMode};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, AlertType, LogEntry};
use serde::{Deserialize, Serialize};
use serde_json::Value;

/// Configuration for the `ManualInterventionRule`
#[derive(Debug, Deserialize, Serialize, Constructor)]
pub struct ManualInterventionRuleConfig {
    /// The interval (in seconds) at which to check monitored doors
    pub check_interval: u32,
    /// Maximum duration (in seconds) allowed for manual intervention before it's considered a failure
    pub max_duration: u64,
}

/// Type alias for the monitoring data structure used by the `ManualInterventionRule`
type MonitoringData = Arc<Mutex<HashMap<String, (NaiveDateTime, String)>>>;

/// An analysis rule that monitors and handles manual interventions on dock doors
pub struct ManualInterventionRule {
    /// The configuration for this rule
    config: ManualInterventionRuleConfig,
    /// Stores data about ongoing manual interventions for each dock door
    monitoring: MonitoringData,
}

impl ManualInterventionRule {
    /// Creates a new `ManualInterventionRule` with the given configuration
    ///
    /// # Arguments
    ///
    /// * `config` - A JSON Value containing the rule configuration
    ///
    /// # Returns
    ///
    /// A new instance of `ManualInterventionRule`
    pub fn new(config: Value) -> Self {
        let parsed_config: ManualInterventionRuleConfig = serde_json::from_value(config)
            .expect("Failed to parse ManualInterventionRule configuration");
        ManualInterventionRule {
            config: parsed_config,
            monitoring: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    /// Starts monitoring a dock door for manual intervention
    ///
    /// # Arguments
    ///
    /// * `dock_name` - The name of the dock door to monitor
    /// * `shipment_id` - The ID of the shipment associated with the manual intervention
    fn start_monitoring(&self, dock_name: String, shipment_id: String) {
        let mut monitoring = self.monitoring.lock().unwrap();
        monitoring.insert(dock_name, (Local::now().naive_local(), shipment_id));
    }

    /// Stops monitoring a dock door for manual intervention
    ///
    /// # Arguments
    ///
    /// * `dock_name` - The name of the dock door to stop monitoring
    ///
    /// # Returns
    ///
    /// An Option containing the start time and shipment ID if the door was being monitored, None otherwise
    fn stop_monitoring(&self, dock_name: &str) -> Option<(NaiveDateTime, String)> {
        let mut monitoring = self.monitoring.lock().unwrap();
        monitoring.remove(dock_name)
    }

    /// Checks the status of all monitored doors for manual intervention timeouts
    ///
    /// # Arguments
    ///
    /// * `dock_doors` - A reference to the map of all `DockDoor` objects
    ///
    /// # Returns
    ///
    /// A vector of `AnalysisResult` containing logs and alerts generated during the check
    pub async fn check_monitored_doors(&self, dock_doors: &HashMap<String, DockDoor>) -> Vec<AnalysisResult> {
        let mut results = Vec::new();
        let now = Local::now().naive_local();

        let mut monitoring = self.monitoring.lock().unwrap();
        monitoring.retain(|dock_name, (start_time, shipment_id)| {
            if let Some(door) = dock_doors.get(dock_name) {
                if door.assigned_shipment.current_shipment.is_some() {
                    let duration = now.signed_duration_since(*start_time);
                    if door.manual_mode == ManualMode::Disabled {
                        results.push(AnalysisResult::Log(LogEntry::ManualInterventionSuccess {
                            log_dttm: now,
                            plant: door.plant_id.clone(),
                            door_name: dock_name.clone(),
                            shipment_id: Some(shipment_id.clone()),
                            event_type: "MANUAL_INTERVENTION_SUCCESS".to_string(),
                            success: true,
                            notes: format!("Manual intervention completed, duration: {:?}", duration),
                            severity: 0,
                            previous_state: None,
                            previous_state_dttm: None,
                        }));
                        false
                    } else if duration > Duration::seconds(self.config.max_duration as i64) {
                        results.push(AnalysisResult::Alert(AlertType::ManualInterventionTimeout {
                            dock_name: dock_name.clone(),
                            shipment_id: shipment_id.clone(),
                            start_time: *start_time,
                            end_time: now,
                        }));
                        results.push(AnalysisResult::Log(LogEntry::ManualInterventionFailure {
                            log_dttm: now,
                            plant: door.plant_id.clone(),
                            door_name: dock_name.clone(),
                            shipment_id: Some(shipment_id.clone()),
                            event_type: "MANUAL_INTERVENTION_FAILURE".to_string(),
                            success: false,
                            notes: format!("Manual intervention timeout after {:?}", duration),
                            severity: 2,
                            previous_state: None,
                            previous_state_dttm: None,
                        }));
                        false
                    } else {
                        true
                    }
                } else {
                    false // Remove from monitoring if there's no assigned shipment
                }
            } else {
                false
            }
        });

        results
    }
}

impl AnalysisRule for ManualInterventionRule {
    /// Applies the rule to a dock door event, generating appropriate analysis results
    ///
    /// This method analyzes the given event and generates relevant logs and alerts
    /// based on manual intervention events.
    ///
    /// # Arguments
    ///
    /// * `dock_door` - A reference to the `DockDoor` associated with the event
    /// * `event` - A reference to the `DockDoorEvent` to analyze
    ///
    /// # Returns
    ///
    /// A vector of `AnalysisResult` containing logs and alerts generated based on the event
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        match event {
            DockDoorEvent::SensorStateChanged(e) if e.sensor_name == "RH_MANUAL_MODE" => {
                if e.new_value == Some(1) && e.old_value == Some(0) && dock_door.assigned_shipment.current_shipment.is_some() {
                    self.start_monitoring(e.dock_name.clone(), dock_door.assigned_shipment.current_shipment.clone().unwrap_or_default());
                    vec![AnalysisResult::Log(LogEntry::ManualInterventionStarted {
                        log_dttm: e.timestamp,
                        plant: dock_door.plant_id.clone(),
                        door_name: e.dock_name.clone(),
                        shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                        event_type: "MANUAL_INTERVENTION_STARTED".to_string(),
                        success: true,
                        notes: "Manual mode engaged".to_string(),
                        severity: 0,
                        previous_state: None,
                        previous_state_dttm: None,
                    })]
                } else if e.new_value == Some(0) && e.old_value == Some(1) {
                    if let Some((start_time, _shipment_id)) = self.stop_monitoring(&e.dock_name) {
                        vec![AnalysisResult::Log(LogEntry::ManualInterventionSuccess {
                            log_dttm: e.timestamp,
                            plant: dock_door.plant_id.clone(),
                            door_name: e.dock_name.clone(),
                            shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                            event_type: "MANUAL_INTERVENTION_SUCCESS".to_string(),
                            success: true,
                            notes: format!("Manual intervention completed, duration: {:?}", e.timestamp.signed_duration_since(start_time)),
                            severity: 0,
                            previous_state: None,
                            previous_state_dttm: None,
                        })]
                    } else {
                        vec![]
                    }
                } else {
                    vec![]
                }
            },
            _ => vec![],
        }
    }
}```

--------------------------------------------------------------------------------

# src\rules\mod.rs
```
pub mod dynamic_rule_manager;
pub mod rule_factory;
pub mod trailer_docking_rule;
pub mod new_shipment_old_trailer_rule;
pub mod manual_intervention_rule;
pub mod docking_state_rule;
pub mod wms_shipment_status_rule;
pub mod suspended_door_rule;
pub mod trailer_pattern_rule;
pub mod long_loading_start_rule;
pub mod trailer_hostage_rule;
pub mod shipment_started_load_not_ready_rule;
pub mod trailer_undocking_rule;
pub mod dock_ready_rule;
pub mod consolidated_data_rule;
pub mod wms_events_rule;
pub mod trailer_at_door_db;

pub use dynamic_rule_manager::*;
pub use rule_factory::*;
pub use trailer_docking_rule::*;
pub use docking_state_rule::*;
pub use new_shipment_old_trailer_rule::*;
pub use wms_shipment_status_rule::*;
pub use suspended_door_rule::*;
pub use trailer_pattern_rule::*;
pub use trailer_hostage_rule::*;
pub use shipment_started_load_not_ready_rule::*;
pub use trailer_undocking_rule::*;```

--------------------------------------------------------------------------------

# src\rules\new_shipment_old_trailer_rule.rs
```
use crate::models::{DockDoor, DockDoorEvent, TrailerState};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, AlertType};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use crate::analysis::LogEntry;

/// Configuration for the `NewShipmentPreviousTrailerPresentRule`
#[derive(Debug, Deserialize, Serialize)]
pub struct NewShipmentPreviousTrailerPresentRuleConfig {
    /// The list of WMS shipment statuses that are considered "complete" for the purpose of this rule
    pub completion_statuses: Vec<String>,
}

/// An analysis rule that detects and alerts when a new shipment is assigned to a dock door while the previous trailer is still present
pub struct NewShipmentPreviousTrailerPresentRule {
    /// The configuration for this rule
    config: NewShipmentPreviousTrailerPresentRuleConfig,
}

impl NewShipmentPreviousTrailerPresentRule {
    /// Creates a new `NewShipmentPreviousTrailerPresentRule` with the given configuration
    pub fn new(config: Value) -> Self {
        let parsed_config: NewShipmentPreviousTrailerPresentRuleConfig = serde_json::from_value(config)
            .expect("Failed to parse NewShipmentPreviousTrailerPresentRule configuration");
        NewShipmentPreviousTrailerPresentRule { config: parsed_config }
    }

    /// Checks if the previous shipment associated with the dock door is considered complete
    ///
    /// The method looks at the `wms_shipment_status` of the `dock_door` and checks if it's present in the `completion_statuses`
    /// defined in the rule's configuration
    ///
    /// # Arguments
    ///
    /// * `dock_door`: A reference to the `DockDoor` object
    ///
    /// # Returns
    ///
    /// * `true` if the previous shipment is complete, `false` otherwise
    fn is_previous_shipment_complete(&self, dock_door: &DockDoor) -> bool {
        if let Some(status) = &dock_door.loading_status.wms_shipment_status {
            self.config.completion_statuses.contains(status)
        } else {
            false
        }
    }
}

impl AnalysisRule for NewShipmentPreviousTrailerPresentRule {
    /// Applies the rule to a dock door event, generating an alert and a log entry if a new shipment is assigned while the previous trailer is still present
    ///
    /// The method checks if the event is a `ShipmentAssignedEvent`. If so, it further checks if:
    /// 1. The trailer is currently docked (`TrailerState::Docked`)
    /// 2. The previous shipment is considered complete (using `is_previous_shipment_complete`)
    ///
    /// If both conditions are met, it generates:
    /// - An `AlertType::NewShipmentPreviousTrailerPresent` alert
    /// - A `LogEntry::NewShipmentPreviousTrailerPresent` log entry
    ///
    /// These are wrapped in `AnalysisResult` and returned in a vector
    /// If the event is not a shipment assignment or the conditions are not met, an empty vector is returned
    ///
    /// # Arguments
    ///
    /// * `dock_door`: A reference to the `DockDoor` object the event is associated with
    /// * `event`: A reference to the `DockDoorEvent` to be analyzed
    ///
    /// # Returns
    ///
    /// A vector containing an alert and a log entry if the rule conditions are met, otherwise an empty vector
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        match event {
            DockDoorEvent::ShipmentAssigned(e) => {
                if dock_door.trailer_state == TrailerState::Docked && self.is_previous_shipment_complete(dock_door) {
                    let log_entry = LogEntry::NewShipmentPreviousTrailerPresent {
                        log_dttm: e.timestamp,
                        plant: dock_door.plant_id.clone(),
                        door_name: e.dock_name.clone(),
                        shipment_id: Some(e.shipment_id.clone()),
                        event_type: "NEW_SHIPMENT_PREVIOUS_TRAILER_PRESENT".to_string(),
                        success: false, // This is generally considered an issue, so marking as not successful
                        notes: format!("New shipment {} assigned while previous trailer (shipment: {:?}) is still present",
                                       e.shipment_id, e.previous_shipment),
                        severity: 2, // Considering this a moderate severity issue
                        previous_state: Some("PREVIOUS_SHIPMENT_DOCKED".to_string()),
                        previous_state_dttm: dock_door.trailer_state_changed,
                    };

                    vec![
                        AnalysisResult::Alert(AlertType::NewShipmentPreviousTrailerPresent {
                            dock_name: e.dock_name.clone(),
                            new_shipment: e.shipment_id.clone(),
                            previous_shipment: e.previous_shipment.clone(),
                            timestamp: e.timestamp,
                        }),
                        AnalysisResult::Log(log_entry)
                    ]
                } else {
                    vec![]
                }
            },
            _ => vec![],
        }
    }
}```

--------------------------------------------------------------------------------

# src\rules\rule_factory.rs
```
use std::sync::Arc;
use anyhow::{Result};
use serde_json::Value;
use crate::analysis::context_analyzer::AnalysisRule;
use crate::rules::{suspended_door_rule::{SuspendedDoorRule}, long_loading_start_rule::{LongLoadingStartRule}, trailer_hostage_rule::{TrailerHostageRule}, shipment_started_load_not_ready_rule::{ShipmentStartedLoadNotReadyRule}, trailer_pattern_rule::{TrailerPatternRule}, trailer_docking_rule::{TrailerDockingRule}, manual_intervention_rule::{ManualInterventionRule}, NewShipmentPreviousTrailerPresentRule, TrailerUndockingRule};
use crate::rules::consolidated_data_rule::ConsolidatedDataRule;
use crate::rules::dock_ready_rule::DockReadyRule;
use crate::rules::trailer_at_door_db::{TrailerAtDoorUpdateRule, TrailerAtDoorUpdateRuleConfig};
use crate::rules::wms_events_rule::WmsEventsRule;

/// A factory for creating analysis rules based on their configuration
#[derive(Debug, Default)]
pub struct RuleFactory;

impl RuleFactory {
    /// Creates a new `RuleFactory`
    pub fn new() -> Self {
        RuleFactory
    }

    /// Creates an analysis rule based on the provided rule type and configuration
    ///
    /// # Arguments
    ///
    /// * `rule_type`: The type of rule to create
    /// * `config`: The configuration for the rule
    ///
    /// # Returns
    ///
    /// * `Ok(Arc<dyn AnalysisRule>)`: The created analysis rule wrapped in an `Arc`
    /// * `Err(anyhow::Error)`: If the rule type is unknown or there's an error parsing the configuration
    pub fn create_rule(&self, rule_type: &str, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        match rule_type {
            "SuspendedDoorRule" => self.create_suspended_door_rule(config),
            "LongLoadingStartRule" => self.create_long_loading_start_rule(config),
            "TrailerHostageRule" => self.create_trailer_hostage_rule(config),
            "ShipmentStartedLoadNotReadyRule" => self.create_shipment_started_load_not_ready_rule(config),
            "TrailerPatternRule" => self.create_trailer_pattern_rule(config),
            "TrailerDockingRule" => self.create_trailer_docking_rule(config),
            "NewShipmentPreviousTrailerPresentRule" => self.create_new_shipment_previous_trailer_present_rule(config),
            "ManualInterventionRule" => self.create_manual_intervention_rule(config),
            "TrailerUndockingRule" => self.create_trailer_undocking_rule(config),
            "DockReadyRule" => Ok(Arc::new(DockReadyRule)),
            "ConsolidatedDataRule" => Ok(Arc::new(ConsolidatedDataRule::new())),
            "WmsEventsRule" => Ok(Arc::new(WmsEventsRule)),
            "TrailerAtDoorUpdateRule" => self.create_trailer_at_door_update_rule(config),

            _ => Err(anyhow::anyhow!("Unknown rule type: {}", rule_type)),
        }
    }

    /// Creates a `SuspendedDoorRule` based on the provided configuration
    fn create_suspended_door_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(SuspendedDoorRule::new(config.clone())))
    }

    /// Creates a `LongLoadingStartRule` based on the provided configuration
    fn create_long_loading_start_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(LongLoadingStartRule::new(config.clone())))
    }

    /// Creates a `TrailerHostageRule` based on the provided configuration
    fn create_trailer_hostage_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(TrailerHostageRule::new(config.clone())))
    }

    /// Creates a `ShipmentStartedLoadNotReadyRule` based on the provided configuration
    fn create_shipment_started_load_not_ready_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(ShipmentStartedLoadNotReadyRule::new(config.clone())))
    }

    /// Creates a `TrailerPatternRule` based on the provided configuration
    fn create_trailer_pattern_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(TrailerPatternRule::new(config.clone())))
    }

    /// Creates a `TrailerDockingRule` based on the provided configuration
    fn create_trailer_docking_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(TrailerDockingRule::new(config.clone())))
    }

    /// Creates a `NewShipmentPreviousTrailerPresentRule` based on the provided configuration
    fn create_new_shipment_previous_trailer_present_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(NewShipmentPreviousTrailerPresentRule::new(config.clone())))
    }

    /// Creates a `ManualInterventionRule` based on the provided configuration
    fn create_manual_intervention_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(ManualInterventionRule::new(config.clone())))
    }

    fn create_trailer_undocking_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        Ok(Arc::new(TrailerUndockingRule::new(config.clone())))
    }

    fn create_trailer_at_door_update_rule(&self, config: &Value) -> Result<Arc<dyn AnalysisRule>> {
        let rule_config: TrailerAtDoorUpdateRuleConfig = serde_json::from_value(config.clone())?;
        Ok(Arc::new(TrailerAtDoorUpdateRule::new(rule_config)))
    }
}```

--------------------------------------------------------------------------------

# src\rules\shipment_started_load_not_ready_rule.rs
```
use serde::{Deserialize, Serialize};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, AlertType};
use crate::models::{DockDoor, DockDoorEvent, DockLockState, DoorPosition, LevelerPosition};

/// Configuration for the ShipmentStartedLoadNotReadyRule
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShipmentStartedLoadNotReadyRuleConfig {
    /// Whether to check if the dock restraint is engaged
    pub check_restraint: bool,
    /// Whether to check if the dock leveler is extended
    pub check_leveler: bool,
    /// Whether to check if the dock door is open
    pub check_door_open: bool,
}

/// Rule for detecting when a shipment has started loading but the dock is not ready
pub struct ShipmentStartedLoadNotReadyRule {
    /// The parsed configuration for this rule
    config: ShipmentStartedLoadNotReadyRuleConfig,
}

impl ShipmentStartedLoadNotReadyRule {
    /// Creates a new ShipmentStartedLoadNotReadyRule with the given configuration
    ///
    /// # Arguments
    ///
    /// * `config` - The JSON configuration containing the rule parameters
    ///
    /// # Returns
    ///
    /// A new instance of ShipmentStartedLoadNotReadyRule
    pub fn new(config: serde_json::Value) -> Self {
        let parsed_config: ShipmentStartedLoadNotReadyRuleConfig = serde_json::from_value(config)
            .expect("Failed to parse ShipmentStartedLoadNotReadyRule configuration");
        Self { config: parsed_config }
    }

    /// Checks if the dock is ready for loading based on the rule configuration
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to check
    ///
    /// # Returns
    ///
    /// A vector of reasons why the dock is not ready, if any
    fn check_dock_readiness(&self, dock_door: &DockDoor) -> Vec<String> {
        let mut reasons = Vec::new();

        if self.config.check_restraint && dock_door.dock_lock_state != DockLockState::Engaged {
            reasons.push("Dock restraint is not engaged".to_string());
        }

        if self.config.check_leveler && dock_door.leveler_position != LevelerPosition::Extended {
            reasons.push("Dock leveler is not extended".to_string());
        }

        if self.config.check_door_open && dock_door.door_position != DoorPosition::Open {
            reasons.push("Dock door is not open".to_string());
        }

        reasons
    }
}

impl AnalysisRule for ShipmentStartedLoadNotReadyRule {
    /// Applies the ShipmentStartedLoadNotReadyRule to the given dock door and event
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to which the rule is being applied
    /// * `event` - The DockDoorEvent being processed
    ///
    /// # Returns
    ///
    /// A vector of AnalysisResult, which may contain alerts if the rule conditions are met
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        let mut results = Vec::new();

        match event {
            DockDoorEvent::WmsEvent(e) if e.event_type == "STARTED_SHIPMENT" => {
                let reasons = self.check_dock_readiness(dock_door);
                if !reasons.is_empty() {
                    results.push(AnalysisResult::Alert(AlertType::ShipmentStartedLoadNotReady {
                        door_name: dock_door.dock_name.clone(),
                        shipment_id: e.shipment_id.clone(),
                        reason: reasons.join(", "),
                    }));
                }
            },
            _ => {}
        }

        results
    }
}```

--------------------------------------------------------------------------------

# src\rules\suspended_door_rule.rs
```
    use std::collections::HashMap;
    use std::sync::Mutex;
    use chrono::{NaiveDateTime, Local, Duration};
    use serde::{Deserialize, Serialize};
    use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, AlertType, LogEntry};
    use crate::models::{DockDoor, DockDoorEvent, LoadingStatus};
    use log::{debug, info};

    /// Configuration for the SuspendedDoorRule
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct SuspendedDoorRuleConfig {
        /// Time threshold (in seconds) after which to generate an alert
        pub alert_threshold: u64,
        /// Interval (in seconds) between repeated alerts
        pub repeat_interval: u64,
    }

    /// Rule for detecting and alerting on suspended doors
    pub struct SuspendedDoorRule {
        config: SuspendedDoorRuleConfig,
        last_alert_time: Mutex<HashMap<String, NaiveDateTime>>,
    }

    impl SuspendedDoorRule {
        /// Creates a new SuspendedDoorRule with the given configuration
        ///
        /// # Arguments
        ///
        /// * `config` - JSON configuration for the rule
        ///
        /// # Returns
        ///
        /// A new instance of SuspendedDoorRule
        pub fn new(config: serde_json::Value) -> Self {
            let parsed_config: SuspendedDoorRuleConfig = serde_json::from_value(config)
                .expect("Failed to parse SuspendedDoorRule configuration");
            Self {
                config: parsed_config,
                last_alert_time: Mutex::new(HashMap::new()),
            }
        }

        /// Determines if an alert should be sent based on the last alert time
        ///
        /// # Arguments
        ///
        /// * `door_name` - The name of the door
        ///
        /// # Returns
        ///
        /// A boolean indicating whether an alert should be sent
        fn should_send_alert(&self, door_name: &str) -> bool {
            let now = Local::now().naive_local();
            let mut last_alert_time = self.last_alert_time.lock().unwrap();
            let last_alert = last_alert_time.get(door_name);

            match last_alert {
                Some(time) if now.signed_duration_since(*time) < Duration::seconds(self.config.repeat_interval as i64) => false,
                _ => {
                    last_alert_time.insert(door_name.to_string(), now);
                    true
                }
            }
        }

        /// Formats a duration into a human-readable string
        ///
        /// # Arguments
        ///
        /// * `duration` - The duration to format
        ///
        /// # Returns
        ///
        /// A formatted duration string
        fn format_duration(&self, duration: &Duration) -> String {
            let total_seconds = duration.num_seconds();
            let hours = total_seconds / 3600;
            let minutes = (total_seconds % 3600) / 60;
            let seconds = total_seconds % 60;

            if hours > 0 {
                format!("{}h {}m {}s", hours, minutes, seconds)
            } else if minutes > 0 {
                format!("{}m {}s", minutes, seconds)
            } else {
                format!("{}s", seconds)
            }
        }

        /// Generates alert and log entry for a suspended door
        ///
        /// # Arguments
        ///
        /// * `dock_door` - The DockDoor that is suspended
        /// * `duration` - The duration of the suspension
        /// * `user` - The user who suspended the door
        /// * `timestamp` - The timestamp of the suspension
        ///
        /// # Returns
        ///
        /// A vector of AnalysisResult items
        fn generate_suspended_door_results(&self, dock_door: &DockDoor, duration: Duration, user: String, timestamp: NaiveDateTime) -> Vec<AnalysisResult> {
            let mut results = Vec::new();

            results.push(AnalysisResult::Alert(AlertType::SuspendedDoor {
                door_name: dock_door.dock_name.clone(),
                duration,
                shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                user: user.clone(),
            }));

            let log_entry = LogEntry::SuspendedDoor {
                log_dttm: Local::now().naive_local(),
                plant: dock_door.plant_id.clone(),
                door_name: dock_door.dock_name.clone(),
                shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                event_type: "SUSPENDED_DOOR".to_string(),
                success: false,
                notes: format!("Door suspended for {} by user {}", self.format_duration(&duration), user),
                severity: 2,
                previous_state: None,
                previous_state_dttm: Some(timestamp),
            };
            results.push(AnalysisResult::Log(log_entry));

            results
        }
    }

    impl AnalysisRule for SuspendedDoorRule {
        /// Applies the rule to a dock door event, generating appropriate analysis results
        ///
        /// # Arguments
        ///
        /// * `dock_door` - The DockDoor associated with the event
        /// * `event` - The DockDoorEvent to analyze
        ///
        /// # Returns
        ///
        /// A vector of AnalysisResult items generated by applying the rule
        fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
            info!("SuspendedDoorRule applying to event: {:?}", event);
            match event {
                DockDoorEvent::ShipmentSuspended(e) => {
                    if dock_door.loading_status.loading_status != LoadingStatus::Suspended {
                        debug!("Ignoring ShipmentSuspended event as door is not currently suspended");
                        return Vec::new();
                    }

                    if self.should_send_alert(&dock_door.dock_name) {
                        let duration = e.base_event.timestamp.signed_duration_since(
                            dock_door.assigned_shipment.assignment_dttm.unwrap_or(e.base_event.timestamp)
                        );
                        let user = e.base_event.message_notes
                            .as_ref()
                            .and_then(|notes| notes.split('-').next())
                            .map(|user| user.trim().to_string())
                            .unwrap_or_else(|| "Unknown".to_string());

                        debug!("Extracted user name for suspended door alert: {}", user);

                        self.generate_suspended_door_results(dock_door, duration, user, e.base_event.timestamp)
                    } else {
                        Vec::new()
                    }
                },
                _ => Vec::new()
            }
        }
    }```

--------------------------------------------------------------------------------

# src\rules\trailer_at_door_db.rs
```
use tokio::sync::Mutex;
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult};
use crate::models::{DockDoor, DockDoorEvent};
use crate::services::db::DatabaseService;
use serde::{Deserialize, Serialize};
use crate::config::Settings;
use once_cell::sync::OnceCell;
use anyhow::Result;

static DB_SERVICE: OnceCell<Mutex<DatabaseService>> = OnceCell::new();

#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct TrailerAtDoorUpdateRuleConfig {
    // Add any configuration parameters here if needed
}

pub struct TrailerAtDoorUpdateRule {
    config: TrailerAtDoorUpdateRuleConfig,
}

impl TrailerAtDoorUpdateRule {
    pub fn new(config: TrailerAtDoorUpdateRuleConfig) -> Self {
        Self { config }
    }

    async fn get_db_service() -> &'static Mutex<DatabaseService> {
        DB_SERVICE.get_or_init(|| {
            let settings = Settings::new().expect("Failed to load settings");
            let db_service = tokio::task::block_in_place(|| {
                tokio::runtime::Runtime::new()
                    .expect("Failed to create runtime")
                    .block_on(async {
                        DatabaseService::new(settings).await.expect("Failed to create DatabaseService")
                    })
            });
            Mutex::new(db_service)
        })
    }

    async fn update_trailer_at_door(door_name: &str, trailer_at_door: u8) -> Result<()> {
        let query = r#"
        UPDATE [NETWORK].[RCH].[DOCK_DOOR_PLCS]
        SET TRAILER_AT_DOOR = @P1,
            UPDATE_DTTM = GETDATE()
        WHERE DOOR_NAME = @P2
    "#;

        let db_service = Self::get_db_service().await?;
        let db_service = db_service.lock().await;

        sqlx_oldapi::query(query)
            .bind(trailer_at_door as i32)
            .bind(door_name)
            .execute(&*db_service.local_client.pool)
            .await?;

        Ok(())
    }
}

impl AnalysisRule for TrailerAtDoorUpdateRule {
    fn apply(&self, _door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        let _ = self.config.clone();
        match event {
            DockDoorEvent::SensorStateChanged(e) if e.sensor_name == "TRAILER_AT_DOOR" => {
                let trailer_at_door = e.new_value.unwrap_or(0);
                let door_name = e.dock_name.clone();

                tokio::spawn(async move {
                    if let Err(err) = Self::update_trailer_at_door(&door_name, trailer_at_door).await {
                        log::error!("Failed to update TRAILER_AT_DOOR for door {}: {:?}", door_name, err);
                    }
                });

                vec![]
            },
            _ => vec![],
        }
    }
}```

--------------------------------------------------------------------------------

# src\rules\trailer_docking_rule.rs
```
//! # Trailer Docking Rule
//!
//! This module defines the `TrailerDockingRule`, which is responsible for analyzing
//! trailer docking events and determining if a docking operation is successful.
//! It provides detailed feedback on why a docking operation might fail, which is
//! crucial for maintenance and troubleshooting.

use crate::models::{DockDoor, DockDoorEvent, TrailerState};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, LogEntry, AlertType};
use chrono::Local;
use log::{info, debug};
use serde::{Deserialize, Serialize};
use serde_json::Value;

/// Configuration for the TrailerDockingRule
#[derive(Debug, Deserialize, Serialize)]
pub struct TrailerDockingRuleConfig {
    /// The loading status that is considered invalid for docking
    pub invalid_loading_status: String,
    /// The WMS shipment status that is considered invalid for docking
    pub invalid_wms_shipment_status: String,
    /// Sensors to monitor during the docking process
    pub sensors_to_monitor: Vec<SensorConfig>,
}

/// Configuration for a sensor to monitor
#[derive(Debug, Deserialize, Serialize)]
pub struct SensorConfig {
    /// The name of the sensor
    pub name: String,
    /// The value that indicates a successful state for this sensor
    pub success_value: u8,
}

/// Rule for analyzing trailer docking events
pub struct TrailerDockingRule {
    /// The configuration for this rule
    config: TrailerDockingRuleConfig,
}

impl TrailerDockingRule {
    /// Creates a new TrailerDockingRule with the given configuration
    ///
    /// # Arguments
    ///
    /// * `config` - JSON configuration for the rule
    ///
    /// # Returns
    ///
    /// A new instance of TrailerDockingRule
    pub fn new(config: Value) -> Self {
        let parsed_config: TrailerDockingRuleConfig = serde_json::from_value(config)
            .expect("Failed to parse TrailerDockingRule configuration");
        TrailerDockingRule { config: parsed_config }
    }

    /// Checks if the docking is successful based on loading status, WMS shipment status, and sensor values
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to check
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the docking is successful
    fn is_docking_successful(&self, dock_door: &DockDoor) -> bool {
        let loading_status_condition = self.check_loading_status(dock_door);
        let wms_status_condition = self.check_wms_status(dock_door);
        let shipment_condition = dock_door.assigned_shipment.current_shipment.is_some();
        let (sensor_condition, _) = self.check_sensors(dock_door);

        debug!(
            "DockDoor: {} - Docking conditions: loading_status={}, wms_status={}, shipment={}, sensors={}",
            dock_door.dock_name, loading_status_condition, wms_status_condition, shipment_condition, sensor_condition
        );

        loading_status_condition && wms_status_condition && shipment_condition && sensor_condition
    }

    /// Checks if the loading status is valid for successful docking
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to check
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the loading status is valid
    fn check_loading_status(&self, dock_door: &DockDoor) -> bool {
        dock_door.loading_status.loading_status.to_string() != self.config.invalid_loading_status
    }

    /// Checks if the WMS shipment status is valid for successful docking
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to check
    ///
    /// # Returns
    ///
    /// A boolean indicating whether the WMS shipment status is valid
    fn check_wms_status(&self, dock_door: &DockDoor) -> bool {
        dock_door.loading_status.wms_shipment_status
            .as_ref()
            .map(|status| status != &self.config.invalid_wms_shipment_status)
            .unwrap_or(false)
    }

    /// Checks if all monitored sensors are in their success state
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to check
    ///
    /// # Returns
    ///
    /// A tuple containing:
    /// - A boolean indicating whether all sensors are in their success state
    /// - A vector of tuples, each containing the sensor name and its current state
    fn check_sensors(&self, dock_door: &DockDoor) -> (bool, Vec<(String, bool)>) {
        let sensor_states: Vec<(String, bool)> = self.config.sensors_to_monitor.iter().map(|sensor| {
            let sensor_state = dock_door.sensors.get(&sensor.name)
                .and_then(|s| s.get_sensor_data().current_value)
                .map(|value| value == sensor.success_value)
                .unwrap_or(false);
            (sensor.name.clone(), sensor_state)
        }).collect();

        let all_sensors_success = sensor_states.iter().all(|(_, state)| *state);
        (all_sensors_success, sensor_states)
    }

    /// Gets the reason for a docking failure
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to check
    ///
    /// # Returns
    ///
    /// A string describing the reason(s) for the docking failure
    fn get_failure_reason(&self, dock_door: &DockDoor) -> String {
        let mut reasons = Vec::new();

        if !self.check_loading_status(dock_door) {
            reasons.push(format!("Invalid loading status: {:?}", dock_door.loading_status.loading_status));
        }
        if !self.check_wms_status(dock_door) {
            reasons.push(format!("Invalid WMS shipment status: {:?}", dock_door.loading_status.wms_shipment_status));
        }
        if dock_door.assigned_shipment.current_shipment.is_none() {
            reasons.push("No shipment assigned".to_string());
        }

        let (_, sensor_states) = self.check_sensors(dock_door);
        for (sensor_name, sensor_state) in sensor_states {
            if !sensor_state {
                reasons.push(format!("Sensor '{}' not in success state", sensor_name));
            }
        }

        if reasons.is_empty() {
            "Unknown docking failure".to_string()
        } else {
            reasons.join(", ")
        }
    }

    /// Checks if this is the first update for the sensors
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to check
    ///
    /// # Returns
    ///
    /// A boolean indicating whether this is the first update (i.e., previous values are None)
    fn is_first_update(&self, dock_door: &DockDoor) -> bool {
        dock_door.sensors.get("TRAILER_AT_DOOR")
                .and_then(|s| s.get_sensor_data().previous_value)
                .is_none()
    }
}

impl AnalysisRule for TrailerDockingRule {
    /// Applies the rule to a dock door event, generating appropriate analysis results
    ///
    /// This method analyzes the given event and generates relevant alerts and log entries
    /// based on the trailer docking process. It skips alert generation during the initial update
    /// to prevent false alerts during system initialization.
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor associated with the event
    /// * `event` - The DockDoorEvent to analyze
    ///
    /// # Returns
    ///
    /// A vector of AnalysisResult items generated by applying the rule
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        info!("TrailerDockingRule applying to event: {:?}", event);
        let mut results = Vec::new();
        match event {
            DockDoorEvent::TrailerStateChanged(e) => {
                if e.new_state == TrailerState::Docked && e.old_state == TrailerState::Undocked {
                    info!("Trailer docking detected, checking conditions...");
                    // Skip alert generation if this is the first update
                    if self.is_first_update(dock_door) {
                        info!("Skipping alert generation for initial update on door: {}", dock_door.dock_name);
                        return results;
                    }

                    let is_successful = self.is_docking_successful(dock_door);
                    info!("Docking success: {}", is_successful);
                    let failure_reason = if !is_successful {
                        Some(self.get_failure_reason(dock_door))
                    } else {
                        None
                    };

                    results.push(AnalysisResult::Alert(AlertType::TrailerDocked {
                        door_name: dock_door.dock_name.clone(),
                        shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                        timestamp: e.timestamp,
                        success: is_successful,
                        failure_reason: failure_reason.clone(),
                    }));

                    let log_entry = LogEntry::DockingTime {
                        log_dttm: Local::now().naive_local(),
                        plant: dock_door.plant_id.clone(),
                        door_name: dock_door.dock_name.clone(),
                        shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                        event_type: "TRAILER_DOCKING".to_string(),
                        success: is_successful,
                        notes: if is_successful {
                            "Trailer docked successfully".to_string()
                        } else {
                            format!("Trailer docking failed: {}", failure_reason.unwrap_or_else(|| "Unknown reason".to_string()))
                        },
                        severity: if is_successful { 0 } else { 2 },
                        previous_state: Some(format!("{:?}", e.old_state)),
                        previous_state_dttm: Some(e.timestamp),
                    };

                    info!("TrailerDockingRule: Generated docking log entry: {:?}", log_entry);
                    results.push(AnalysisResult::Log(log_entry));
                }
            },
            _ => {},
        }
        info!("TrailerDockingRule results: {:?}", results);
        results
    }
}```

--------------------------------------------------------------------------------

# src\rules\trailer_hostage_rule.rs
```
use std::sync::Arc;
use chrono::{NaiveDateTime, Local, Duration};
use dashmap::DashMap;
use serde::{Deserialize, Serialize};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, AlertType, LogEntry};
use crate::models::{DockDoor, DockDoorEvent, LoadingStatus, TrailerState, ManualMode};
use log::{debug, info};

/// Configuration for the TrailerHostageRule
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrailerHostageRuleConfig {
    /// The time threshold (in seconds) after which an alert should be triggered
    pub alert_threshold: u64,
    /// The interval (in seconds) at which repeat alerts should be sent
    pub repeat_interval: u64,
}

/// Rule for detecting and alerting on trailer hostage situations
pub struct TrailerHostageRule {
    /// The parsed configuration for this rule
    config: TrailerHostageRuleConfig,
    /// A map to track the last alert time for each door
    last_alert_time: Arc<DashMap<String, NaiveDateTime>>,
}

impl TrailerHostageRule {
    /// Creates a new TrailerHostageRule with the given configuration
    ///
    /// # Arguments
    ///
    /// * `config` - JSON configuration for the rule
    ///
    /// # Returns
    ///
    /// A new instance of TrailerHostageRule
    pub fn new(config: serde_json::Value) -> Self {
        let parsed_config: TrailerHostageRuleConfig = serde_json::from_value(config)
            .expect("Failed to parse TrailerHostageRule configuration");
        Self {
            config: parsed_config,
            last_alert_time: Arc::new(DashMap::new()),
        }
    }

    /// Checks if an alert should be sent based on the last alert time and repeat interval
    ///
    /// # Arguments
    ///
    /// * `door_name` - The name of the dock door
    ///
    /// # Returns
    ///
    /// A boolean indicating whether an alert should be sent
    fn should_send_alert(&self, door_name: &str) -> bool {
        let now = Local::now().naive_local();
        match self.last_alert_time.get(door_name) {
            Some(time) if now.signed_duration_since(*time) < Duration::seconds(self.config.repeat_interval as i64) => false,
            _ => {
                self.last_alert_time.insert(door_name.to_string(), now);
                true
            }
        }
    }

    /// Determines if a trailer hostage situation is occurring
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor to check
    ///
    /// # Returns
    ///
    /// A boolean indicating whether a hostage situation is occurring
    fn is_hostage_situation(&self, dock_door: &DockDoor) -> bool {
        (dock_door.loading_status.loading_status == LoadingStatus::Completed ||
            dock_door.loading_status.loading_status == LoadingStatus::WaitingForExit) &&
            dock_door.trailer_state == TrailerState::Docked &&
            dock_door.manual_mode == ManualMode::Enabled
    }

    /// Generates alert and log entry for a trailer hostage situation
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor with the hostage situation
    /// * `duration` - The duration of the hostage situation
    ///
    /// # Returns
    ///
    /// A vector of AnalysisResult items containing the alert and log entry
    fn generate_hostage_results(&self, dock_door: &DockDoor, duration: Duration) -> Vec<AnalysisResult> {
        let mut results = Vec::new();

        results.push(AnalysisResult::Alert(AlertType::TrailerHostage {
            door_name: dock_door.dock_name.clone(),
            shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
            duration,
        }));

        let log_entry = LogEntry::TrailerHostage {
            log_dttm: Local::now().naive_local(),
            plant: dock_door.plant_id.clone(),
            door_name: dock_door.dock_name.clone(),
            shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
            event_type: "TRAILER_HOSTAGE".to_string(),
            success: false,
            notes: format!("Trailer hostage situation detected. Duration: {:?}", duration),
            severity: 2,
            previous_state: None,
            previous_state_dttm: None,
        };
        results.push(AnalysisResult::Log(log_entry));

        results
    }
}

impl AnalysisRule for TrailerHostageRule {
    /// Applies the rule to a dock door event, generating appropriate analysis results
    ///
    /// This method analyzes the given event and generates relevant alerts and log entries
    /// based on the trailer hostage situation. It checks for hostage situations when the
    /// loading status changes to Completed or WaitingForExit, or when the manual mode is engaged.
    ///
    /// # Arguments
    ///
    /// * `dock_door` - The DockDoor associated with the event
    /// * `event` - The DockDoorEvent to analyze
    ///
    /// # Returns
    ///
    /// A vector of AnalysisResult items generated by applying the rule
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        match event {
            DockDoorEvent::LoadingStatusChanged(e) => {
                if (e.new_status == LoadingStatus::Completed || e.new_status == LoadingStatus::WaitingForExit)
                    && e.old_status == LoadingStatus::Loading {
                    info!("Loading status changed to {:?} for door: {}", e.new_status, dock_door.dock_name);
                    if self.is_hostage_situation(dock_door) {
                        debug!("Potential trailer hostage situation detected for door: {}", dock_door.dock_name);
                        // Initial detection, return results to add to monitoring queue
                        self.generate_hostage_results(dock_door, Duration::seconds(0))
                    } else {
                        Vec::new()
                    }
                } else {
                    Vec::new()
                }
            },
            DockDoorEvent::SensorStateChanged(e) if e.sensor_name == "RH_MANUAL_MODE" && e.new_value == Some(1) => {
                if self.is_hostage_situation(dock_door) {
                    let duration = dock_door.trailer_state_changed
                        .map(|t| Local::now().naive_local().signed_duration_since(t))
                        .unwrap_or_else(|| Duration::seconds(0));

                    if duration > Duration::seconds(self.config.alert_threshold as i64) &&
                        self.should_send_alert(&dock_door.dock_name) {
                        debug!("Trailer hostage situation confirmed for door: {}", dock_door.dock_name);
                        self.generate_hostage_results(dock_door, duration)
                    } else {
                        Vec::new()
                    }
                } else {
                    Vec::new()
                }
            },
            _ => Vec::new()
        }
    }
}```

--------------------------------------------------------------------------------

# src\rules\trailer_pattern_rule.rs
```
use serde::{Deserialize, Serialize};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, AlertType, LogEntry};
use crate::models::{DockDoor, DockDoorEvent};
use chrono::Local;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrailerPatternRuleConfig {
    pub severity_threshold: i32,
}

pub struct TrailerPatternRule {
    config: TrailerPatternRuleConfig,
}

impl TrailerPatternRule {
    pub fn new(config: serde_json::Value) -> Self {
        let parsed_config: TrailerPatternRuleConfig = serde_json::from_value(config)
            .expect("Failed to parse TrailerPatternRule configuration");
        Self { config: parsed_config }
    }

    fn parse_trl_ptn_value(&self, message_notes: &str) -> Option<i32> {
        message_notes.parse::<i32>().ok()
    }
}

impl AnalysisRule for TrailerPatternRule {
    fn apply(&self, dock_door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        let mut results = Vec::new();
        match event {
            DockDoorEvent::WmsEvent(e) if e.event_type == "TRK_PTRN" => {
                if let Some(message_notes) = &e.message_notes {
                    if let Some(pattern_value) = self.parse_trl_ptn_value(message_notes) {
                        if pattern_value > 0 && pattern_value > self.config.severity_threshold {
                            results.push(AnalysisResult::Alert(AlertType::TrailerPatternIssue {
                                door_name: dock_door.dock_name.clone(),
                                issue: format!("Trailer pattern issue detected: {}", pattern_value),
                                severity: pattern_value,
                                shipment_id: dock_door.assigned_shipment.current_shipment.clone(),
                            }));

                            if let Some(AnalysisResult::Alert(AlertType::TrailerPatternIssue { door_name, issue, severity, shipment_id })) = results.last() {
                                let log_entry = LogEntry::TrailerPatternIssue {
                                    log_dttm: Local::now().naive_local(),
                                    plant: dock_door.plant_id.clone(),
                                    door_name: door_name.clone(),
                                    shipment_id: shipment_id.clone(),
                                    event_type: "TRAILER_PATTERN_ISSUE".to_string(),
                                    success: false,
                                    notes: issue.clone(),
                                    severity: *severity,
                                    previous_state: None,
                                    previous_state_dttm: None,
                                };
                                results.push(AnalysisResult::Log(log_entry));
                            }
                        }
                    }
                }
            },
            _ => {}
        }
        results
    }
}```

--------------------------------------------------------------------------------

# src\rules\trailer_undocking_rule.rs
```
use crate::models::{DockDoor, DockDoorEvent};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, LogEntry};
use chrono::{Local};
use log::debug;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrailerUndockingRuleConfig {
    // Add any configuration parameters if needed
}

pub struct TrailerUndockingRule {
    config: TrailerUndockingRuleConfig,
}

impl TrailerUndockingRule {
    pub fn new(config: serde_json::Value) -> Self {
        let parsed_config: TrailerUndockingRuleConfig = serde_json::from_value(config)
            .expect("Failed to parse TrailerUndockingRule configuration");
        Self { config: parsed_config }
    }

    fn generate_undocking_results(&self, door: &DockDoor, timestamp: chrono::NaiveDateTime, previous_state: &str) -> Vec<AnalysisResult> {
        let mut results = Vec::new();
        let _con = self.config.clone();

        let log_entry = LogEntry::TrailerUndocked {
            log_dttm: Local::now().naive_local(),
            plant: door.plant_id.clone(),
            door_name: door.dock_name.clone(),
            shipment_id: door.assigned_shipment.current_shipment.clone(),
            event_type: "TRAILER_UNDOCKING".to_string(),
            success: true,
            notes: "Trailer undocked successfully".to_string(),
            severity: 0,
            previous_state: Some(previous_state.to_string()),
            previous_state_dttm: Some(timestamp),
        };

        debug!("TrailerUndockingRule: Generated undocking log entry: {:?}", log_entry);
        results.push(AnalysisResult::Log(log_entry));

        results
    }
}

impl AnalysisRule for TrailerUndockingRule {
    fn apply(&self, door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        match event {
            DockDoorEvent::SensorStateChanged(e) => {
                if e.sensor_name == "TRAILER_AT_DOOR" && e.new_value == Some(0) {
                    self.generate_undocking_results(door, e.timestamp, "TRAILER_DOCKING")
                } else {
                    Vec::new()
                }
            },
            _ => Vec::new(),
        }
    }
}```

--------------------------------------------------------------------------------

# src\rules\wms_events_rule.rs
```
use log::info;
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult};
use crate::models::{DockDoor, DockDoorEvent, WmsEventWrapper, DbInsert};

pub struct WmsEventsRule;

impl AnalysisRule for WmsEventsRule {
    fn apply(&self, door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        info!("WmsEventsRule for: {:?}", event);
        match event {
            DockDoorEvent::WmsEvent(e) => vec![create_wms_db_insert(door, e)],
            DockDoorEvent::ShipmentStarted(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::ShipmentSuspended(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::ShipmentCancelled(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::ShipmentResumed(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::PriorityUpdated(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::LoadPlanSaved(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::ShipmentForcedClosed(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::LoadQuantityAdjusted(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::DriverCheckedIn(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::TrailerRejected(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::LgvStartLoading(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::FirstDrop(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::ShipmentCheckout(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::TrailerPatternProcessed(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::AppointmentUpdated(e) => vec![create_wms_db_insert(door, &e.base_event)],
            DockDoorEvent::TripProcessed(e) => vec![create_wms_db_insert(door, &e.base_event)],
            _ => vec![],
        }
    }
}

fn create_wms_db_insert(door: &DockDoor, base_event: &WmsEventWrapper) -> AnalysisResult {
    let user_id = if ["STARTED_SHIPMENT", "SUSPENDED_SHIPMENT", "RESUMED_SHIPMENT",
        "UPDATED_PRIORITY", "CANCELLED_SHIPMENT", "SDM_LOAD_PLAN",
        "LOAD_QTY_ADJUSTED", "SDM_CHECK_IN", "SDM_TRAILER_REJECTION"]
        .contains(&base_event.event_type.as_str()) {
        base_event.message_notes
            .as_ref()
            .and_then(|notes| notes.split('-').next())
            .map(|user| user.trim().to_string())
    } else {
        None
    };

    AnalysisResult::DbInsert(DbInsert {
        LOG_DTTM: base_event.timestamp,
        PLANT: door.plant_id.clone(),
        DOOR_NAME: door.dock_name.clone(),
        SHIPMENT_ID: Some(base_event.shipment_id.clone()),
        EVENT_TYPE: base_event.event_type.clone(),
        SUCCESS: if base_event.result_code == 0 { 1 } else { 0 },
        NOTES: base_event.message_notes.clone().unwrap_or_default(),
        ID_USER: user_id,
        SEVERITY: base_event.result_code,
        PREVIOUS_STATE: None,
        PREVIOUS_STATE_DTTM: None
    })
}```

--------------------------------------------------------------------------------

# src\rules\wms_shipment_status_rule.rs
```
use crate::models::{DockDoor, DockDoorEvent};
use crate::analysis::context_analyzer::{AnalysisRule, AnalysisResult, LogEntry};

/// An analysis rule that handles events related to WMS shipment status and loading status changes
pub struct WmsShipmentStatus;

impl AnalysisRule for WmsShipmentStatus {
    /// Applies the rule to a dock door event, generating log entries for shipment assignment, unassignment, and loading status changes
    ///
    /// The method matches the event type and creates corresponding log entries:
    /// - `DockDoorEvent::ShipmentAssigned`: Creates a `LogEntry::ShipmentAssigned` entry
    /// - `DockDoorEvent::ShipmentUnassigned`: Creates a `LogEntry::ShipmentUnassigned` entry
    /// - `DockDoorEvent::LoadingStatusChanged`: Creates a `LogEntry::LoadingStatusChange` entry
    /// For other event types, it returns an empty vector
    ///
    /// # Arguments
    ///
    /// * `door`: A reference to the `DockDoor` object the event is associated with
    /// * `event`: A reference to the `DockDoorEvent` to be analyzed
    ///
    /// # Returns
    ///
    /// A vector containing a `LogEntry` wrapped in an `AnalysisResult` if the event is relevant, otherwise an empty vector
    fn apply(&self, door: &DockDoor, event: &DockDoorEvent) -> Vec<AnalysisResult> {
        match event {
            DockDoorEvent::ShipmentAssigned(e) => {
                vec![
                    AnalysisResult::Log(LogEntry::ShipmentAssigned {
                        log_dttm: e.timestamp,
                        plant: door.plant_id.clone(),
                        door_name: e.dock_name.clone(),
                        shipment_id: Some(e.shipment_id.clone()),
                        event_type: "SHIPMENT_ASSIGNED".to_string(),
                        success: true,
                        notes: format!("New shipment assigned: {}", e.shipment_id),
                        severity: 0,
                        previous_state: e.previous_shipment.clone(),
                        previous_state_dttm: None,
                    }),
                ]
            },
            DockDoorEvent::ShipmentUnassigned(e) => {
                vec![
                    AnalysisResult::Log(LogEntry::ShipmentUnassigned {
                        log_dttm: e.timestamp,
                        plant: door.plant_id.clone(),
                        door_name: e.dock_name.clone(),
                        shipment_id: Some(e.shipment_id.clone()),
                        event_type: "SHIPMENT_UNASSIGNED".to_string(),
                        success: true,
                        notes: format!("Shipment unassigned: {}", e.shipment_id),
                        severity: 0,
                        previous_state: None,
                        previous_state_dttm: None,
                    }),
                ]
            },
            DockDoorEvent::LoadingStatusChanged(e) => {
                vec![
                    AnalysisResult::Log(LogEntry::LoadingStatusChange {
                        log_dttm: e.timestamp,
                        plant: door.plant_id.clone(),
                        door_name: e.dock_name.clone(),
                        shipment_id: door.assigned_shipment.current_shipment.clone(),
                        event_type: "LOADING_STATUS_CHANGED".to_string(),
                        success: true,
                        notes: format!("Loading status changed from {:?} to {:?}", e.old_status, e.new_status),
                        severity: 0,
                        previous_state: Some(format!("{:?}", e.old_status)),
                        previous_state_dttm: None,
                    }),
                ]
            },
            _ => vec![],
        }
    }
}```

--------------------------------------------------------------------------------

# src\services\db.rs
```
//! # Database Services

//! This module provides the core functionality for interacting with databases within the IQX Dock Manager application. 
//! It includes the `DatabaseConnectionFactory` for managing database connections and the `DatabaseService` for performing 
//! various database operations such as inserting dock door events and fetching WMS data.

use std::collections::HashMap;
use std::sync::Arc;
use secrecy::ExposeSecret;
use tokio::sync::Mutex;
use crate::config::Settings;
use crate::errors::{DockManagerError, DockManagerResult};
use crate::models::{DbInsert, WmsDoorStatus, WmsEvent};
use crate::models::consolidated_dock_event::ConsolidatedDockEvent;
use crate::repositories::{DoorEventRepository, WmsStatusRepository, Repository};
use crate::repositories::consolidated::ConsolidatedDockEventRepository;
use crate::services::DatabaseClient;

/// A factory for creating and managing database connections on a per-plant basis
pub struct DatabaseConnectionFactory {
    /// A thread-safe map storing database connections, keyed by plant ID
    connections: Arc<Mutex<HashMap<String, DatabaseClient>>>,
}

impl DatabaseConnectionFactory {
    /// Creates a new `DatabaseConnectionFactory`
    pub fn new() -> Self {
        Self {
            connections: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    /// Retrieves a database connection for the specified plant
    ///
    /// If a connection for the plant already exists in the map, it is returned
    /// Otherwise, a new connection is created based on the plant's configuration 
    /// and added to the map before being returned
    ///
    /// # Arguments
    ///
    /// * `plant_id`: The ID of the plant for which to retrieve the connection
    /// * `settings`: The application settings containing database configuration
    ///
    /// # Returns
    ///
    /// * `Ok(DatabaseClient)`: The database connection for the specified plant
    /// * `Err(DockManagerError)`: If the plant is not found in the settings or if there's an error creating the connection
    pub async fn get_connection(&self, plant_id: &str, settings: &Settings) -> DockManagerResult<DatabaseClient> {
        let mut connections = self.connections.lock().await;
        if let Some(client) = connections.get(plant_id) {
            Ok(client.clone())
        } else {
            let plant_settings = settings.get_plant(plant_id)
                .ok_or_else(|| DockManagerError::ConfigError(format!("Plant {} not found in settings", plant_id)))?;
            let client = DatabaseClient::new(
                &plant_settings.lgv_wms_database.connection_string().expose_secret(),
                &plant_settings.lgv_wms_database.app_name,
            ).await?;
            connections.insert(plant_id.to_string(), client.clone());
            Ok(client)
        }
    }
}

/// Provides services for interacting with both local and plant-specific WMS databases
#[derive(Clone)]
pub struct DatabaseService {
    /// The database client for the local database
    pub local_client: DatabaseClient,
    /// A map of database clients for different plants, keyed by plant ID
    plant_clients: HashMap<String, DatabaseClient>,
    /// The application settings containing database configurations
    settings: Settings,
}

impl DatabaseService {
    /// Creates a new `DatabaseService`
    ///
    /// Initializes the service by establishing connections to the local database and
    /// the WMS databases for each configured plant
    ///
    /// # Arguments
    ///
    /// * `settings`: The application settings containing database configurations
    ///
    /// # Returns
    ///
    /// * `Ok(Self)`: The initialized `DatabaseService` instance
    /// * `Err(DockManagerError)`: If there's an error establishing any of the database connections
    pub async fn new(settings: Settings) -> DockManagerResult<Self> {
        let local_client = DatabaseClient::new(
            &settings.database.connection_string().expose_secret(),
            &settings.database.app_name,
        ).await?;

        let mut plant_clients = HashMap::new();
        for plant in &settings.plants {
            let client = DatabaseClient::new(
                &plant.lgv_wms_database.connection_string().expose_secret(),
                &plant.lgv_wms_database.app_name,
            ).await?;
            plant_clients.insert(plant.plant_id.clone(), client);
        }

        Ok(Self {
            local_client,
            plant_clients,
            settings,
        })
    }

    /// Inserts a batch of dock door events into the local database
    ///
    /// # Arguments
    ///
    /// * `events`: A vector of `DbInsert` objects representing the events to be inserted
    ///
    /// # Returns
    ///
    /// * `Ok(())`: If the events were inserted successfully
    /// * `Err(DockManagerError)`: If there's an error during the insertion process
    pub async fn insert_dock_door_events(&self, events: Vec<DbInsert>) -> DockManagerResult<()> {
        let repo = DoorEventRepository::new(self.local_client.clone());
        for event in events {
            repo.insert(&event).await?;
        }
        Ok(())
    }

    /// Inserts a consolidated dock event into the database.
    ///
    /// # Arguments
    /// * `event`: The `ConsolidatedDockEvent` to be inserted
    ///
    /// # Returns
    /// * `Ok(())` if the insertion was successful
    /// * `Err(DockManagerError)` if there was an error during the database operation
    pub async fn insert_consolidated_event(&self, event: &ConsolidatedDockEvent) -> Result<(), DockManagerError> {
        let repo = ConsolidatedDockEventRepository::new(self.local_client.clone());
        repo.insert(event).await?;
        Ok(())
    }

    /// Fetches WMS data (door statuses) for the specified plant
    ///
    /// # Arguments:
    /// * `plant_id`: The ID of the plant for which to fetch WMS data
    ///
    /// # Returns
    /// * `Ok(Vec<WmsDoorStatus>)`: If the WMS data was fetched successfully
    /// * `Err(DockManagerError)`: If the plant is not found or if there's an error fetching the data
    pub async fn fetch_wms_data(&self, plant_id: &str) -> DockManagerResult<Vec<WmsDoorStatus>> {
        let client = self.plant_clients.get(plant_id)
            .ok_or_else(|| DockManagerError::ConfigError(format!("Plant {} not found", plant_id)))?;
        let repo = WmsStatusRepository::new(client.clone());
        let query = self.settings.queries.wms_door_status.replace("{|}", plant_id);
        repo.fetch(&query).await
    }

    /// Fetches WMS events for the specified plant, shipment, and dock
    ///
    /// # Arguments
    ///
    /// * `plant_id`: The ID of the plant
    /// * `shipment_id`: The ID of the shipment
    /// * `dock_name`: The name of the dock
    ///
    /// # Returns
    ///
    /// * `Ok(Vec<WmsEvent>)`: If the WMS events were fetched successfully
    /// * `Err(DockManagerError)` if the plant is not found or if there's an error fetching the events
    pub async fn fetch_wms_events(&self, plant_id: &str, shipment_id: &str, dock_name: &str) -> DockManagerResult<Vec<WmsEvent>> {
        let client = self.plant_clients.get(plant_id)
            .ok_or_else(|| DockManagerError::ConfigError(format!("Plant {} not found", plant_id)))?;
        let repo = WmsStatusRepository::new(client.clone());
        let query = self.settings.queries.wms_events
            .replace("{}", shipment_id)
            .replace("{|}", dock_name)
            .replace("{#}", plant_id);
        repo.fetch_wms_events(&query, shipment_id, dock_name).await
    }

    pub async fn fetch_empty_rack_count(&self, plant_id: &str) -> DockManagerResult<i64> {
        let client = self.plant_clients.get(plant_id)
            .ok_or_else(|| DockManagerError::ConfigError(format!("Plant {} not found", plant_id)))?;

        let query = &self.settings.queries.wms_rack_space;

        let result: (i64,) = sqlx_oldapi::query_as(query)
            .fetch_one(&*client.pool)
            .await
            .map_err(DockManagerError::DatabaseError)?;

        Ok(result.0)
    }
}```

--------------------------------------------------------------------------------

# src\services\mod.rs
```
pub mod plc;
pub mod db;
pub mod dbc;

pub use plc::*;
pub use dbc::*;
```

--------------------------------------------------------------------------------

# src\services\dbc\database_client.rs
```
//! # Database Client

//! This module defines the `DatabaseClient` struct, which provides a convenient and efficient interface for interacting with a Microsoft SQL Server database. 
//! The `DatabaseClient` encapsulates a connection pool and offers methods to execute SQL queries and fetch query results, streamlining database operations within the IQX Dock Manager application.


use std::str::FromStr;
use sqlx_oldapi::mssql::{MssqlPool, MssqlConnectOptions};
use sqlx_oldapi::{Error as SqlxError, query, query_as};
use std::sync::Arc;
use crate::errors::DockManagerError;

/// Represents a client for interacting with a Microsoft SQL Server database
#[derive(Debug, Clone)]
pub struct DatabaseClient {
    /// The connection pool used to manage database connections
    pub pool: Arc<MssqlPool>,
}

impl DatabaseClient {
    /// Creates a new `DatabaseClient` and establishes a connection pool to the database
    ///
    /// The connection string should be in the format `mssql://username:password@host:port/database_name`
    /// The `app_name` is used to identify the application in the database connection
    ///
    /// # Arguments
    ///
    /// * `connection_string`: The connection string to the database
    /// * `app_name`: The name of the application
    ///
    /// # Returns
    ///
    /// * `Ok(Self)`: The created `DatabaseClient` if the connection is successful
    /// * `Err(DockManagerError)`: If there's an error parsing the connection string or connecting to the database
    pub async fn new(connection_string: &str, app_name: &str) -> Result<Self, DockManagerError> {
        let mut connect_options = MssqlConnectOptions::from_str(connection_string)
            .map_err(|e| DockManagerError::DatabaseError(SqlxError::Configuration(e.into())))?;
        connect_options = connect_options.app_name(app_name);
        let pool = MssqlPool::connect_with(connect_options)
            .await
            .map_err(DockManagerError::DatabaseError)?;
        Ok(Self {
            pool: Arc::new(pool),
        })
    }

    /// Executes a SQL query without returning any rows
    ///
    /// This method is useful for executing DDL (Data Definition Language) statements or DML (Data Manipulation Language) statements 
    /// that don't produce result sets (e.g., `INSERT`, `UPDATE`, `DELETE`)
    ///
    /// # Arguments
    ///
    /// * `sql_query`: The SQL query to execute
    ///
    /// # Returns
    ///
    /// * `Ok(sqlx_oldapi::mssql::MssqlQueryResult)`: If the query execution is successful
    /// * `Err(DockManagerError)`: If there's an error executing the query
    pub async fn execute<'a>(&self, sql_query: &str) -> Result<sqlx_oldapi::mssql::MssqlQueryResult, DockManagerError> {
        query(sql_query)
            .execute(&*self.pool)
            .await
            .map_err(DockManagerError::DatabaseError)
    }

    /// Executes a SQL query and fetches the results into a vector of the specified type
    ///
    /// This method is suitable for executing SELECT queries that return rows of data
    /// The type `R` must implement the `sqlx_oldapi::FromRow` trait to allow deserialization of the query results
    ///
    /// # Arguments
    ///
    /// * `query`: The SQL query to execute
    ///
    /// # Returns
    ///
    /// * `Ok(Vec<R>)`: A vector containing the fetched rows, deserialized into the type `R`
    /// * `Err(DockManagerError)`: If there's an error executing the query or deserializing the results
    pub async fn fetch<'a, R>(&self, query: &str) -> Result<Vec<R>, DockManagerError>
        where
            R: Send + Unpin + for<'r> sqlx_oldapi::FromRow<'r, sqlx_oldapi::mssql::MssqlRow>,
    {
        query_as::<_, R>(query)
            .fetch_all(&*self.pool)
            .await
            .map_err(DockManagerError::DatabaseError)
    }
}```

--------------------------------------------------------------------------------

# src\services\dbc\mod.rs
```
pub mod database_client;
pub use database_client::DatabaseClient;```

--------------------------------------------------------------------------------

# src\services\plc\mod.rs
```
pub mod plc_tag_factory;
pub mod plc_reader;
pub mod plcs;

pub use plcs::*;```

--------------------------------------------------------------------------------

# src\services\plc\plcs.rs
```
use std::sync::Arc;
use std::time::{Duration, Instant};
use log::{info, error};
use futures::future::join_all;
use crate::models::PlcVal;
use crate::errors::{DockManagerError, DockManagerResult};
use crate::config::Settings;
use tokio::time::timeout;
use crate::services::plc::plc_tag_factory::PlcTagFactory;
use crate::services::plc::plc_reader::PlcReader;

// noinspection all
/// # PlcService
///
/// The `PlcService` struct is responsible for managing communications with Programmable Logic Controllers (PLCs)
/// in the dock door management system. It handles sensor polling and data retrieval from the PLCs.
///
/// ## Fields
///
/// * `reader`: An `Arc<PlcReader>` that provides thread-safe access to the PLC reading functionality.
/// * `max_retries`: The maximum number of retry attempts for reading sensor data.
///
/// ## Usage
///
/// The `PlcService` is typically instantiated in the `main.rs` file or a central service manager.
/// It's used by the `DockDoorController` to periodically poll sensor data from the PLCs.
///
/// ## Example
///
/// ```rust
/// let plc_service = PlcService::new();
/// let sensor_data = plc_service.poll_sensors(&settings).await?;
/// ```
#[derive(Clone)]
pub struct PlcService {
    /// Provides thread-safe access to the PLC reading functionality
    reader: Arc<PlcReader>,
    /// The maximum number of retry attempts for reading sensor data
    max_retries: u32,
}

impl PlcService {
    // noinspection all
    /// Creates a new instance of `PlcService`.
    ///
    /// This method initializes a new `PlcService` with default configurations:
    /// - A `PlcReader` with a 5000ms timeout
    /// - A maximum of 3 retry attempts for sensor reading
    ///
    /// # Returns
    ///
    /// Returns a new `PlcService` instance.
    ///
    /// # Example
    ///
    /// ```rust
    /// let plc_service = PlcService::new();
    /// ```
    pub fn new() -> Self {
        Self {
            reader: Arc::new(PlcReader::new(5000)),
            max_retries: 3,
        }
    }

    /// Polls sensors across all plants and collects their values
    ///
    /// This method iterates through all configured plants, their associated doors, and sensors
    /// For each sensor, it attempts to read its value from the PLC using the `read_sensor` method
    /// The collected sensor values are returned as a vector of `PlcVal`
    ///
    /// # Arguments
    /// * `settings`: The application settings containing plant and sensor configurations
    ///
    /// # Returns
    /// * `Ok(Vec<PlcVal>)`: The collected sensor values
    /// * `Err(DockManagerError)`: If there's an error during sensor polling or task joining
    pub async fn poll_sensors(&self, settings: &Settings) -> DockManagerResult<Vec<PlcVal>> {
        let start = Instant::now();
        let mut all_plc_values = Vec::new();
        let _ = self.max_retries.clone();

        for plant in &settings.plants {
            let plant_start = Instant::now();
            let plant_id = plant.plant_id.clone();

            info!("Starting sensor polling for plant {} with {} doors", plant_id, plant.dock_doors.dock_door_config.len());

            let sensor_futures: Vec<_> = plant.dock_doors.dock_door_config.iter()
                .flat_map(|door| {
                    plant.dock_doors.dock_plc_tags.iter().map({
                        let plant = plant_id.clone();
                        move |sensor| {
                            let reader = Arc::clone(&self.reader);
                            let plant_id = plant.clone();
                            let door_name = door.dock_name.clone();
                            let door_ip = door.dock_ip.clone();
                            let sensor_name = sensor.tag_name.clone();
                            let address = sensor.address.clone();

                            tokio::spawn(async move {
                                timeout(Duration::from_secs(1), Self::read_sensor(
                                    reader,
                                    plant_id,
                                    door_name,
                                    door_ip,
                                    sensor_name,
                                    address,
                                )).await
                            })
                        }
                    })
                })
                .collect();

            let results = join_all(sensor_futures).await;

            for result in results {
                match result {
                    Ok(Ok(Ok(plc_val))) => all_plc_values.push(plc_val),
                    Ok(Ok(Err(e))) => info!("Sensor read error: {:?}", e),
                    Ok(Err(_)) => info!("Sensor read timed out"),
                    Err(e) => error!("Task join error: {:?}", e),
                }
            }

            info!("Completed sensor polling for plant {} in {:?}", plant_id, plant_start.elapsed());
        }

        info!("Completed polling all sensors in {:?}", start.elapsed());
        Ok(all_plc_values)
    }

    /// Attempts to read a sensor value from a PLC with retries
    ///
    /// This method creates a PLC tag using the `PlcTagFactory` and then tries to read its value using the `PlcReader`
    /// If the read fails, it retries up to `max_retries` times with a 2-second delay between attempts
    /// If all attempts fail it returns an error
    ///
    /// # Arguments
    ///
    /// * `reader`: The `PlcReader` used for communication with the PLC
    /// * `max_retries`: The maximum number of retry attempts
    /// * `plant_id`: The ID of the plant where the sensor is located
    /// * `door_name`: The name of the door associated with the sensor
    /// * `door_ip`: The IP address of the PLC controlling the door
    /// * `sensor`: The name of the sensor
    /// * `plc_tag_address`: The PLC address of the sensor
    ///
    /// # Returns
    ///
    /// * `Ok(PlcVal)`: The read sensor value encapsulated in a `PlcVal` struct
    /// * `Err(DockManagerError)`: If the sensor read fails after all retries
    async fn read_sensor(
        reader: Arc<PlcReader>,
        plant_id: String,
        door_name: String,
        door_ip: String,
        sensor: String,
        plc_tag_address: String
    ) -> DockManagerResult<PlcVal> {
        let tag = PlcTagFactory::create_tag(&door_ip, &plc_tag_address, 1000)?; // Set timeout to 1000ms
        match reader.read_tag(tag).await {
            Ok(value) => Ok(PlcVal::new(&plant_id, &door_name, &door_ip, &sensor, value)),
            Err(e) => Err(DockManagerError::PlcError(format!("Failed to read sensor {} for door {}: {:?}", sensor, door_name, e)))
        }
    }
}```

--------------------------------------------------------------------------------

# src\services\plc\plc_reader.rs
```
use tokio::task;
use std::time::Duration;
use crate::errors::DockManagerError;

/// # PlcReader
///
/// A struct responsible for reading data from PLC (Programmable Logic Controller) tags.
/// It handles the actual communication with the PLC, including timeout management and error handling.
///
/// ## Fields
///
/// * `timeout_ms`: The timeout for PLC read operations in milliseconds.
///
/// ## Usage
///
/// The `PlcReader` is typically instantiated within the `PlcService` and used to read sensor values
/// from PLCs in the dock door management system.
///
/// ## Example
///
/// ```rust
/// let reader = PlcReader::new(5000);
/// let tag = PlcTagFactory::create_tag("192.168.1.100", "Tag1", 5000)?;
/// let value = reader.read_tag(tag).await?;
/// ```
pub struct PlcReader {
    pub timeout_ms: u64,
}

impl PlcReader {
    /// Creates a new instance of `PlcReader`.
    ///
    /// # Arguments
    ///
    /// * `timeout_ms`: The timeout for PLC read operations in milliseconds.
    ///
    /// # Returns
    ///
    /// Returns a new `PlcReader` instance.
    ///
    /// # Example
    ///
    /// ```rust
    /// let reader = PlcReader::new(5000);
    /// ```
    pub fn new(timeout_ms: u64) -> Self {
        Self { timeout_ms }
    }

    /// Reads a value from a PLC tag.
    ///
    /// This method attempts to read an 8-bit unsigned integer value from the given PLC tag.
    /// It uses Tokio's `spawn_blocking` to perform the blocking PLC read operation in a separate thread,
    /// and implements a timeout to prevent indefinite blocking.
    ///
    /// # Arguments
    ///
    /// * `tag`: A `RawTag` instance representing the PLC tag to read from.
    ///
    /// # Returns
    ///
    /// Returns a `Result<u8, DockManagerError>`:
    /// - `Ok(u8)`: The successfully read 8-bit unsigned integer value.
    /// - `Err(DockManagerError)`: An error if the read operation fails or times out.
    ///
    /// # Errors
    ///
    /// This function will return an error if:
    /// - The PLC read operation fails.
    /// - The spawned task panics.
    /// - The operation times out.
    ///
    /// # Usage
    ///
    /// This method is typically called in the `read_sensor` method of `PlcService`:
    ///
    /// ```rust
    /// let value = reader.read_tag(tag).await?;
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// let reader = PlcReader::new(5000);
    /// let tag = PlcTagFactory::create_tag("192.168.1.100", "Tag1", 5000)?;
    /// let value = reader.read_tag(tag).await?;
    /// println!("Read value: {}", value);
    /// ```
    pub async fn read_tag(&self, tag: plctag::RawTag) -> Result<u8, DockManagerError> {
        let timeout = Duration::from_millis(self.timeout_ms);
        let timeout_ms = self.timeout_ms;

        tokio::time::timeout(timeout, task::spawn_blocking(move || {
            tag.read(timeout_ms as u32);
            tag.get_u8(0)
        }))
            .await
            .map_err(|_| DockManagerError::PlcError("PLC read operation timed out".to_string()))?
            .map_err(|e| DockManagerError::PlcError(format!("Task join error: {}", e)))?
            .map_err(|e| DockManagerError::PlcError(format!("Failed to read tag value: {}", e)))
    }
}```

--------------------------------------------------------------------------------

# src\services\plc\plc_tag_factory.rs
```
use plctag::builder::*;
use plctag::RawTag;
use crate::errors::DockManagerError;

/// # PlcTagFactory
///
/// A factory struct for creating PLC (Programmable Logic Controller) tags.
/// This struct provides a static method to create `RawTag` instances, which are used
/// for communication with PLCs in the dock door management system.
///
/// ## Usage
///
/// The `PlcTagFactory` is typically used within the `PlcService`, specifically in the `read_sensor` method,
/// to create tags for each sensor that needs to be read.
///
/// ## Example
///
/// ```rust
/// let tag = PlcTagFactory::create_tag("192.168.1.100", "Tag1", 5000)?;
/// ```
pub struct PlcTagFactory;

impl PlcTagFactory {
    /// Creates a new PLC tag for communication with a specific sensor on a PLC.
    ///
    /// This method constructs a `RawTag` using the provided parameters and the libplctag library.
    /// It sets up the communication path and parameters required to interact with a specific PLC tag.
    ///
    /// # Arguments
    ///
    /// * `door_ip`: A string slice containing the IP address of the PLC.
    /// * `plc_tag_address`: A string slice representing the address of the tag in the PLC.
    /// * `timeout_ms`: The timeout for PLC operations in milliseconds.
    ///
    /// # Returns
    ///
    /// Returns a `Result<RawTag, DockManagerError>`:
    /// - `Ok(RawTag)`: A successfully created `RawTag` instance.
    /// - `Err(DockManagerError)`: An error if tag creation fails.
    ///
    /// # Errors
    ///
    /// This function will return an error if:
    /// - The PLC path building fails.
    /// - The `RawTag` creation fails.
    ///
    /// # Usage
    ///
    /// This method is typically called in the `read_sensor` method of `PlcService`:
    ///
    /// ```rust
    /// let tag = PlcTagFactory::create_tag(door_ip, plc_tag_address, reader.timeout_ms)?;
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// let tag = PlcTagFactory::create_tag("192.168.1.100", "Tag1", 5000)?;
    /// // Use the tag for PLC communication
    /// ```
    ///
    /// # TODO
    ///
    /// - Consider adding support for different PLC types beyond MicroLogix.
    /// - Implement a caching mechanism for frequently used tags to improve performance.
    /// - Add validation for the `plc_tag_address` format to catch configuration errors early.
    ///
    /// # Safety
    ///
    /// This method creates tags that directly interact with industrial control systems.
    /// Ensure that proper security measures are in place to prevent unauthorized access or manipulation.
    ///
    /// # Performance Considerations
    ///
    /// Tag creation can be a relatively expensive operation. If the same tags are used frequently,
    /// consider implementing a caching mechanism to reuse tag instances where possible.
    pub fn create_tag(
        door_ip: &str,
        plc_tag_address: &str,
        timeout_ms: u64
    ) -> Result<RawTag, DockManagerError> {
        let path = PathBuilder::default()
            .protocol(Protocol::EIP)
            .gateway(door_ip)
            .plc(PlcKind::MicroLogix)
            .name(plc_tag_address)
            .element_size(1)
            .element_count(1)
            .path("0")
            .read_cache_ms(0)
            .build()
            .map_err(|e| DockManagerError::PlcError(format!("Failed to build PLC path: {:?}", e)))?;

        RawTag::new(path, timeout_ms as u32)
            .map_err(|e| DockManagerError::PlcError(format!("Failed to create PLC tag: {:?}", e)))
    }
}```

--------------------------------------------------------------------------------

# src\state_management\command_processor.rs
```
use tokio::sync::mpsc;
use crate::errors::{DockManagerError, DockManagerResult};
use crate::models::{PlcVal, WmsDoorStatus, DockDoorEvent, DbInsert, WmsEvent, DoorState};
use crate::state_management::door_state_repository::DoorStateRepository;
use crate::state_management::sensor_data_processor::SensorDataProcessor;
use crate::state_management::wms_data_processor::WmsDataProcessor;
use crate::state_management::database_event_manager::DatabaseEventManager;
use crate::state_management::event_dispatcher::EventDispatcher;
use tokio::sync::oneshot;
use std::sync::Arc;
use log::error;

/// Represents the different commands that can be processed by the CommandProcessor
#[derive(Debug)]
pub enum StateManagerCommand {
    UpdateSensors(Vec<PlcVal>, oneshot::Sender<Result<Vec<DockDoorEvent>, DockManagerError>>),
    UpdateFromWms(Vec<WmsDoorStatus>, oneshot::Sender<Result<Vec<DockDoorEvent>, DockManagerError>>),
    GetDoorState(String, String, oneshot::Sender<Result<DoorState, DockManagerError>>),
    HandleWmsEvents(Vec<WmsEvent>, oneshot::Sender<Result<Vec<DbInsert>, DockManagerError>>),
    GetAndClearDbBatch(oneshot::Sender<Vec<DbInsert>>),
    EvaluateDoorStates(oneshot::Sender<Result<(), DockManagerError>>),
}

/// Processes commands for the dock monitoring system
pub struct CommandProcessor {
    command_receiver: mpsc::Receiver<StateManagerCommand>,
    door_repository: Arc<DoorStateRepository>,
    sensor_processor: Arc<SensorDataProcessor>,
    wms_processor: Arc<WmsDataProcessor>,
    db_event_manager: Arc<DatabaseEventManager>,
    event_dispatcher: Arc<EventDispatcher>,
}

impl CommandProcessor {
    /// Creates a new CommandProcessor
    ///
    /// # Arguments
    ///
    /// * `command_receiver` - The receiver end of the command channel
    /// * `door_repository` - The repository for managing door states
    /// * `sensor_processor` - The processor for sensor data
    /// * `wms_processor` - The processor for WMS data
    /// * `db_event_manager` - The manager for database events
    /// * `event_dispatcher` - The dispatcher for dock door events
    ///
    /// # Returns
    ///
    /// A new instance of CommandProcessor
    pub fn new(
        command_receiver: mpsc::Receiver<StateManagerCommand>,
        door_repository: Arc<DoorStateRepository>,
        sensor_processor: Arc<SensorDataProcessor>,
        wms_processor: Arc<WmsDataProcessor>,
        db_event_manager: Arc<DatabaseEventManager>,
        event_dispatcher: Arc<EventDispatcher>,
    ) -> Self {
        Self {
            command_receiver,
            door_repository,
            sensor_processor,
            wms_processor,
            db_event_manager,
            event_dispatcher,
        }
    }

    /// Runs the command processing loop
    ///
    /// This method continuously receives commands and processes them until the channel is closed
    pub async fn run(&mut self) -> DockManagerResult<()> {
        while let Some(command) = self.command_receiver.recv().await {
            if let Err(e) = self.process_command(command).await {
                error!("Error processing command: {:?}", e);
                return Err(e);
            }
        }
        Ok(())
    }

    /// Processes a single command
    ///
    /// # Arguments
    ///
    /// * `command` - The command to process
    ///
    /// # Returns
    ///
    /// A Result indicating success or failure of the command processing
    async fn process_command(&self, command: StateManagerCommand) -> DockManagerResult<()> {
        match command {
            StateManagerCommand::UpdateSensors(sensor_values, response_sender) => {
                let result = self.handle_update_sensors(sensor_values).await;
                response_sender.send(result).map_err(|_| DockManagerError::ChannelSendError("Failed to send UpdateSensors response".to_string()))?;
            },
            StateManagerCommand::UpdateFromWms(wms_data, response_sender) => {
                let result = self.handle_update_from_wms(wms_data).await;
                response_sender.send(result).map_err(|_| DockManagerError::ChannelSendError("Failed to send UpdateFromWms response".to_string()))?;
            },
            StateManagerCommand::GetDoorState(plant_id, door_name, response_sender) => {
                let result = self.handle_get_door_state(&plant_id, &door_name).await;
                response_sender.send(result).map_err(|_| DockManagerError::ChannelSendError("Failed to send GetDoorState response".to_string()))?;
            },
            StateManagerCommand::HandleWmsEvents(wms_events, response_sender) => {
                let result = self.handle_wms_events(wms_events).await;
                response_sender.send(result).map_err(|_| DockManagerError::ChannelSendError("Failed to send HandleWmsEvents response".to_string()))?;
            },
            StateManagerCommand::GetAndClearDbBatch(response_sender) => {
                let result = self.db_event_manager.get_and_clear_events().await;
                response_sender.send(result).map_err(|_| DockManagerError::ChannelSendError("Failed to send GetAndClearDbBatch response".to_string()))?;
            },
            StateManagerCommand::EvaluateDoorStates(response_sender) => {
                let result = self.handle_evaluate_door_states().await;
                response_sender.send(result).map_err(|_| DockManagerError::ChannelSendError("Failed to send EvaluateDoorStates response".to_string()))?;
            },
        }
        Ok(())
    }

    /// Handles the UpdateSensors command
    ///
    /// # Arguments
    ///
    /// * `sensor_values` - A vector of PlcVal representing sensor updates
    ///
    /// # Returns
    ///
    /// A Result containing a vector of DockDoorEvents or a DockManagerError
    async fn handle_update_sensors(&self, sensor_values: Vec<PlcVal>) -> Result<Vec<DockDoorEvent>, DockManagerError> {
        let events = self.sensor_processor.process_sensor_updates(sensor_values).await?;
        for event in &events {
            if let Err(e) = self.event_dispatcher.dispatch_event(event.clone()).await {
                error!("Error dispatching event: {:?}", e);
            }
        }
        Ok(events)
    }

    /// Handles the UpdateFromWms command
    ///
    /// # Arguments
    ///
    /// * `wms_data` - A vector of WmsDoorStatus representing WMS updates
    ///
    /// # Returns
    ///
    /// A Result containing a vector of DockDoorEvents or a DockManagerError
    async fn handle_update_from_wms(&self, wms_data: Vec<WmsDoorStatus>) -> Result<Vec<DockDoorEvent>, DockManagerError> {
        let events = self.wms_processor.process_wms_updates(wms_data).await?;
        for event in &events {
            if let Err(e) = self.event_dispatcher.dispatch_event(event.clone()).await {
                error!("Error dispatching event: {:?}", e);
            }
        }
        Ok(events)
    }

    /// Handles the GetDoorState command
    ///
    /// # Arguments
    ///
    /// * `door_name` - The name of the door to get the state for
    ///
    /// # Returns
    ///
    /// A Result containing the DoorState or a DockManagerError
    async fn handle_get_door_state(&self, plant_id: &str, door_name: &str) -> Result<DoorState, DockManagerError> {
        self.door_repository.get_door_state(plant_id, door_name).await
            .ok_or_else(|| DockManagerError::DoorNotFound(format!("Plant: {}, Door: {}", plant_id, door_name)))
            .map(|door| door.door_state)
    }

    /// Handles the HandleWmsEvents command
    ///
    /// # Arguments
    ///
    /// * `wms_events` - A vector of WmsEvent to be processed
    ///
    /// # Returns
    ///
    /// A Result containing a vector of DbInsert or a DockManagerError
    async fn handle_wms_events(&self, _wms_events: Vec<WmsEvent>) -> Result<Vec<DbInsert>, DockManagerError> {
        // Implement WMS event handling logic
        // This is a placeholder and should be implemented based on your specific requirements
        todo!("Implement WMS event handling")
    }

    /// Handles the EvaluateDoorStates command
    ///
    /// # Returns
    ///
    /// A Result indicating success or a DockManagerError
    async fn handle_evaluate_door_states(&self) -> Result<(), DockManagerError> {
        // Implement logic to evaluate and update door states
        // This is a placeholder and should be implemented based on your specific requirements
        Ok(())
    }
}```

--------------------------------------------------------------------------------

# src\state_management\database_event_manager.rs
```
use tokio::sync::RwLock;
use crate::models::DbInsert;
use crate::errors::DockManagerError;
use crate::services::db::DatabaseService;
use std::sync::Arc;
use log::{info, error};

/// Manages the collection and processing of database events for the dock monitoring system.
pub struct DatabaseEventManager {
    /// The queue of database events waiting to be processed.
    db_events: RwLock<Vec<DbInsert>>,
    /// The maximum number of events to accumulate before automatically flushing to the database.
    batch_size: usize,
    /// The database service used for inserting events.
    db_service: Arc<DatabaseService>,
}

impl DatabaseEventManager {
    /// Creates a new `DatabaseEventManager`.
    ///
    /// # Arguments
    ///
    /// * `batch_size` - The maximum number of events to accumulate before automatically flushing.
    /// * `db_service` - A reference to the `DatabaseService` for database operations.
    ///
    /// # Returns
    ///
    /// A new instance of `DatabaseEventManager`.
    pub fn new(batch_size: usize, db_service: Arc<DatabaseService>) -> Self {
        Self {
            db_events: RwLock::new(Vec::new()),
            batch_size,
            db_service,
        }
    }

    /// Adds a new database event to the queue.
    ///
    /// If the number of queued events reaches the batch size, it automatically
    /// triggers a flush operation.
    ///
    /// # Arguments
    ///
    /// * `event` - The `DbInsert` event to be added to the queue.
    ///
    /// # Returns
    ///
    /// A Result indicating success or failure of the operation.
    pub async fn add_event(&self, event: DbInsert) -> Result<(), DockManagerError> {
        let mut events = self.db_events.write().await;
        events.push(event);

        if events.len() >= self.batch_size {
            drop(events); // Release the write lock before flushing
            self.flush_events().await?;
        }

        Ok(())
    }

    /// Flushes all queued events to the database.
    ///
    /// This method is called automatically when the batch size is reached,
    /// or it can be called manually to force a flush operation.
    ///
    /// # Returns
    ///
    /// A Result indicating success or failure of the flush operation.
    pub async fn flush_events(&self) -> Result<(), DockManagerError> {
        let mut events = self.db_events.write().await;
        if events.is_empty() {
            return Ok(());
        }

        let events_to_flush = std::mem::take(&mut *events);
        drop(events); // Release the write lock before database operation

        info!("Flushing {} database events", events_to_flush.len());
        match self.db_service.insert_dock_door_events(events_to_flush).await {
            Ok(_) => {
                info!("Successfully flushed database events");
                Ok(())
            },
            Err(e) => {
                error!("Failed to flush database events: {:?}", e);
                // In case of failure, we might want to re-queue the events or implement a retry mechanism
                Err(e)
            }
        }
    }

    /// Retrieves and clears all currently queued database events.
    ///
    /// This method is useful for getting a snapshot of current events,
    /// for example during shutdown or for manual processing.
    ///
    /// # Returns
    ///
    /// A vector of all queued `DbInsert` events.
    pub async fn get_and_clear_events(&self) -> Vec<DbInsert> {
        let mut events = self.db_events.write().await;
        std::mem::take(&mut *events)
    }

    /// Returns the current number of queued database events.
    ///
    /// # Returns
    ///
    /// The number of events currently in the queue.
    pub async fn queue_size(&self) -> usize {
        let events = self.db_events.read().await;
        events.len()
    }
}```

--------------------------------------------------------------------------------

# src\state_management\door_state_repository.rs
```
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use crate::models::{DbInsert, DockDoor};
use crate::errors::DockManagerError;
use crate::config::Settings;
use tracing::info;

pub struct DoorStateRepository {
    plants: Arc<RwLock<HashMap<String, HashMap<String, DockDoor>>>>,
}

impl DoorStateRepository {
    pub fn new() -> Self {
        Self {
            plants: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    pub async fn get_door_state(&self, plant_id: &str, door_name: &str) -> Option<DockDoor> {
        let plants = self.plants.read().await;
        plants.get(plant_id)
            .and_then(|plant_doors| plant_doors.get(door_name).cloned())
    }

    pub async fn update_door(&self, plant_id: &str, door: DockDoor) -> Result<(), DockManagerError> {
        let mut plants = self.plants.write().await;
        plants
            .entry(plant_id.to_string())
            .or_insert_with(HashMap::new)
            .insert(door.dock_name.clone(), door);
        Ok(())
    }

    pub async fn get_all_doors(&self) -> Vec<DockDoor> {
        let plants = self.plants.read().await;
        plants.values()
            .flat_map(|plant_doors| plant_doors.values().cloned())
            .collect()
    }

    pub async fn initialize_from_settings(&self, settings: &Settings) -> Result<(), DockManagerError> {
        let mut plants = self.plants.write().await;
        for plant in &settings.plants {
            let plant_id = &plant.plant_id;
            let mut plant_doors = HashMap::new();

            for dock in &plant.dock_doors.dock_door_config {
                let door = DockDoor::new(
                    plant_id.clone(),
                    dock.dock_name.clone(),
                    dock.dock_ip.clone(),
                    plant,
                );
                plant_doors.insert(dock.dock_name.clone(), door);
            }

            plants.insert(plant_id.clone(), plant_doors);
        }
        Ok(())
    }

    pub async fn insert_db_event(&self, plant_id: &str, event: DbInsert) -> Result<(), DockManagerError> {
        info!("{:?} - {:?}", plant_id, event);
        Ok(())
    }
}```

--------------------------------------------------------------------------------

# src\state_management\event_dispatcher.rs
```
use tokio::sync::mpsc;
use crate::errors::{DockManagerError, DockManagerResult};
use crate::models::DockDoorEvent;
use log::{info, error};

/// Dispatches events to the appropriate handlers in the dock monitoring system.
pub struct EventDispatcher {
    /// The sender end of a channel for dispatching events.
    event_sender: mpsc::Sender<DockDoorEvent>,
}

impl EventDispatcher {
    /// Creates a new `EventDispatcher`.
    ///
    /// # Arguments
    ///
    /// * `event_sender` - The sender end of a channel for dispatching events.
    ///
    /// # Returns
    ///
    /// A new instance of `EventDispatcher`.
    pub fn new(event_sender: mpsc::Sender<DockDoorEvent>) -> Self {
        Self { event_sender }
    }

    /// Dispatches an event to the appropriate handler.
    ///
    /// This method sends the event through the channel to be processed by the event handler.
    ///
    /// # Arguments
    ///
    /// * `event` - The `DockDoorEvent` to be dispatched.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure of the dispatch operation.
    pub async fn dispatch_event(&self, event: DockDoorEvent) -> DockManagerResult<()> {
        info!("Dispatching event: {:?}", event);
        self.event_sender.send(event).await
            .map_err(|e| {
                error!("Failed to dispatch event: {:?}", e);
                DockManagerError::EventProcessingError(format!("Failed to dispatch event: {}", e))
            })
    }

    /// Dispatches multiple events to the appropriate handlers.
    ///
    /// This method sends multiple events through the channel to be processed by the event handler.
    ///
    /// # Arguments
    ///
    /// * `events` - A vector of `DockDoorEvent`s to be dispatched.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure of the dispatch operation.
    pub async fn dispatch_events(&self, events: Vec<DockDoorEvent>) -> DockManagerResult<()> {
        info!("Dispatching {} events", events.len());
        for event in events {
            if let Err(e) = self.dispatch_event(event).await {
                error!("Failed to dispatch event: {:?}", e);
                return Err(e);
            }
        }
        Ok(())
    }

    /// Checks if the event channel is still open and able to send events.
    ///
    /// # Returns
    ///
    /// `true` if the channel is open, `false` otherwise.
    pub fn is_channel_open(&self) -> bool {
        !self.event_sender.is_closed()
    }
}```

--------------------------------------------------------------------------------

# src\state_management\mod.rs
```
pub mod state_manager;
pub mod door_state_repository;
pub mod command_processor;
pub mod sensor_data_processor;
pub mod event_dispatcher;
pub mod database_event_manager;
pub mod state_manager_lifecycle;
pub mod wms_data_processor;

pub use state_manager::DockDoorStateManager;```

--------------------------------------------------------------------------------

# src\state_management\sensor_data_processor.rs
```
use std::sync::Arc;
use chrono::Local;
use log::{info, debug};
use crate::errors::{DockManagerError, DockManagerResult};
use crate::models::{
    DockDoor, DockDoorEvent, DockLockState, DoorPosition, DoorState, DoorStateChangedEvent,
    FaultState, LevelerPosition, ManualMode, PlcVal, RestraintState, SensorStateChangedEvent,
    TrailerPositionState, TrailerState, TrailerStateChangedEvent
};
use crate::state_management::door_state_repository::DoorStateRepository;

/// Processes sensor data updates for the dock monitoring system.
pub struct SensorDataProcessor {
    /// Repository for managing dock door states.
    door_repository: Arc<DoorStateRepository>,
}

impl SensorDataProcessor {
    /// Creates a new `SensorDataProcessor`.
    ///
    /// # Arguments
    ///
    /// * `door_repository` - A reference to the `DoorStateRepository` for managing door states.
    ///
    /// # Returns
    ///
    /// A new instance of `SensorDataProcessor`.
    pub fn new(door_repository: Arc<DoorStateRepository>) -> Self {
        Self {
            door_repository,
        }
    }

    /// Processes a batch of sensor updates and generates corresponding events.
    ///
    /// # Arguments
    ///
    /// * `sensor_values` - A vector of `PlcVal` representing the sensor updates.
    ///
    /// # Returns
    ///
    /// A Result containing a vector of `DockDoorEvent`s generated from the sensor updates,
    /// or a `DockManagerError` if processing fails.
    pub async fn process_sensor_updates(&self, sensor_values: Vec<PlcVal>) -> DockManagerResult<Vec<DockDoorEvent>> {
        let mut events = Vec::new();
        for sensor_value in sensor_values {
            let plant_id = &sensor_value.plant_id;
            let door_name = &sensor_value.door_name;

            let mut door = self.door_repository.get_door_state(plant_id, door_name).await
                .ok_or_else(|| DockManagerError::DoorNotFound(format!("Plant: {}, Door: {}", plant_id, door_name)))?;

            let new_events = self.process_single_sensor_update(&mut door, &sensor_value).await?;
            events.extend(new_events);

            self.door_repository.update_door(plant_id, door).await?;
        }

        Ok(events)
    }

    /// Processes a single sensor update for a specific door.
    ///
    /// # Arguments
    ///
    /// * `door` - A mutable reference to the `DockDoor` being updated.
    /// * `sensor_value` - The `PlcVal` containing the sensor update.
    ///
    /// # Returns
    ///
    /// A Result containing a vector of `DockDoorEvent`s generated from the sensor update,
    /// or a `DockManagerError` if processing fails.
    async fn process_single_sensor_update(&self, door: &mut DockDoor, sensor_value: &PlcVal) -> Result<Vec<DockDoorEvent>, DockManagerError> {
        let mut events = Vec::new();

        let sensor_evaluation = door.update_sensor(&sensor_value.sensor_name, Some(sensor_value.value))?;

        if sensor_evaluation.changed {
            if sensor_evaluation.old_value.is_none() {
                debug!("Skipping initial sensor update for door: {}, sensor: {}", door.dock_name, sensor_value.sensor_name);
                self.update_door_state(door, sensor_value, &mut Vec::new())?;
                return Ok(Vec::new())
            } else {
                events.push(DockDoorEvent::SensorStateChanged(SensorStateChangedEvent {
                    plant_id: door.plant_id.clone(),
                    dock_name: door.dock_name.clone(),
                    sensor_name: sensor_value.sensor_name.clone(),
                    old_value: sensor_evaluation.old_value,
                    new_value: sensor_evaluation.new_value,
                    timestamp: chrono::Local::now().naive_local(),
                }));
                self.update_door_state(door, sensor_value, &mut events)?;
            }
        }

        Ok(events)
    }

    /// Updates the door state based on the sensor value.
    ///
    /// # Arguments
    ///
    /// * `door` - A mutable reference to the `DockDoor` being updated.
    /// * `sensor_value` - The `PlcVal` containing the sensor update.
    /// * `events` - A mutable reference to the vector of events being generated.
    ///
    /// # Returns
    ///
    /// A Result indicating success or a `DockManagerError` if processing fails.
    fn update_door_state(&self, door: &mut DockDoor, sensor_value: &PlcVal, events: &mut Vec<DockDoorEvent>) -> Result<(), DockManagerError> {
        match sensor_value.sensor_name.as_str() {
            "AUTO_DISENGAGING" => {
                door.restraint_state = if sensor_value.value == 1 { RestraintState::Unlocking } else { RestraintState::Unlocked };
            },
            "AUTO_ENGAGING" => {
                door.restraint_state = if sensor_value.value == 1 { RestraintState::Locking } else { RestraintState::Locked };
            },
            "FAULT_PRESENCE" => {
                door.fault_state = if sensor_value.value == 1 { FaultState::FaultPresent } else { FaultState::NoFault };
            },
            "FAULT_TRAILER_DOORS" => {
                door.trailer_door_fault = sensor_value.value == 1;
            },
            "RH_DOCK_READY" => {
                if sensor_value.value == 1 &&
                    (door.door_state == DoorState::TrailerDocked || door.door_state == DoorState::Unassigned) {
                    if let Some(old_value) = door.sensors.get("RH_DOCK_READY").and_then(|s| s.get_sensor_data().current_value) {
                        if old_value == 0 {
                            door.consolidated.last_dock_ready_time = Some(Local::now().naive_local());
                            self.change_door_state(door, DoorState::DoorReady, events)?;
                        }
                    }
                } else {
                    door.consolidated.last_dock_ready_time = None;
                }
            },
            "RH_DOKLOCK_FAULT" => {
                door.dock_lock_fault = sensor_value.value == 1;
            },
            "RH_DOOR_FAULT" => {
                door.door_fault = sensor_value.value == 1;
            },
            "RH_DOOR_OPEN" => {
                door.door_position = if sensor_value.value == 1 { DoorPosition::Open } else { DoorPosition::Closed };
            },
            "RH_ESTOP" => {
                door.emergency_stop = sensor_value.value == 1;
                if door.emergency_stop {
                    door.manual_mode = ManualMode::Enabled;
                }
            },
            "RH_LEVELER_FAULT" => {
                door.leveler_fault = sensor_value.value == 1;
            },
            "RH_LEVELR_READY" => {
                door.leveler_position = if sensor_value.value == 1 { LevelerPosition::Extended } else { LevelerPosition::Stored };
            },
            "RH_MANUAL_MODE" => {
                door.manual_mode = if sensor_value.value == 1 { ManualMode::Enabled } else { ManualMode::Disabled };
            },
            "RH_RESTRAINT_ENGAGED" => {
                door.dock_lock_state = if sensor_value.value == 1 { DockLockState::Engaged } else { DockLockState::Disengaged };
            },
            "TRAILER_ANGLE" | "TRAILER_CENTERING" | "TRAILER_DISTANCE" => {
                door.trailer_position_state = if sensor_value.value == 0 { TrailerPositionState::Proper } else { TrailerPositionState::Improper };
            },
            "TRAILER_AT_DOOR" => {
                let new_trailer_state = if sensor_value.value == 1 {
                    door.set_docking_time();
                    TrailerState::Docked
                } else {
                    door.clear_docking_time();
                    TrailerState::Undocked
                };
                if door.trailer_state != new_trailer_state {
                    info!("Trailer state change detected: {:?} -> {:?}", door.trailer_state, new_trailer_state);
                    events.push(DockDoorEvent::TrailerStateChanged(TrailerStateChangedEvent {
                        plant_id: door.plant_id.clone(),
                        dock_name: door.dock_name.clone(),
                        old_state: door.trailer_state,
                        new_state: new_trailer_state,
                        timestamp: chrono::Local::now().naive_local(),
                    }));
                    door.trailer_state = new_trailer_state;
                    if new_trailer_state == TrailerState::Docked {
                        info!("Changing door state to TrailerDocked");
                        self.change_door_state(door, DoorState::TrailerDocked, events)?;
                    }
                }
            },
            _ => {
                debug!("Unhandled sensor type: {}", sensor_value.sensor_name);
            }
        }
        Ok(())
    }


    /// Changes the door state and generates a DoorStateChanged event.
    ///
    /// # Arguments
    ///
    /// * `door` - A mutable reference to the `DockDoor` being updated.
    /// * `new_state` - The new `DoorState` to set.
    /// * `events` - A mutable reference to the vector of events being generated.
    ///
    /// # Returns
    ///
    /// A Result indicating success or a `DockManagerError` if processing fails.
    fn change_door_state(&self, door: &mut DockDoor, new_state: DoorState, events: &mut Vec<DockDoorEvent>) -> Result<(), DockManagerError> {
        if door.door_state != new_state {
            let old_state = door.door_state;
            door.door_state = new_state;
            events.push(DockDoorEvent::DoorStateChanged(DoorStateChangedEvent {
                plant_id: door.plant_id.clone(),
                dock_name: door.dock_name.clone(),
                old_state,
                new_state,
                timestamp: chrono::Local::now().naive_local(),
            }));
            info!("Door state changed for {}: {:?} -> {:?}", door.dock_name, old_state, new_state);
        }
        Ok(())
    }
}```

--------------------------------------------------------------------------------

# src\state_management\state_manager.rs
```
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex};
use tokio::sync::mpsc::Receiver;
use log::{info, error};
use crate::config::Settings;
use crate::errors::{DockManagerError, DockManagerResult};
use crate::models::{DockDoorEvent, PlcVal, WmsDoorStatus, DbInsert, WmsEvent, DockDoor};
use crate::state_management::door_state_repository::DoorStateRepository;
use crate::state_management::command_processor::CommandProcessor;
use crate::state_management::sensor_data_processor::SensorDataProcessor;
use crate::state_management::wms_data_processor::WmsDataProcessor;
use crate::state_management::database_event_manager::DatabaseEventManager;
use crate::state_management::event_dispatcher::EventDispatcher;
use crate::state_management::state_manager_lifecycle::StateManagerLifecycle;
use crate::services::db::DatabaseService;

/// Manages the overall state of the dock door monitoring system.
#[derive(Clone)]
pub struct DockDoorStateManager {
    door_repository: Arc<DoorStateRepository>,
    command_processor: Arc<Mutex<CommandProcessor>>,
    sensor_processor: Arc<SensorDataProcessor>,
    wms_processor: Arc<WmsDataProcessor>,
    db_event_manager: Arc<DatabaseEventManager>,
    event_dispatcher: Arc<EventDispatcher>,
    lifecycle: Arc<StateManagerLifecycle>,
}

impl DockDoorStateManager {
    /// Creates a new `DockDoorStateManager`.
    ///
    /// # Arguments
    ///
    /// * `settings` - The application settings.
    /// * `db_service` - A reference to the database service.
    ///
    /// # Returns
    ///
    /// A new instance of `DockDoorStateManager`.
    pub async fn new(settings: &Settings, db_service: Arc<DatabaseService>) -> (Self, Receiver<DockDoorEvent>) {
        let door_repository = Arc::new(DoorStateRepository::new());
        door_repository.initialize_from_settings(settings)
            .await
            .expect("Failed to initialize doors from settings");
        let (_command_sender, command_receiver) = mpsc::channel(100);
        let (event_sender, event_receiver) = mpsc::channel(1000);

        let db_event_manager = Arc::new(DatabaseEventManager::new(settings.batch_size,
            Arc::clone(&db_service)
        ));

        let event_dispatcher = Arc::new(EventDispatcher::new(event_sender));

        let sensor_processor = Arc::new(SensorDataProcessor::new(Arc::clone(&door_repository)));
        let wms_processor = Arc::new(WmsDataProcessor::new(Arc::clone(&door_repository)));

        let command_processor = Arc::new(Mutex::new(CommandProcessor::new(
            command_receiver,
            Arc::clone(&door_repository),
            Arc::clone(&sensor_processor),
            Arc::clone(&wms_processor),
            Arc::clone(&db_event_manager),
            Arc::clone(&event_dispatcher),
        )));

        let lifecycle = Arc::new(StateManagerLifecycle::new(Arc::clone(&db_event_manager)));

        (Self {
            door_repository,
            command_processor,
            sensor_processor,
            wms_processor,
            db_event_manager,
            event_dispatcher,
            lifecycle,
        }, event_receiver)
    }

    /// Runs the main loop of the state manager.
    ///
    /// This method processes commands and handles shutdown when signaled.
    pub async fn run(&self) {
        info!("Starting DockDoorStateManager");

        let command_processor = Arc::clone(&self.command_processor);
        let command_processor_handle = tokio::spawn(async move {
            if let Err(e) = command_processor.lock().await.run().await {
                error!("Error in command processor: {:?}", e);
            }
        });

        loop {
            tokio::select! {
                _ = self.lifecycle.wait_for_shutdown() => {
                    info!("Shutdown signal received, stopping DockDoorStateManager");
                    break;
                }
                result = command_processor_handle => {
                    match result {
                        Ok(_) => info!("Command processor finished successfully"),
                        Err(e) => error!("Command processor task panicked: {:?}", e),
                    }
                    break;
                }
            }
        }

        self.shutdown().await;
    }

    /// Handles the shutdown process for the state manager.
    async fn shutdown(&self) {
        info!("Initiating shutdown process");

        // Perform cleanup
        if let Err(e) = self.lifecycle.cleanup().await {
            error!("Error during cleanup: {:?}", e);
        }

        info!("DockDoorStateManager shutdown complete");
    }

    /// Updates sensor values and generates corresponding events.
    ///
    /// # Arguments
    ///
    /// * `sensor_values` - A vector of `PlcVal` representing the sensor updates.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` containing a vector of generated `DockDoorEvent`s.
    pub async fn update_sensors(&self, sensor_values: Vec<PlcVal>) -> DockManagerResult<Vec<DockDoorEvent>> {
        self.sensor_processor.process_sensor_updates(sensor_values).await
    }

    /// Updates the state based on WMS data and generates corresponding events.
    ///
    /// # Arguments
    ///
    /// * `wms_data` - A vector of `WmsDoorStatus` representing the WMS updates.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` containing a vector of generated `DockDoorEvent`s.
    pub async fn update_from_wms(&self, wms_data: Vec<WmsDoorStatus>) -> DockManagerResult<Vec<DockDoorEvent>> {
        self.wms_processor.process_wms_updates(wms_data).await
    }

    /// Processes WMS events and generates database insert events.
    ///
    /// # Arguments
    ///
    /// * `wms_events` - A vector of `WmsEvent`s to process.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` containing a vector of generated `DbInsert` events.
    pub async fn process_wms_events(&self, wms_events: Vec<WmsEvent>) -> DockManagerResult<Vec<DockDoorEvent>> {
        self.wms_processor.process_wms_events(wms_events).await
    }

    /// Dispatches a single event.
    ///
    /// # Arguments
    ///
    /// * `event` - The `DockDoorEvent` to dispatch.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure.
    pub async fn dispatch_event(&self, event: DockDoorEvent) -> DockManagerResult<()> {
        self.event_dispatcher.dispatch_event(event).await
    }

    /// Dispatches multiple events.
    ///
    /// # Arguments
    ///
    /// * `events` - A vector of `DockDoorEvent`s to dispatch.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure.
    pub async fn dispatch_events(&self, events: Vec<DockDoorEvent>) -> DockManagerResult<()> {
        self.event_dispatcher.dispatch_events(events).await
    }

    /// Triggers the shutdown process for the state manager.
    pub fn trigger_shutdown(&self) {
        self.lifecycle.trigger_shutdown();
    }

    /// Adds a database event to be processed.
    ///
    /// # Arguments
    ///
    /// * `event` - The `DbInsert` event to add.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure.
    pub async fn add_db_event(&self, event: DbInsert) -> DockManagerResult<()> {
        self.db_event_manager.add_event(event).await
    }

    /// Flushes all pending database events.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure.
    pub async fn flush_db_events(&self) -> DockManagerResult<()> {
        self.db_event_manager.flush_events().await
    }

    pub async fn get_door(&self, plant_id: &str, door_name: &str) -> Option<DockDoor> {
        self.door_repository.get_door_state(plant_id, door_name).await
    }

    pub async fn update_door(&self, plant_id: &str, door: DockDoor) -> Result<(), DockManagerError> {
        self.door_repository.update_door(plant_id, door).await
    }

    pub async fn insert_db_event(&self, event: DbInsert) -> Result<(), DockManagerError> {
        self.db_event_manager.add_event(event).await
    }

    pub fn get_door_repository(&self) -> Arc<DoorStateRepository> {
        Arc::clone(&self.door_repository)
    }

}```

--------------------------------------------------------------------------------

# src\state_management\state_manager_lifecycle.rs
```
use tokio::sync::Notify;
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use log::{info, error};
use crate::errors::DockManagerResult;
use crate::state_management::database_event_manager::DatabaseEventManager;

/// Manages the lifecycle of the state manager in the dock monitoring system.
pub struct StateManagerLifecycle {
    /// Signal for triggering and waiting for shutdown.
    shutdown_signal: Arc<Notify>,
    /// Boolean flag to indicate if shutdown has been triggered.
    shutdown_triggered: Arc<AtomicBool>,
    /// Reference to the database event manager for flushing events during shutdown.
    db_event_manager: Arc<DatabaseEventManager>,
}

impl StateManagerLifecycle {
    /// Creates a new `StateManagerLifecycle`.
    ///
    /// # Arguments
    ///
    /// * `db_event_manager` - A reference to the `DatabaseEventManager` for handling shutdown operations.
    ///
    /// # Returns
    ///
    /// A new instance of `StateManagerLifecycle`.
    pub fn new(db_event_manager: Arc<DatabaseEventManager>) -> Self {
        Self {
            shutdown_signal: Arc::new(Notify::new()),
            shutdown_triggered: Arc::new(AtomicBool::new(false)),
            db_event_manager,
        }
    }

    /// Waits for the shutdown signal.
    ///
    /// This method blocks until the shutdown signal is triggered.
    pub async fn wait_for_shutdown(&self) {
        info!("Waiting for shutdown signal");
        self.shutdown_signal.notified().await;
        info!("Shutdown signal received");
    }

    /// Triggers the shutdown signal.
    ///
    /// This method notifies all tasks waiting on the shutdown signal to begin their shutdown process.
    pub fn trigger_shutdown(&self) {
        info!("Triggering shutdown");
        self.shutdown_triggered.store(true, Ordering::SeqCst);
        self.shutdown_signal.notify_waiters();
    }

    /// Performs cleanup operations during shutdown.
    ///
    /// This method is responsible for any necessary cleanup tasks, such as flushing remaining database events.
    ///
    /// # Returns
    ///
    /// A `DockManagerResult` indicating success or failure of the cleanup process.
    pub async fn cleanup(&self) -> DockManagerResult<()> {
        info!("Starting cleanup process");

        // Flush any remaining database events
        if let Err(e) = self.db_event_manager.flush_events().await {
            error!("Error flushing database events during cleanup: {:?}", e);
            // Decide whether to return the error or continue with other cleanup tasks
        }

        info!("Cleanup process completed");
        Ok(())
    }

    /// Checks if the shutdown signal has been triggered.
    ///
    /// # Returns
    ///
    /// `true` if the shutdown signal has been triggered, `false` otherwise.
    pub fn is_shutdown_triggered(&self) -> bool {
        self.shutdown_triggered.load(Ordering::SeqCst)
    }

    /// Resets the shutdown signal.
    ///
    /// This method can be used to reset the shutdown state, allowing the system to be restarted.
    /// It should be used with caution and only in specific scenarios where a reset is appropriate.
    pub fn reset_shutdown_signal(&self) {
        info!("Resetting shutdown signal");
        self.shutdown_triggered.store(false, Ordering::SeqCst);
        // Note: We don't need to reset the Notify here as it automatically resets after notifying
    }
}```

--------------------------------------------------------------------------------

# src\state_management\wms_data_processor.rs
```
use std::str::FromStr;
use crate::models::{WmsDoorStatus, DockDoorEvent, DoorState, DockDoor, ShipmentAssignedEvent, ShipmentUnassignedEvent, LoadingStatus, LoadingStatusChangedEvent, DoorStateChangedEvent, WmsEvent};
use crate::errors::{DockManagerError, DockManagerResult};
use crate::state_management::door_state_repository::DoorStateRepository;
use std::sync::Arc;
use chrono::Local;
use log::info;

/// Processes WMS (Warehouse Management System) data updates for the dock monitoring system.
pub struct WmsDataProcessor {
    /// Repository for managing dock door states.
    door_repository: Arc<DoorStateRepository>,
}

impl WmsDataProcessor {
    /// Creates a new `WmsDataProcessor`.
    ///
    /// # Arguments
    ///
    /// * `door_repository` - A reference to the `DoorStateRepository` for managing door states.
    ///
    /// # Returns
    ///
    /// A new instance of `WmsDataProcessor`.
    pub fn new(door_repository: Arc<DoorStateRepository>) -> Self {
        Self {
            door_repository,
        }
    }

    /// Processes a batch of WMS data updates and generates corresponding events.
    ///
    /// # Arguments
    ///
    /// * `wms_data` - A vector of `WmsDoorStatus` representing the WMS updates.
    ///
    /// # Returns
    ///
    /// A Result containing a vector of `DockDoorEvent`s generated from the WMS updates,
    /// or a `DockManagerError` if processing fails.
    pub async fn process_wms_updates(&self, wms_data: Vec<WmsDoorStatus>) -> Result<Vec<DockDoorEvent>, DockManagerError> {
        let mut events = Vec::new();

        for wms_status in wms_data {
            let door_events = self.process_single_wms_update(&wms_status).await?;
            events.extend(door_events);
        }

        Ok(events)
    }

    /// Processes a single WMS update for a specific door.
    ///
    /// # Arguments
    ///
    /// * `wms_status` - The `WmsDoorStatus` containing the WMS update for a door.
    ///
    /// # Returns
    ///
    /// A Result containing a vector of `DockDoorEvent`s generated from the WMS update,
    /// or a `DockManagerError` if processing fails.
    async fn process_single_wms_update(&self, wms_status: &WmsDoorStatus) -> Result<Vec<DockDoorEvent>, DockManagerError> {
        let mut events = Vec::new();

        let mut door = self.door_repository.get_door_state(wms_status.plant.as_str(),&wms_status.dock_name).await
            .ok_or_else(|| DockManagerError::DoorNotFound(wms_status.dock_name.clone()))?;

        // Update shipment assignment
        if door.assigned_shipment.current_shipment != wms_status.assigned_shipment {
            let old_shipment = door.assigned_shipment.current_shipment.clone();
            door.assigned_shipment.current_shipment = wms_status.assigned_shipment.clone();
            door.assigned_shipment.assignment_dttm = Some(Local::now().naive_local());
            door.consolidated.dock_assignment = Some(Local::now().naive_local());


            if let Some(shipment_id) = &wms_status.assigned_shipment {
                events.push(DockDoorEvent::ShipmentAssigned(ShipmentAssignedEvent {
                    plant_id: wms_status.plant.clone(),
                    dock_name: door.dock_name.clone(),
                    shipment_id: shipment_id.clone(),
                    timestamp: Local::now().naive_local(),
                    previous_shipment: old_shipment,
                }));
            } else if let Some(previous_shipment) = old_shipment {
                door.assigned_shipment.assignment_dttm = None;
                door.consolidated.dock_assignment = None;

                events.push(DockDoorEvent::ShipmentUnassigned(ShipmentUnassignedEvent {
                    plant_id: wms_status.plant.clone(),
                    dock_name: door.dock_name.clone(),
                    shipment_id: previous_shipment,
                    timestamp: chrono::Local::now().naive_local(),
                }));
            }
        }

        // Update loading status
        let new_loading_status = LoadingStatus::from_str(&wms_status.loading_status)
            .map_err(|_| DockManagerError::ConfigError(format!("Invalid loading status: {}", wms_status.loading_status)))?;

        if door.loading_status.loading_status != new_loading_status {
            events.push(DockDoorEvent::LoadingStatusChanged(LoadingStatusChangedEvent {
                plant_id: wms_status.plant.clone(),
                dock_name: door.dock_name.clone(),
                old_status: door.loading_status.loading_status,
                new_status: new_loading_status,
                timestamp: chrono::Local::now().naive_local(),
            }));

            // Archiving previous state
            door.loading_status.previous_loading_status = door.loading_status.loading_status;
            door.loading_status.previous_state_dttm = door.loading_status.current_state_dttm;
            door.loading_status.loading_status = new_loading_status;
            door.loading_status.current_state_dttm = Some(Local::now().naive_local());

        }

        // Update WMS shipment status
        door.loading_status.wms_shipment_status = wms_status.wms_shipment_status.clone();
        if wms_status.is_preload.is_some() {
            if door.consolidated.is_preload != wms_status.is_preload.unwrap()
            {
                log::info!("Updating is_preload for door {}: {:?} -> {:?}",
               door.dock_name, door.consolidated.is_preload, wms_status.is_preload.unwrap());
                door.consolidated.is_preload = wms_status.is_preload.unwrap();
            }
        }

        // Update door state based on WMS data
        let new_door_state = self.determine_door_state(&door, wms_status);
        if door.door_state != new_door_state {
            events.push(DockDoorEvent::DoorStateChanged(DoorStateChangedEvent {
                plant_id: wms_status.plant.clone(),
                dock_name: door.dock_name.clone(),
                old_state: door.door_state,
                new_state: new_door_state,
                timestamp: chrono::Local::now().naive_local(),
            }));
            door.door_state = new_door_state;
        }

        // Update the door in the repository
        self.door_repository.update_door(door.plant_id.clone().as_str(), door).await?;

        Ok(events)
    }

    /// Determines the appropriate door state based on WMS data and current door state.
    ///
    /// # Arguments
    ///
    /// * `door` - The current `DockDoor` state.
    /// * `wms_status` - The `WmsDoorStatus` containing the WMS update for the door.
    ///
    /// # Returns
    ///
    /// The new `DoorState` based on the WMS data and current door state.
    fn determine_door_state(&self, door: &DockDoor, wms_status: &WmsDoorStatus) -> DoorState {
        match wms_status.loading_status.as_str() {
            "Idle" => DoorState::Unassigned,
            "CSO" => DoorState::Assigned,
            "WhseInspection" => DoorState::DriverCheckedIn,
            "LgvAllocation" => DoorState::DoorReady,
            "Loading" => DoorState::Loading,
            "Completed" => DoorState::LoadingCompleted,
            "WaitingForExit" => DoorState::WaitingForExit,
            _ => door.door_state, // Maintain current state if unknown WMS status
        }
    }

    pub async fn process_wms_events(&self, wms_events: Vec<WmsEvent>) -> DockManagerResult<Vec<DockDoorEvent>> {
        let mut events = Vec::new();

        for wms_event in wms_events {
            info!("Converting WMS Event: {:?}", wms_event);
            let mut door = self.door_repository.get_door_state(&wms_event.plant, &wms_event.dock_name).await
                .ok_or_else(|| DockManagerError::DoorNotFound(wms_event.dock_name.clone()))?;

            // Convert WmsEvent to DockDoorEvent
            let dock_door_event = DockDoorEvent::from_wms_event(wms_event.clone());
            info!("Converted WMS Event: {:?}", dock_door_event);
            // Update door state based on WMS event
            if wms_event.message_type == "DOCK_ASSIGNMENT" {
                door.consolidated.dock_assignment = Some(wms_event.log_dttm.unwrap_or_else(|| chrono::Local::now().naive_local()));
            }

            if wms_event.message_type == "STARTED_SHIPMENT" {
                door.consolidated.shipment_started_dttm = Some(wms_event.log_dttm.unwrap_or_else(|| chrono::Local::now().naive_local()));
            }

            if wms_event.message_type == "LGV_START_LOADING" {
                door.consolidated.lgv_loading_started = Some(wms_event.log_dttm.unwrap_or_else(|| chrono::Local::now().naive_local()));
            }

            if wms_event.message_type == "FIRST_DROP" {
                door.consolidated.lgv_loading_started = Some(wms_event.log_dttm.unwrap_or_else(|| chrono::Local::now().naive_local()));
            }


            // Update the door in the repository
            self.door_repository.update_door(&wms_event.plant, door).await?;

            events.push(dock_door_event);
        }

        Ok(events)
    }

}```

--------------------------------------------------------------------------------

# src\utils\mod.rs
```
use chrono::Duration;


/// Formats a duration into a human-readable string
///
/// # Arguments
///
/// * `duration` - The duration to format
///
/// # Returns
///
/// A formatted duration string
pub fn format_duration(duration: &Duration) -> String {
    let total_seconds = duration.num_seconds();
    let hours = total_seconds / 3600;
    let minutes = (total_seconds % 3600) / 60;
    let seconds = total_seconds % 60;

    if hours > 0 {
        format!("{}h {}m {}s", hours, minutes, seconds)
    } else if minutes > 0 {
        format!("{}m {}s", minutes, seconds)
    } else {
        format!("{}s", seconds)
    }
}```

--------------------------------------------------------------------------------
